{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I've tagged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "\n",
    "Tag data. You'll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\n",
    "\n",
    "Once you've created an account you'll want to create a new dataset. (+ button on the left hand side.)\n",
    "Select the Document Annotation option under Text annotations.\n",
    "    Provide a dataset name (you can use whatever)\n",
    "    for the list of entities just input Person\n",
    "    for the tagging instructions provide whatever you would like\n",
    "    Then hit submit\n",
    "    \n",
    "You will then hit the \"Upload raw data\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\n",
    "\n",
    "You can then tag each document. Simply highlight the piece of text that you think is a person. When you've identified all of them for a single document hit \"move to done\". Use the guidelines contained in the next cell.\n",
    "\n",
    "When you finish tagging all 5 documents, go into the project you've tagged and hit the options button in the top right. You will then hit \"download\". You will want to have the \"complete items\" and \"json\" options selected. Hit download and you will then have a json file for all of your documents.\n",
    "\n",
    "(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation guidelines:\n",
    "    These are from the ACE Guidelines for Person:\n",
    "    \n",
    "3.1 Persons (PER) \n",
    "    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \n",
    "\n",
    "There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \n",
    "\n",
    "Examples: \n",
    "He is [a real turkey]\n",
    "[The political cat of the year]\n",
    "She’s known as [the brain of the family] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2:\n",
    "\n",
    "Look through the below code.\n",
    "\n",
    "You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\n",
    "\n",
    "Implement the appropriate code to calculate these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\n\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\n\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 379, 'end': 386, 'text': 'Blackmon'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 74, 'end': 79, 'text': 'Hardin'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 64, 'end': 71, 'text': 'Blackmon'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 55, 'end': 71, 'text': 'Jonathan Blackmon'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1586954510000,\n",
       "   'last_updated_at': 1586954510000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'CORRECT'}},\n",
       " {'content': 'Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\n\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\n\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 453, 'end': 460, 'text': 'Morrison'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 79, 'end': 91, 'text': 'Peter O’Neill'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 32, 'end': 39, 'text': 'Morrison'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 26, 'end': 39, 'text': 'Scott Morrison'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1586954448000,\n",
       "   'last_updated_at': 1586954448000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}},\n",
       " {'content': 'Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\n\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\n\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 0, 'end': 10, 'text': 'Joe Montana'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1586954477000,\n",
       "   'last_updated_at': 1586954477000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}},\n",
       " {'content': 'To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\n\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\n\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 816, 'end': 825, 'text': 'John Deere'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 701, 'end': 710, 'text': 'John Deere'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 588, 'end': 594, 'text': 'Merritt'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 576, 'end': 581, 'text': 'Walker'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 532, 'end': 537, 'text': 'Walker'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 501, 'end': 510, 'text': 'John Deere'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 224, 'end': 230, 'text': 'Merritt'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 218, 'end': 229, 'text': 'Piper Merrit'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 183, 'end': 192, 'text': 'John Deere'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 25, 'end': 34, 'text': 'John Deere'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1586954335000,\n",
       "   'last_updated_at': 1586954335000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}},\n",
       " {'content': 'A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 44, 'end': 62, 'text': 'George Washington’s'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1586954354000,\n",
       "   'last_updated_at': 1586954354000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "# method to read annotation file\n",
    "def annotation_processor(annotation_file):\n",
    "    annotation_array = []\n",
    "\n",
    "    # here we need to be careful and process each line of the annotation file separately\n",
    "    read_annotation = open(annotation_file,encoding='utf8')\n",
    "    for line in read_annotation:\n",
    "        data = json.loads(line)\n",
    "        annotation_array.append(data)\n",
    "\n",
    "    # here we return an array of the individual annotations\n",
    "    return annotation_array\n",
    "    \n",
    "# calling the annotation processor function\n",
    "annotation_processor('Person_entites.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#person_dict = json.loads('annotated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\n\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\n\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 379, 'end': 386, 'text': 'Blackmon'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 293, 'end': 296, 'text': 'Irma'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 267, 'end': 272, 'text': 'Harvey'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 74, 'end': 79, 'text': 'Hardin'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 64, 'end': 71, 'text': 'Blackmon'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 42,\n",
       "      'end': 71,\n",
       "      'text': 'Chief Deputy Jonathan Blackmon'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1541085438000,\n",
       "   'last_updated_at': 1541085438000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'nJUvh8eg6cTQb2imeaFWqJDvwDt1',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}},\n",
       " {'content': 'Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\n\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\n\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 453, 'end': 460, 'text': 'Morrison'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 315, 'end': 325, 'text': 'the leaders'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 80, 'end': 91, 'text': 'eter O’Neill'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 32, 'end': 39, 'text': 'Morrison'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 26, 'end': 39, 'text': 'Scott Morrison'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1541085568000,\n",
       "   'last_updated_at': 1541085568000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'nJUvh8eg6cTQb2imeaFWqJDvwDt1',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}},\n",
       " {'content': 'Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\n\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\n\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 416, 'end': 420, 'text': 'Clark'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 269, 'end': 275, 'text': 'Montana'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 245, 'end': 259, 'text': 'the quarterback'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 40, 'end': 44, 'text': 'Clark'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 33, 'end': 44, 'text': 'Dwight Clark'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 4, 'end': 10, 'text': 'Montana'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 0, 'end': 10, 'text': 'Joe Montana'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1541085542000,\n",
       "   'last_updated_at': 1541085542000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'nJUvh8eg6cTQb2imeaFWqJDvwDt1',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}},\n",
       " {'content': 'To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\n\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\n\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 816, 'end': 825, 'text': 'John Deere'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 701, 'end': 710, 'text': 'John Deere'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 588, 'end': 594, 'text': 'Merritt'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 576, 'end': 581, 'text': 'Walker'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 532, 'end': 537, 'text': 'Walker'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 527, 'end': 537, 'text': 'Doug Walker'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 501, 'end': 510, 'text': 'John Deere'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 224, 'end': 230, 'text': 'Merritt'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 218, 'end': 231, 'text': 'Piper Merritt,'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 183, 'end': 192, 'text': 'John Deere'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 25, 'end': 34, 'text': 'John Deere'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1541085478000,\n",
       "   'last_updated_at': 1541085478000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'nJUvh8eg6cTQb2imeaFWqJDvwDt1',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}},\n",
       " {'content': 'A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.',\n",
       "  'annotation': [{'label': ['Person'],\n",
       "    'points': [{'start': 85,\n",
       "      'end': 116,\n",
       "      'text': 'A group of students and teachers'}]},\n",
       "   {'label': ['Person'],\n",
       "    'points': [{'start': 44, 'end': 60, 'text': 'George Washington'}]}],\n",
       "  'extras': None,\n",
       "  'metadata': {'first_done_at': 1541085505000,\n",
       "   'last_updated_at': 1541085505000,\n",
       "   'sec_taken': 0,\n",
       "   'last_updated_by': 'nJUvh8eg6cTQb2imeaFWqJDvwDt1',\n",
       "   'status': 'done',\n",
       "   'evaluation': 'NONE'}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_processor('annotated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will create two objects to store the reference annotations and your own annotations\n",
    "reference_annotations = annotation_processor('Person_entites.json')\n",
    "\n",
    "# here I am just putting the same file in... if I do this I would expect a perfect match\n",
    "my_annotations = annotation_processor('annotated.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=my_annotations[:]\n",
    "n=reference_annotations[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will primarily focus on implementing this compare_annotations method\n",
    "def compare_annotations(m, n):\n",
    "    num_matches = 0\n",
    "    num_non_matches = 0\n",
    "    # you will need to implement this method\n",
    "    # The annotations you will get in the parameters are arrays of objects like this:\n",
    "    # {'label': ['Person'],\n",
    "    # 'points': [{'start': 85,\n",
    "    #  'end': 116,\n",
    "    #  'text': 'A group of students and teachers'}]}\n",
    "    # You will need to compare the annoatations between the reference and your own\n",
    "    # You will look to see if you have annotations that match when the start and end values are the same,\n",
    "    # that is the character offset is correct\n",
    "    for smallm,smalln in zip(m,n):\n",
    "        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \n",
    "                if keym==\"annotation\" and keyn==\"annotation\":\n",
    "                    for vm,vn in zip(valuem,valuen):\n",
    "                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\n",
    "                            if vmk==\"points\" and vnk==\"points\":\n",
    "                                for v1,v2 in zip(vmv,vnv):\n",
    "                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\n",
    "                                        #for v11,v22 in zip(vv1,vv2):\n",
    "                                        if vv1==vv2:\n",
    "                                            num_matches = num_matches +1 \n",
    "                                        elif vv1!=vv2:\n",
    "                                            num_non_matches=num_non_matches+1\n",
    "    print(\"success\")\n",
    "    \n",
    "    return num_matches, num_non_matches\n",
    "    \n",
    "\n",
    "def compare_annotation_files(mm, nn):\n",
    "    m1,n1=compare_annotations(mm,nn)\n",
    "    return m1,n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "(23, 37)\n"
     ]
    }
   ],
   "source": [
    "m=my_annotations[:]\n",
    "n=reference_annotations[:]\n",
    "print(compare_annotation_files(m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "val1,val2=compare_annotation_files(reference_annotations, my_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3:\n",
    "\n",
    "With the numbers now available, try to determine the Cohen's Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\n",
    "\n",
    "Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\n",
    "\n",
    "The rest of the formula should be as discussed in class.\n",
    "\n",
    "Report the numbers you calculate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen Kappa calculation: \n",
    "        - number of matches:val1: 23\n",
    "        - number of non matches: val2: 37\n",
    "        - probability of random agreement: 0.3.\n",
    "        \n",
    "## Calculations:\n",
    "    - Observed Values: 23/60= 0.38\n",
    "    - Kappa: (0.38-0.3)/(1-0.3)\n",
    "    - Kappa: 0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4:\n",
    "\n",
    "You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\n",
    "    What kind of differences there are between your annotations and the ones I have provided.\n",
    "        Look through the different annotations and suggest where I might have been mistaken in identifying people\n",
    "    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\n",
    "    A brief explanation of the Cohen's Kappa you calculated. Do you think it might be high or low? Does it report anything useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination:\n",
    "The guidelines seem to to be very well explained, even though the size of the documents is small, I failed to identify occupations as a person. I also missed out certain names like \"Joe Montana\". This would mean that hand annotations are not very reliable. \n",
    "\n",
    "I do not see many errors in the refernece annotations. \"eter O’Neill\"- this may be an example of a incomplete annotation. Also I am not sure if \"the leaders\" can be identified as a person, as I do not see it as an example of an occupation. \n",
    "\n",
    "The matched number of entities is 23 and the non-matches is 37, meaning that the total number of observations is 60. Therefore calculating the observed number of values is: (matches/total) : (23/60) : 0.38. The cohen's kappa formula : (observed values-probability of random agreement)/(1-probability of random agreement) : (0.38)/(0.3)-(1-0.3). The final value of cohen's kappa would be 0.11. The cohen's kappa is fairly low. This would mean that the hand annotations are not very useful and do not match the refrence annotations very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5:\n",
    "\n",
    "Now you will compare the output of two extractors over a small dataset of news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just using two different spacy models.\n",
    "# you will need to ensure that you have both models installed\n",
    "model_1 = spacy.load(\"en_core_web_sm\")\n",
    "model_2 = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\NLP_HW\\\\HW3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_base = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"content\": \"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\n\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\n\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":379,\"end\":386,\"text\":\"Blackmon\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":293,\"end\":296,\"text\":\"Irma\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":267,\"end\":272,\"text\":\"Harvey\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":74,\"end\":79,\"text\":\"Hardin\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":64,\"end\":71,\"text\":\"Blackmon\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":42,\"end\":71,\"text\":\"Chief Deputy Jonathan Blackmon\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085438000,\"last_updated_at\":1541085438000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "{\"content\": \"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\n\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\n\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":453,\"end\":460,\"text\":\"Morrison\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":315,\"end\":325,\"text\":\"the leaders\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":80,\"end\":91,\"text\":\"eter O’Neill\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":32,\"end\":39,\"text\":\"Morrison\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":26,\"end\":39,\"text\":\"Scott Morrison\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085568000,\"last_updated_at\":1541085568000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "{\"content\": \"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\n\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\n\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":416,\"end\":420,\"text\":\"Clark\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":269,\"end\":275,\"text\":\"Montana\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":245,\"end\":259,\"text\":\"the quarterback\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":40,\"end\":44,\"text\":\"Clark\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":33,\"end\":44,\"text\":\"Dwight Clark\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":4,\"end\":10,\"text\":\"Montana\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":0,\"end\":10,\"text\":\"Joe Montana\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085542000,\"last_updated_at\":1541085542000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "{\"content\": \"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\n\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\n\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":816,\"end\":825,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":701,\"end\":710,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":588,\"end\":594,\"text\":\"Merritt\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":576,\"end\":581,\"text\":\"Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":532,\"end\":537,\"text\":\"Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":527,\"end\":537,\"text\":\"Doug Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":501,\"end\":510,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":224,\"end\":230,\"text\":\"Merritt\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":218,\"end\":231,\"text\":\"Piper Merritt,\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":183,\"end\":192,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":25,\"end\":34,\"text\":\"John Deere\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085478000,\"last_updated_at\":1541085478000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "{\"content\": \"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":85,\"end\":116,\"text\":\"A group of students and teachers\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":44,\"end\":60,\"text\":\"George Washington\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085505000,\"last_updated_at\":1541085505000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Homework #3\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I've tagged.\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 1:\\n\",\n",
      "    \"\\n\",\n",
      "    \"Tag data. You'll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\n\",\n",
      "    \"\\n\",\n",
      "    \"Once you've created an account you'll want to create a new dataset. (+ button on the left hand side.)\\n\",\n",
      "    \"Select the Document Annotation option under Text annotations.\\n\",\n",
      "    \"    Provide a dataset name (you can use whatever)\\n\",\n",
      "    \"    for the list of entities just input Person\\n\",\n",
      "    \"    for the tagging instructions provide whatever you would like\\n\",\n",
      "    \"    Then hit submit\\n\",\n",
      "    \"    \\n\",\n",
      "    \"You will then hit the \\\"Upload raw data\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\n\",\n",
      "    \"\\n\",\n",
      "    \"You can then tag each document. Simply highlight the piece of text that you think is a person. When you've identified all of them for a single document hit \\\"move to done\\\". Use the guidelines contained in the next cell.\\n\",\n",
      "    \"\\n\",\n",
      "    \"When you finish tagging all 5 documents, go into the project you've tagged and hit the options button in the top right. You will then hit \\\"download\\\". You will want to have the \\\"complete items\\\" and \\\"json\\\" options selected. Hit download and you will then have a json file for all of your documents.\\n\",\n",
      "    \"\\n\",\n",
      "    \"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Annotation guidelines:\\n\",\n",
      "    \"    These are from the ACE Guidelines for Person:\\n\",\n",
      "    \"    \\n\",\n",
      "    \"3.1 Persons (PER) \\n\",\n",
      "    \"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\n\",\n",
      "    \"\\n\",\n",
      "    \"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\n\",\n",
      "    \"\\n\",\n",
      "    \"Examples: \\n\",\n",
      "    \"He is [a real turkey]\\n\",\n",
      "    \"[The political cat of the year]\\n\",\n",
      "    \"She’s known as [the brain of the family] \"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 2:\\n\",\n",
      "    \"\\n\",\n",
      "    \"Look through the below code.\\n\",\n",
      "    \"\\n\",\n",
      "    \"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\n\",\n",
      "    \"\\n\",\n",
      "    \"Implement the appropriate code to calculate these numbers.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# import json\\n\",\n",
      "    \"from pprint import pprint\\n\",\n",
      "    \"\\n\",\n",
      "    \"\\n\",\n",
      "    \"# method to read annotation file\\n\",\n",
      "    \"def annotation_processor(annotation_file):\\n\",\n",
      "    \"    annotation_array = []\\n\",\n",
      "    \"\\n\",\n",
      "    \"    # here we need to be careful and process each line of the annotation file separately\\n\",\n",
      "    \"    read_annotation = open(annotation_file)\\n\",\n",
      "    \"    for line in read_annotation:\\n\",\n",
      "    \"        data = json.loads(line)\\n\",\n",
      "    \"        annotation_array.append(data)\\n\",\n",
      "    \"\\n\",\n",
      "    \"    # here we return an array of the individual annotations\\n\",\n",
      "    \"    return annotation_array\\n\",\n",
      "    \"    \\n\",\n",
      "    \"# calling the annotation processor function\\n\",\n",
      "    \"annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# here we will create two objects to store the reference annotations and your own annotations\\n\",\n",
      "    \"reference_annotations = annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\n\",\n",
      "    \"\\n\",\n",
      "    \"# here I am just putting the same file in... if I do this I would expect a perfect match\\n\",\n",
      "    \"my_annotations = annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\n\",\n",
      "    \"\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# you will primarily focus on implementing this compare_annotations method\\n\",\n",
      "    \"def compare_annotations(reference_annotations, my_annotations):\\n\",\n",
      "    \"    num_matches = 0\\n\",\n",
      "    \"    num_non_matches = 0\\n\",\n",
      "    \"    # you will need to implement this method\\n\",\n",
      "    \"    # The annotations you will get in the parameters are arrays of objects like this:\\n\",\n",
      "    \"    # {'label': ['Person'],\\n\",\n",
      "    \"    # 'points': [{'start': 85,\\n\",\n",
      "    \"    #  'end': 116,\\n\",\n",
      "    \"    #  'text': 'A group of students and teachers'}]}\\n\",\n",
      "    \"    # You will need to compare the annoatations between the reference and your own\\n\",\n",
      "    \"    # You will look to see if you have annotations that match when the start and end values are the same,\\n\",\n",
      "    \"    # that is the character offset is correct\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    print(\\\"success\\\")\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return num_matches, num_non_matches\\n\",\n",
      "    \"    \\n\",\n",
      "    \"\\n\",\n",
      "    \"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\n\",\n",
      "    \"    num_annotations_in_reference = 0\\n\",\n",
      "    \"    num_annotations_in_mine = 0\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # we want this method to calculate these two numbers\\n\",\n",
      "    \"    # num_matches should simply count all the cases where we \\n\",\n",
      "    \"    num_matches = 0\\n\",\n",
      "    \"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\n\",\n",
      "    \"    num_non_matches = 0\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\n\",\n",
      "    \"    num_partial_match = 0\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    for annotation in reference_annotation_array:\\n\",\n",
      "    \"        for my_annotation in my_annotation_array:\\n\",\n",
      "    \"            # here we need to do some things to ensure that the documents we are comparing are identical\\n\",\n",
      "    \"            if (annotation[\\\"content\\\"] == my_annotation[\\\"content\\\"]):\\n\",\n",
      "    \"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\"annotation\\\"], my_annotation[\\\"annotation\\\"])\\n\",\n",
      "    \"        \\n\",\n",
      "    \"        # implement the sum of the temp_num_matches to the num_matches\\n\",\n",
      "    \"        \\n\",\n",
      "    \"    return num_matches, num_non_matches\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"print(compare_annotation_files(reference_annotations, my_annotations))\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 3:\\n\",\n",
      "    \"\\n\",\n",
      "    \"With the numbers now available, try to determine the Cohen's Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\n\",\n",
      "    \"\\n\",\n",
      "    \"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\n\",\n",
      "    \"\\n\",\n",
      "    \"The rest of the formula should be as discussed in class.\\n\",\n",
      "    \"\\n\",\n",
      "    \"Report the numbers you calculate.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 4:\\n\",\n",
      "    \"\\n\",\n",
      "    \"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\n\",\n",
      "    \"    What kind of differences there are between your annotations and the ones I have provided.\\n\",\n",
      "    \"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\n\",\n",
      "    \"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\n\",\n",
      "    \"    A brief explanation of the Cohen's Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 5:\\n\",\n",
      "    \"\\n\",\n",
      "    \"Now you will compare the output of two extractors over a small dataset of news.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"import spacy\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# here we are just using two different spacy models.\\n\",\n",
      "    \"# you will need to ensure that you have both models installed\\n\",\n",
      "    \"model_1 = spacy.load(\\\"en_core_web_sm\\\")\\n\",\n",
      "    \"model_2 = spacy.load(\\\"en_core_web_md\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"from os import listdir\\n\",\n",
      "    \"from os.path import isfile, join\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"dir_base = \\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"\\n\",\n",
      "    \"####\\n\",\n",
      "    \"# Notice: We are reusing code from class notes... remember these kind of building blocks\\n\",\n",
      "    \"####\\n\",\n",
      "    \"\\n\",\n",
      "    \"def read_file(filename):\\n\",\n",
      "    \"    input_file_text = open(filename , encoding='utf-8').read()\\n\",\n",
      "    \"    return input_file_text\\n\",\n",
      "    \"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"def read_directory_files(directory):\\n\",\n",
      "    \"    file_texts = []\\n\",\n",
      "    \"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\n\",\n",
      "    \"    for f in files:\\n\",\n",
      "    \"        file_text = read_file(join(directory, f))\\n\",\n",
      "    \"        print(file_text)\\n\",\n",
      "    \"        file_texts.append({\\\"file\\\":f, \\\"content\\\": file_text })\\n\",\n",
      "    \"    return file_texts\\n\",\n",
      "    \"    \\n\",\n",
      "    \"# here we will generate the list that contains all the files and their contents\\n\",\n",
      "    \"text_corpus = read_directory_files(dir_base)\\n\",\n",
      "    \"print(text_corpus)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# extract entities\\n\",\n",
      "    \"def get_entities(document_text, model):\\n\",\n",
      "    \"    analyzed_doc = model(document_text)\\n\",\n",
      "    \"    # here we are just limiting to a small set of entity types\\n\",\n",
      "    \"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\"PER\\\", \\\"ORG\\\", \\\"LOC\\\", \\\"GPE\\\"]]\\n\",\n",
      "    \"    return entities\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def compare_entities_from_document(reference_entities, test_entities):\\n\",\n",
      "    \"    print(reference_entities)\\n\",\n",
      "    \"    print(test_entities)\\n\",\n",
      "    \"    # here we need to calculate how different the reference and test entity sets are\\n\",\n",
      "    \"    # Since we treat the reference entity set as the ground truth we are trying to find \\n\",\n",
      "    \"    # how many of the same entities are returned in the test entity set\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # So we need to identify the correctly identified entities that are also in the \\n\",\n",
      "    \"    # test entity set and also if entities are not retrieved\\n\",\n",
      "    \"    # we also want to count the number of entities that are in the test entity set that\\n\",\n",
      "    \"    # are not in the reference entity set as well\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # in this case we will only concern ourselves with exact matches of entities\\n\",\n",
      "    \"    # thus, a match is the same portion of text and the same entity type\\n\",\n",
      "    \"    # hint: this is easy if you try to use normal comparisons\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    correct_identified_entities = 0 \\n\",\n",
      "    \"    # count the number of items in the test set \\n\",\n",
      "    \"    # that are also in the reference set\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    correct_unidentified_entities = 0\\n\",\n",
      "    \"    # count the number of items that are in the reference set \\n\",\n",
      "    \"    # that are not in the test set\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    spurious_identified_entites = 0\\n\",\n",
      "    \"    # count the number of items in the test set that are not in \\n\",\n",
      "    \"    # the reference set\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # one way you could do this is to iterate over the test entity list and see if each\\n\",\n",
      "    \"    # item is in the reference entity set\\n\",\n",
      "    \"    # so if an item in the test set is in the reference then you would increment the \\n\",\n",
      "    \"    # correct_identified_entities number\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    ###\\n\",\n",
      "    \"    # Your code goes here\\n\",\n",
      "    \"    ###\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\n\",\n",
      "    \"    \\n\",\n",
      "    \"\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"overall_correct_identified_entities = 0\\n\",\n",
      "    \"overall_correct_unidentified_entities = 0\\n\",\n",
      "    \"overall_spurious_identified_entites = 0\\n\",\n",
      "    \"\\n\",\n",
      "    \"for document in text_corpus:\\n\",\n",
      "    \"    # below you will see that entities_1 is from model_1\\n\",\n",
      "    \"    # you can make a decision about which model output will be the reference output\\n\",\n",
      "    \"    entities_1 = get_entities(document[\\\"content\\\"], model_1)\\n\",\n",
      "    \"    entities_2 = get_entities(document[\\\"content\\\"], model_2)\\n\",\n",
      "    \"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # increment the overall variables\\n\",\n",
      "    \"    \\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# now that you are outside the loop, determine the following values\\n\",\n",
      "    \"precision = # determine which set of numbers above needed to calculate\\n\",\n",
      "    \"recall = # determine which set of numbers above needed to calculate\\n\",\n",
      "    \"\\n\",\n",
      "    \"# what is the overall precision and recall?\\n\",\n",
      "    \"# does this change if you change the reference model?\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 6: \\n\",\n",
      "    \"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren't using a normal evaluation set, feel free to speculate as you wish.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Extra Credit: \\n\",\n",
      "    \"\\n\",\n",
      "    \"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\n\",\n",
      "    \"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\n\",\n",
      "    \"    \"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": []\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.7.2\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 2\n",
      "}\n",
      "\n",
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Homework #3\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I've tagged.\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 1:\\n\",\n",
      "    \"\\n\",\n",
      "    \"Tag data. You'll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\n\",\n",
      "    \"\\n\",\n",
      "    \"Once you've created an account you'll want to create a new dataset. (+ button on the left hand side.)\\n\",\n",
      "    \"Select the Document Annotation option under Text annotations.\\n\",\n",
      "    \"    Provide a dataset name (you can use whatever)\\n\",\n",
      "    \"    for the list of entities just input Person\\n\",\n",
      "    \"    for the tagging instructions provide whatever you would like\\n\",\n",
      "    \"    Then hit submit\\n\",\n",
      "    \"    \\n\",\n",
      "    \"You will then hit the \\\"Upload raw data\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\n\",\n",
      "    \"\\n\",\n",
      "    \"You can then tag each document. Simply highlight the piece of text that you think is a person. When you've identified all of them for a single document hit \\\"move to done\\\". Use the guidelines contained in the next cell.\\n\",\n",
      "    \"\\n\",\n",
      "    \"When you finish tagging all 5 documents, go into the project you've tagged and hit the options button in the top right. You will then hit \\\"download\\\". You will want to have the \\\"complete items\\\" and \\\"json\\\" options selected. Hit download and you will then have a json file for all of your documents.\\n\",\n",
      "    \"\\n\",\n",
      "    \"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Annotation guidelines:\\n\",\n",
      "    \"    These are from the ACE Guidelines for Person:\\n\",\n",
      "    \"    \\n\",\n",
      "    \"3.1 Persons (PER) \\n\",\n",
      "    \"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\n\",\n",
      "    \"\\n\",\n",
      "    \"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\n\",\n",
      "    \"\\n\",\n",
      "    \"Examples: \\n\",\n",
      "    \"He is [a real turkey]\\n\",\n",
      "    \"[The political cat of the year]\\n\",\n",
      "    \"She’s known as [the brain of the family] \"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 2:\\n\",\n",
      "    \"\\n\",\n",
      "    \"Look through the below code.\\n\",\n",
      "    \"\\n\",\n",
      "    \"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\n\",\n",
      "    \"\\n\",\n",
      "    \"Implement the appropriate code to calculate these numbers.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 1,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"[{'content': 'According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\n\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\n\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.',\\n\",\n",
      "       \"  'annotation': [{'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 379, 'end': 386, 'text': 'Blackmon'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 74, 'end': 79, 'text': 'Hardin'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 64, 'end': 71, 'text': 'Blackmon'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 55, 'end': 71, 'text': 'Jonathan Blackmon'}]}],\\n\",\n",
      "       \"  'extras': None,\\n\",\n",
      "       \"  'metadata': {'first_done_at': 1586954510000,\\n\",\n",
      "       \"   'last_updated_at': 1586954510000,\\n\",\n",
      "       \"   'sec_taken': 0,\\n\",\n",
      "       \"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\n\",\n",
      "       \"   'status': 'done',\\n\",\n",
      "       \"   'evaluation': 'CORRECT'}},\\n\",\n",
      "       \" {'content': 'Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\n\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\n\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.',\\n\",\n",
      "       \"  'annotation': [{'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 453, 'end': 460, 'text': 'Morrison'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 79, 'end': 91, 'text': 'Peter O’Neill'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 32, 'end': 39, 'text': 'Morrison'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 26, 'end': 39, 'text': 'Scott Morrison'}]}],\\n\",\n",
      "       \"  'extras': None,\\n\",\n",
      "       \"  'metadata': {'first_done_at': 1586954448000,\\n\",\n",
      "       \"   'last_updated_at': 1586954448000,\\n\",\n",
      "       \"   'sec_taken': 0,\\n\",\n",
      "       \"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\n\",\n",
      "       \"   'status': 'done',\\n\",\n",
      "       \"   'evaluation': 'NONE'}},\\n\",\n",
      "       \" {'content': 'Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\n\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\n\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.',\\n\",\n",
      "       \"  'annotation': [{'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 0, 'end': 10, 'text': 'Joe Montana'}]}],\\n\",\n",
      "       \"  'extras': None,\\n\",\n",
      "       \"  'metadata': {'first_done_at': 1586954477000,\\n\",\n",
      "       \"   'last_updated_at': 1586954477000,\\n\",\n",
      "       \"   'sec_taken': 0,\\n\",\n",
      "       \"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\n\",\n",
      "       \"   'status': 'done',\\n\",\n",
      "       \"   'evaluation': 'NONE'}},\\n\",\n",
      "       \" {'content': 'To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\n\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\n\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.',\\n\",\n",
      "       \"  'annotation': [{'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 816, 'end': 825, 'text': 'John Deere'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 701, 'end': 710, 'text': 'John Deere'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 588, 'end': 594, 'text': 'Merritt'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 576, 'end': 581, 'text': 'Walker'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 532, 'end': 537, 'text': 'Walker'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 501, 'end': 510, 'text': 'John Deere'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 224, 'end': 230, 'text': 'Merritt'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 218, 'end': 229, 'text': 'Piper Merrit'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 183, 'end': 192, 'text': 'John Deere'}]},\\n\",\n",
      "       \"   {'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 25, 'end': 34, 'text': 'John Deere'}]}],\\n\",\n",
      "       \"  'extras': None,\\n\",\n",
      "       \"  'metadata': {'first_done_at': 1586954335000,\\n\",\n",
      "       \"   'last_updated_at': 1586954335000,\\n\",\n",
      "       \"   'sec_taken': 0,\\n\",\n",
      "       \"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\n\",\n",
      "       \"   'status': 'done',\\n\",\n",
      "       \"   'evaluation': 'NONE'}},\\n\",\n",
      "       \" {'content': 'A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.',\\n\",\n",
      "       \"  'annotation': [{'label': ['Person'],\\n\",\n",
      "       \"    'points': [{'start': 44, 'end': 62, 'text': 'George Washington’s'}]}],\\n\",\n",
      "       \"  'extras': None,\\n\",\n",
      "       \"  'metadata': {'first_done_at': 1586954354000,\\n\",\n",
      "       \"   'last_updated_at': 1586954354000,\\n\",\n",
      "       \"   'sec_taken': 0,\\n\",\n",
      "       \"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\n\",\n",
      "       \"   'status': 'done',\\n\",\n",
      "       \"   'evaluation': 'NONE'}}]\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 1,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# import json\\n\",\n",
      "    \"from pprint import pprint\\n\",\n",
      "    \"import json\\n\",\n",
      "    \"\\n\",\n",
      "    \"# method to read annotation file\\n\",\n",
      "    \"def annotation_processor(annotation_file):\\n\",\n",
      "    \"    annotation_array = []\\n\",\n",
      "    \"\\n\",\n",
      "    \"    # here we need to be careful and process each line of the annotation file separately\\n\",\n",
      "    \"    read_annotation = open(annotation_file,encoding='utf8')\\n\",\n",
      "    \"    for line in read_annotation:\\n\",\n",
      "    \"        data = json.loads(line)\\n\",\n",
      "    \"        annotation_array.append(data)\\n\",\n",
      "    \"\\n\",\n",
      "    \"    # here we return an array of the individual annotations\\n\",\n",
      "    \"    return annotation_array\\n\",\n",
      "    \"    \\n\",\n",
      "    \"# calling the annotation processor function\\n\",\n",
      "    \"annotation_processor('Person_entites.json')\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 2,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"#import json\\n\",\n",
      "    \"#person_dict = json.loads('annotated.json')\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 3,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# here we will create two objects to store the reference annotations and your own annotations\\n\",\n",
      "    \"reference_annotations = annotation_processor('Person_entites.json')\\n\",\n",
      "    \"\\n\",\n",
      "    \"# here I am just putting the same file in... if I do this I would expect a perfect match\\n\",\n",
      "    \"my_annotations = annotation_processor('annotated.json')\\n\",\n",
      "    \"\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 4,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"m=my_annotations[:]\\n\",\n",
      "    \"n=reference_annotations[:]\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 5,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# you will primarily focus on implementing this compare_annotations method\\n\",\n",
      "    \"def compare_annotations(m, n):\\n\",\n",
      "    \"    num_matches = 0\\n\",\n",
      "    \"    num_non_matches = 0\\n\",\n",
      "    \"    # you will need to implement this method\\n\",\n",
      "    \"    # The annotations you will get in the parameters are arrays of objects like this:\\n\",\n",
      "    \"    # {'label': ['Person'],\\n\",\n",
      "    \"    # 'points': [{'start': 85,\\n\",\n",
      "    \"    #  'end': 116,\\n\",\n",
      "    \"    #  'text': 'A group of students and teachers'}]}\\n\",\n",
      "    \"    # You will need to compare the annoatations between the reference and your own\\n\",\n",
      "    \"    # You will look to see if you have annotations that match when the start and end values are the same,\\n\",\n",
      "    \"    # that is the character offset is correct\\n\",\n",
      "    \"    for smallm,smalln in zip(m,n):\\n\",\n",
      "    \"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\n\",\n",
      "    \"                if keym==\\\"annotation\\\" and keyn==\\\"annotation\\\":\\n\",\n",
      "    \"                    for vm,vn in zip(valuem,valuen):\\n\",\n",
      "    \"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\n\",\n",
      "    \"                            if vmk==\\\"points\\\" and vnk==\\\"points\\\":\\n\",\n",
      "    \"                                for v1,v2 in zip(vmv,vnv):\\n\",\n",
      "    \"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\n\",\n",
      "    \"                                        #for v11,v22 in zip(vv1,vv2):\\n\",\n",
      "    \"                                        if vv1==vv2:\\n\",\n",
      "    \"                                            num_matches = num_matches +1 \\n\",\n",
      "    \"                                        elif vv1!=vv2:\\n\",\n",
      "    \"                                            num_non_matches=num_non_matches+1\\n\",\n",
      "    \"    print(\\\"success\\\")\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    return num_matches, num_non_matches\\n\",\n",
      "    \"    \\n\",\n",
      "    \"\\n\",\n",
      "    \"def compare_annotation_files(mm, nn):\\n\",\n",
      "    \"    m1,n1=compare_annotations(mm,nn)\\n\",\n",
      "    \"    return m1,n1\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 6,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"success\\n\",\n",
      "      \"(23, 37)\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"m=my_annotations[:]\\n\",\n",
      "    \"n=reference_annotations[:]\\n\",\n",
      "    \"print(compare_annotation_files(m, n))\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 7,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"success\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"val1,val2=compare_annotation_files(reference_annotations, my_annotations)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 8,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"23\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 8,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"val1\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 9,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"37\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 9,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"val2\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 3:\\n\",\n",
      "    \"\\n\",\n",
      "    \"With the numbers now available, try to determine the Cohen's Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\n\",\n",
      "    \"\\n\",\n",
      "    \"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\n\",\n",
      "    \"\\n\",\n",
      "    \"The rest of the formula should be as discussed in class.\\n\",\n",
      "    \"\\n\",\n",
      "    \"Report the numbers you calculate.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"## Cohen Kappa calculation: \\n\",\n",
      "    \"        - number of matches:val1: 23\\n\",\n",
      "    \"        - number of non matches: val2: 37\\n\",\n",
      "    \"        - probability of random agreement: 0.3.\\n\",\n",
      "    \"        \\n\",\n",
      "    \"## Calculations:\\n\",\n",
      "    \"    - Observed Values: 23/60= 0.38\\n\",\n",
      "    \"    - Kappa: (0.38-0.3)/(1-0.3)\\n\",\n",
      "    \"    - Kappa: 0.11\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 4:\\n\",\n",
      "    \"\\n\",\n",
      "    \"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\n\",\n",
      "    \"    What kind of differences there are between your annotations and the ones I have provided.\\n\",\n",
      "    \"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\n\",\n",
      "    \"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\n\",\n",
      "    \"    A brief explanation of the Cohen's Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 5:\\n\",\n",
      "    \"\\n\",\n",
      "    \"Now you will compare the output of two extractors over a small dataset of news.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 10,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"import spacy\\n\",\n",
      "    \"import os\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 11,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# here we are just using two different spacy models.\\n\",\n",
      "    \"# you will need to ensure that you have both models installed\\n\",\n",
      "    \"model_1 = spacy.load(\\\"en_core_web_sm\\\")\\n\",\n",
      "    \"model_2 = spacy.load(\\\"en_core_web_md\\\")\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 17,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"from os import listdir\\n\",\n",
      "    \"from os.path import isfile, join\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 18,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"'C:\\\\\\\\Users\\\\\\\\user\\\\\\\\NLP_HW\\\\\\\\HW3'\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 18,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"os.getcwd()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 19,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"dir_base = os.getcwd()\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 20,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"{\\\"content\\\": \\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\n\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\n\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":379,\\\"end\\\":386,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":293,\\\"end\\\":296,\\\"text\\\":\\\"Irma\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":267,\\\"end\\\":272,\\\"text\\\":\\\"Harvey\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":74,\\\"end\\\":79,\\\"text\\\":\\\"Hardin\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":64,\\\"end\\\":71,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":42,\\\"end\\\":71,\\\"text\\\":\\\"Chief Deputy Jonathan Blackmon\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085438000,\\\"last_updated_at\\\":1541085438000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"{\\\"content\\\": \\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\n\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\n\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":453,\\\"end\\\":460,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":315,\\\"end\\\":325,\\\"text\\\":\\\"the leaders\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":80,\\\"end\\\":91,\\\"text\\\":\\\"eter O’Neill\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":32,\\\"end\\\":39,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":26,\\\"end\\\":39,\\\"text\\\":\\\"Scott Morrison\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085568000,\\\"last_updated_at\\\":1541085568000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"{\\\"content\\\": \\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\n\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\n\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":416,\\\"end\\\":420,\\\"text\\\":\\\"Clark\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":269,\\\"end\\\":275,\\\"text\\\":\\\"Montana\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":245,\\\"end\\\":259,\\\"text\\\":\\\"the quarterback\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":40,\\\"end\\\":44,\\\"text\\\":\\\"Clark\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":33,\\\"end\\\":44,\\\"text\\\":\\\"Dwight Clark\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":4,\\\"end\\\":10,\\\"text\\\":\\\"Montana\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":0,\\\"end\\\":10,\\\"text\\\":\\\"Joe Montana\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085542000,\\\"last_updated_at\\\":1541085542000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"{\\\"content\\\": \\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\n\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\n\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":816,\\\"end\\\":825,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":701,\\\"end\\\":710,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":588,\\\"end\\\":594,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":576,\\\"end\\\":581,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":532,\\\"end\\\":537,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":527,\\\"end\\\":537,\\\"text\\\":\\\"Doug Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":501,\\\"end\\\":510,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":224,\\\"end\\\":230,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":218,\\\"end\\\":231,\\\"text\\\":\\\"Piper Merritt,\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":183,\\\"end\\\":192,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":25,\\\"end\\\":34,\\\"text\\\":\\\"John Deere\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085478000,\\\"last_updated_at\\\":1541085478000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"{\\\"content\\\": \\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":85,\\\"end\\\":116,\\\"text\\\":\\\"A group of students and teachers\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":44,\\\"end\\\":60,\\\"text\\\":\\\"George Washington\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085505000,\\\"last_updated_at\\\":1541085505000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"\\n\",\n",
      "      \"{\\n\",\n",
      "      \" \\\"cells\\\": [\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# Homework #3\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I've tagged.\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 1:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Tag data. You'll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Once you've created an account you'll want to create a new dataset. (+ button on the left hand side.)\\\\n\\\",\\n\",\n",
      "      \"    \\\"Select the Document Annotation option under Text annotations.\\\\n\\\",\\n\",\n",
      "      \"    \\\"    Provide a dataset name (you can use whatever)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for the list of entities just input Person\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for the tagging instructions provide whatever you would like\\\\n\\\",\\n\",\n",
      "      \"    \\\"    Then hit submit\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"You will then hit the \\\\\\\"Upload raw data\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you've identified all of them for a single document hit \\\\\\\"move to done\\\\\\\". Use the guidelines contained in the next cell.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"When you finish tagging all 5 documents, go into the project you've tagged and hit the options button in the top right. You will then hit \\\\\\\"download\\\\\\\". You will want to have the \\\\\\\"complete items\\\\\\\" and \\\\\\\"json\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Annotation guidelines:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    These are from the ACE Guidelines for Person:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"3.1 Persons (PER) \\\\n\\\",\\n\",\n",
      "      \"    \\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Examples: \\\\n\\\",\\n\",\n",
      "      \"    \\\"He is [a real turkey]\\\\n\\\",\\n\",\n",
      "      \"    \\\"[The political cat of the year]\\\\n\\\",\\n\",\n",
      "      \"    \\\"She’s known as [the brain of the family] \\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 2:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Look through the below code.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Implement the appropriate code to calculate these numbers.\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# import json\\\\n\\\",\\n\",\n",
      "      \"    \\\"from pprint import pprint\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"# method to read annotation file\\\\n\\\",\\n\",\n",
      "      \"    \\\"def annotation_processor(annotation_file):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    annotation_array = []\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # here we need to be careful and process each line of the annotation file separately\\\\n\\\",\\n\",\n",
      "      \"    \\\"    read_annotation = open(annotation_file)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for line in read_annotation:\\\\n\\\",\\n\",\n",
      "      \"    \\\"        data = json.loads(line)\\\\n\\\",\\n\",\n",
      "      \"    \\\"        annotation_array.append(data)\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # here we return an array of the individual annotations\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return annotation_array\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"# calling the annotation processor function\\\\n\\\",\\n\",\n",
      "      \"    \\\"annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# here we will create two objects to store the reference annotations and your own annotations\\\\n\\\",\\n\",\n",
      "      \"    \\\"reference_annotations = annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\n\\\",\\n\",\n",
      "      \"    \\\"my_annotations = annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# you will primarily focus on implementing this compare_annotations method\\\\n\\\",\\n\",\n",
      "      \"    \\\"def compare_annotations(reference_annotations, my_annotations):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_non_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # you will need to implement this method\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # 'points': [{'start': 85,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #  'end': 116,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #  'text': 'A group of students and teachers'}]}\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # You will need to compare the annoatations between the reference and your own\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # that is the character offset is correct\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    print(\\\\\\\"success\\\\\\\")\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    return num_matches, num_non_matches\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_annotations_in_reference = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_annotations_in_mine = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # we want this method to calculate these two numbers\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # num_matches should simply count all the cases where we \\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_non_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_partial_match = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    for annotation in reference_annotation_array:\\\\n\\\",\\n\",\n",
      "      \"    \\\"        for my_annotation in my_annotation_array:\\\\n\\\",\\n\",\n",
      "      \"    \\\"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\n\\\",\\n\",\n",
      "      \"    \\\"            if (annotation[\\\\\\\"content\\\\\\\"] == my_annotation[\\\\\\\"content\\\\\\\"]):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\\\"annotation\\\\\\\"], my_annotation[\\\\\\\"annotation\\\\\\\"])\\\\n\\\",\\n\",\n",
      "      \"    \\\"        \\\\n\\\",\\n\",\n",
      "      \"    \\\"        # implement the sum of the temp_num_matches to the num_matches\\\\n\\\",\\n\",\n",
      "      \"    \\\"        \\\\n\\\",\\n\",\n",
      "      \"    \\\"    return num_matches, num_non_matches\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"print(compare_annotation_files(reference_annotations, my_annotations))\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 3:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"With the numbers now available, try to determine the Cohen's Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"The rest of the formula should be as discussed in class.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Report the numbers you calculate.\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 4:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\n\\\",\\n\",\n",
      "      \"    \\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\n\\\",\\n\",\n",
      "      \"    \\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\n\\\",\\n\",\n",
      "      \"    \\\"    A brief explanation of the Cohen's Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 5:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Now you will compare the output of two extractors over a small dataset of news.\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"import spacy\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# here we are just using two different spacy models.\\\\n\\\",\\n\",\n",
      "      \"    \\\"# you will need to ensure that you have both models installed\\\\n\\\",\\n\",\n",
      "      \"    \\\"model_1 = spacy.load(\\\\\\\"en_core_web_sm\\\\\\\")\\\\n\\\",\\n\",\n",
      "      \"    \\\"model_2 = spacy.load(\\\\\\\"en_core_web_md\\\\\\\")\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"from os import listdir\\\\n\\\",\\n\",\n",
      "      \"    \\\"from os.path import isfile, join\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"dir_base = \\\\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"####\\\\n\\\",\\n\",\n",
      "      \"    \\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\n\\\",\\n\",\n",
      "      \"    \\\"####\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"def read_file(filename):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    input_file_text = open(filename , encoding='utf-8').read()\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return input_file_text\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"def read_directory_files(directory):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    file_texts = []\\\\n\\\",\\n\",\n",
      "      \"    \\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for f in files:\\\\n\\\",\\n\",\n",
      "      \"    \\\"        file_text = read_file(join(directory, f))\\\\n\\\",\\n\",\n",
      "      \"    \\\"        print(file_text)\\\\n\\\",\\n\",\n",
      "      \"    \\\"        file_texts.append({\\\\\\\"file\\\\\\\":f, \\\\\\\"content\\\\\\\": file_text })\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return file_texts\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"# here we will generate the list that contains all the files and their contents\\\\n\\\",\\n\",\n",
      "      \"    \\\"text_corpus = read_directory_files(dir_base)\\\\n\\\",\\n\",\n",
      "      \"    \\\"print(text_corpus)\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# extract entities\\\\n\\\",\\n\",\n",
      "      \"    \\\"def get_entities(document_text, model):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    analyzed_doc = model(document_text)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # here we are just limiting to a small set of entity types\\\\n\\\",\\n\",\n",
      "      \"    \\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\"PER\\\\\\\", \\\\\\\"ORG\\\\\\\", \\\\\\\"LOC\\\\\\\", \\\\\\\"GPE\\\\\\\"]]\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return entities\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"def compare_entities_from_document(reference_entities, test_entities):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    print(reference_entities)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    print(test_entities)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # here we need to calculate how different the reference and test entity sets are\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # how many of the same entities are returned in the test entity set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # So we need to identify the correctly identified entities that are also in the \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # test entity set and also if entities are not retrieved\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # we also want to count the number of entities that are in the test entity set that\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # are not in the reference entity set as well\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # in this case we will only concern ourselves with exact matches of entities\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # thus, a match is the same portion of text and the same entity type\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # hint: this is easy if you try to use normal comparisons\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    correct_identified_entities = 0 \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # count the number of items in the test set \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # that are also in the reference set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    correct_unidentified_entities = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # count the number of items that are in the reference set \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # that are not in the test set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    spurious_identified_entites = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # count the number of items in the test set that are not in \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # the reference set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # item is in the reference entity set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # so if an item in the test set is in the reference then you would increment the \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # correct_identified_entities number\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    ###\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # Your code goes here\\\\n\\\",\\n\",\n",
      "      \"    \\\"    ###\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"overall_correct_identified_entities = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"overall_correct_unidentified_entities = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"overall_spurious_identified_entites = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"for document in text_corpus:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # below you will see that entities_1 is from model_1\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # you can make a decision about which model output will be the reference output\\\\n\\\",\\n\",\n",
      "      \"    \\\"    entities_1 = get_entities(document[\\\\\\\"content\\\\\\\"], model_1)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    entities_2 = get_entities(document[\\\\\\\"content\\\\\\\"], model_2)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # increment the overall variables\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# now that you are outside the loop, determine the following values\\\\n\\\",\\n\",\n",
      "      \"    \\\"precision = # determine which set of numbers above needed to calculate\\\\n\\\",\\n\",\n",
      "      \"    \\\"recall = # determine which set of numbers above needed to calculate\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"# what is the overall precision and recall?\\\\n\\\",\\n\",\n",
      "      \"    \\\"# does this change if you change the reference model?\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 6: \\\\n\\\",\\n\",\n",
      "      \"    \\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren't using a normal evaluation set, feel free to speculate as you wish.\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Extra Credit: \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\n\\\",\\n\",\n",
      "      \"    \\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": []\\n\",\n",
      "      \"  }\\n\",\n",
      "      \" ],\\n\",\n",
      "      \" \\\"metadata\\\": {\\n\",\n",
      "      \"  \\\"kernelspec\\\": {\\n\",\n",
      "      \"   \\\"display_name\\\": \\\"Python 3\\\",\\n\",\n",
      "      \"   \\\"language\\\": \\\"python\\\",\\n\",\n",
      "      \"   \\\"name\\\": \\\"python3\\\"\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  \\\"language_info\\\": {\\n\",\n",
      "      \"   \\\"codemirror_mode\\\": {\\n\",\n",
      "      \"    \\\"name\\\": \\\"ipython\\\",\\n\",\n",
      "      \"    \\\"version\\\": 3\\n\",\n",
      "      \"   },\\n\",\n",
      "      \"   \\\"file_extension\\\": \\\".py\\\",\\n\",\n",
      "      \"   \\\"mimetype\\\": \\\"text/x-python\\\",\\n\",\n",
      "      \"   \\\"name\\\": \\\"python\\\",\\n\",\n",
      "      \"   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n\",\n",
      "      \"   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n\",\n",
      "      \"   \\\"version\\\": \\\"3.7.2\\\"\\n\",\n",
      "      \"  }\\n\",\n",
      "      \" },\\n\",\n",
      "      \" \\\"nbformat\\\": 4,\\n\",\n",
      "      \" \\\"nbformat_minor\\\": 2\\n\",\n",
      "      \"}\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"\\n\",\n",
      "      \"{\\n\",\n",
      "      \" \\\"cells\\\": [\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# Homework #3\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I've tagged.\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 1:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Tag data. You'll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Once you've created an account you'll want to create a new dataset. (+ button on the left hand side.)\\\\n\\\",\\n\",\n",
      "      \"    \\\"Select the Document Annotation option under Text annotations.\\\\n\\\",\\n\",\n",
      "      \"    \\\"    Provide a dataset name (you can use whatever)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for the list of entities just input Person\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for the tagging instructions provide whatever you would like\\\\n\\\",\\n\",\n",
      "      \"    \\\"    Then hit submit\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"You will then hit the \\\\\\\"Upload raw data\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you've identified all of them for a single document hit \\\\\\\"move to done\\\\\\\". Use the guidelines contained in the next cell.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"When you finish tagging all 5 documents, go into the project you've tagged and hit the options button in the top right. You will then hit \\\\\\\"download\\\\\\\". You will want to have the \\\\\\\"complete items\\\\\\\" and \\\\\\\"json\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Annotation guidelines:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    These are from the ACE Guidelines for Person:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"3.1 Persons (PER) \\\\n\\\",\\n\",\n",
      "      \"    \\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Examples: \\\\n\\\",\\n\",\n",
      "      \"    \\\"He is [a real turkey]\\\\n\\\",\\n\",\n",
      "      \"    \\\"[The political cat of the year]\\\\n\\\",\\n\",\n",
      "      \"    \\\"She’s known as [the brain of the family] \\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 2:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Look through the below code.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Implement the appropriate code to calculate these numbers.\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 24,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"data\\\": {\\n\",\n",
      "      \"      \\\"text/plain\\\": [\\n\",\n",
      "      \"       \\\"[{'content': 'According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\n\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\n\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.',\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'annotation': [{'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 379, 'end': 386, 'text': 'Blackmon'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 74, 'end': 79, 'text': 'Hardin'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 64, 'end': 71, 'text': 'Blackmon'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 55, 'end': 71, 'text': 'Jonathan Blackmon'}]}],\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'extras': None,\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'metadata': {'first_done_at': 1586954510000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_at': 1586954510000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'sec_taken': 0,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'status': 'done',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'evaluation': 'CORRECT'}},\\\\n\\\",\\n\",\n",
      "      \"       \\\" {'content': 'Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\n\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\n\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.',\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'annotation': [{'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 453, 'end': 460, 'text': 'Morrison'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 79, 'end': 91, 'text': 'Peter O’Neill'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 32, 'end': 39, 'text': 'Morrison'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 26, 'end': 39, 'text': 'Scott Morrison'}]}],\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'extras': None,\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'metadata': {'first_done_at': 1586954448000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_at': 1586954448000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'sec_taken': 0,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'status': 'done',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'evaluation': 'NONE'}},\\\\n\\\",\\n\",\n",
      "      \"       \\\" {'content': 'Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\n\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\n\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.',\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'annotation': [{'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 0, 'end': 10, 'text': 'Joe Montana'}]}],\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'extras': None,\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'metadata': {'first_done_at': 1586954477000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_at': 1586954477000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'sec_taken': 0,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'status': 'done',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'evaluation': 'NONE'}},\\\\n\\\",\\n\",\n",
      "      \"       \\\" {'content': 'To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\n\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.',\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'annotation': [{'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 816, 'end': 825, 'text': 'John Deere'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 701, 'end': 710, 'text': 'John Deere'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 588, 'end': 594, 'text': 'Merritt'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 576, 'end': 581, 'text': 'Walker'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 532, 'end': 537, 'text': 'Walker'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 501, 'end': 510, 'text': 'John Deere'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 224, 'end': 230, 'text': 'Merritt'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 218, 'end': 229, 'text': 'Piper Merrit'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 183, 'end': 192, 'text': 'John Deere'}]},\\\\n\\\",\\n\",\n",
      "      \"       \\\"   {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 25, 'end': 34, 'text': 'John Deere'}]}],\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'extras': None,\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'metadata': {'first_done_at': 1586954335000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_at': 1586954335000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'sec_taken': 0,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'status': 'done',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'evaluation': 'NONE'}},\\\\n\\\",\\n\",\n",
      "      \"       \\\" {'content': 'A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.',\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'annotation': [{'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"       \\\"    'points': [{'start': 44, 'end': 62, 'text': 'George Washington’s'}]}],\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'extras': None,\\\\n\\\",\\n\",\n",
      "      \"       \\\"  'metadata': {'first_done_at': 1586954354000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_at': 1586954354000,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'sec_taken': 0,\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'last_updated_by': 'GAUua4TByDWq4pqf203jFtL8DoL2',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'status': 'done',\\\\n\\\",\\n\",\n",
      "      \"       \\\"   'evaluation': 'NONE'}}]\\\"\\n\",\n",
      "      \"      ]\\n\",\n",
      "      \"     },\\n\",\n",
      "      \"     \\\"execution_count\\\": 24,\\n\",\n",
      "      \"     \\\"metadata\\\": {},\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"execute_result\\\"\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# import json\\\\n\\\",\\n\",\n",
      "      \"    \\\"from pprint import pprint\\\\n\\\",\\n\",\n",
      "      \"    \\\"import json\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"# method to read annotation file\\\\n\\\",\\n\",\n",
      "      \"    \\\"def annotation_processor(annotation_file):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    annotation_array = []\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # here we need to be careful and process each line of the annotation file separately\\\\n\\\",\\n\",\n",
      "      \"    \\\"    read_annotation = open(annotation_file,encoding='utf8')\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for line in read_annotation:\\\\n\\\",\\n\",\n",
      "      \"    \\\"        data = json.loads(line)\\\\n\\\",\\n\",\n",
      "      \"    \\\"        annotation_array.append(data)\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # here we return an array of the individual annotations\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return annotation_array\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"# calling the annotation processor function\\\\n\\\",\\n\",\n",
      "      \"    \\\"annotation_processor('Person_entites.json')\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 25,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"#import json\\\\n\\\",\\n\",\n",
      "      \"    \\\"#person_dict = json.loads('annotated.json')\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 26,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# here we will create two objects to store the reference annotations and your own annotations\\\\n\\\",\\n\",\n",
      "      \"    \\\"reference_annotations = annotation_processor('Person_entites.json')\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\n\\\",\\n\",\n",
      "      \"    \\\"my_annotations = annotation_processor('annotated.json')\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 27,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"m=my_annotations[:]\\\\n\\\",\\n\",\n",
      "      \"    \\\"n=reference_annotations[:]\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 28,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"num_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"num_non_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # you will need to implement this method\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # 'points': [{'start': 85,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #  'end': 116,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #  'text': 'A group of students and teachers'}]}\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # You will need to compare the annoatations between the reference and your own\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # that is the character offset is correct\\\\n\\\",\\n\",\n",
      "      \"    \\\"for smallm,smalln in zip(m,n):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\n\\\",\\n\",\n",
      "      \"    \\\"            if keym==\\\\\\\"annotation\\\\\\\" and keyn==\\\\\\\"annotation\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"                for vm,vn in zip(valuem,valuen):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                    for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                        if vmk==\\\\\\\"points\\\\\\\" and vnk==\\\\\\\"points\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"                            for v1,v2 in zip(vmv,vnv):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                    #for v11,v22 in zip(vv1,vv2):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                    if vv1==vv2:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                        num_matches = num_matches +1 \\\\n\\\",\\n\",\n",
      "      \"    \\\"                                    elif vv1!=vv2:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                        num_non_matches=num_non_matches+1\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 29,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"23\\\\n\\\",\\n\",\n",
      "      \"      \\\"37\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"print(num_matches)\\\\n\\\",\\n\",\n",
      "      \"    \\\"print(num_non_matches)\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 30,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 379\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 386\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Blackmon\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 293\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 296\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Irma\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 267\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 272\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Harvey\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 74\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 79\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Hardin\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 64\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 71\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Blackmon\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 42\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 71\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Chief Deputy Jonathan Blackmon\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 453\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 460\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Morrison\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 315\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 325\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value the leaders\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 80\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 91\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value eter O’Neill\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 32\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 39\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Morrison\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 26\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 39\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Scott Morrison\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 416\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 420\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Clark\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 269\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 275\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Montana\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 245\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 259\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value the quarterback\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 40\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 44\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Clark\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 33\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 44\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Dwight Clark\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 4\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 10\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Montana\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 0\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 10\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Joe Montana\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 816\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 825\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value John Deere\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 701\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 710\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value John Deere\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 588\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 594\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Merritt\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 576\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 581\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Walker\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 532\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 537\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Walker\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 527\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 537\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Doug Walker\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 501\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 510\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value John Deere\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 224\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 230\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Merritt\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 218\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 231\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value Piper Merritt,\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 183\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 192\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value John Deere\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 25\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 34\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value John Deere\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 85\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 116\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value A group of students and teachers\\\\n\\\",\\n\",\n",
      "      \"      \\\"********\\\\n\\\",\\n\",\n",
      "      \"      \\\"tag Person\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys start\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 44\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys end\\\\n\\\",\\n\",\n",
      "      \"      \\\"value 60\\\\n\\\",\\n\",\n",
      "      \"      \\\"keys text\\\\n\\\",\\n\",\n",
      "      \"      \\\"value George Washington\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"#final checking function- done- works!!!\\\\n\\\",\\n\",\n",
      "      \"    \\\"m=my_annotations[0:5]\\\\n\\\",\\n\",\n",
      "      \"    \\\"for small in m:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for key,value in small.items():\\\\n\\\",\\n\",\n",
      "      \"    \\\"        if key==\\\\\\\"annotation\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"            for v in value:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                print(\\\\\\\"********\\\\\\\")\\\\n\\\",\\n\",\n",
      "      \"    \\\"                for vk,vv in v.items():\\\\n\\\",\\n\",\n",
      "      \"    \\\"                    if vk==\\\\\\\"label\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"                        for vvl in vv:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                            print(\\\\\\\"tag\\\\\\\",vvl)\\\\n\\\",\\n\",\n",
      "      \"    \\\"                    if vk==\\\\\\\"points\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"                        for vvl in vv:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                            for vvlk,vvlv in vvl.items():\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                print(\\\\\\\"keys\\\\\\\",vvlk)\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                print(\\\\\\\"value\\\\\\\",vvlv)\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 31,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# you will primarily focus on implementing this compare_annotations method\\\\n\\\",\\n\",\n",
      "      \"    \\\"def compare_annotations(m, n):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_non_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # you will need to implement this method\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # 'points': [{'start': 85,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #  'end': 116,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #  'text': 'A group of students and teachers'}]}\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # You will need to compare the annoatations between the reference and your own\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # that is the character offset is correct\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for smallm,smalln in zip(m,n):\\\\n\\\",\\n\",\n",
      "      \"    \\\"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\n\\\",\\n\",\n",
      "      \"    \\\"                if keym==\\\\\\\"annotation\\\\\\\" and keyn==\\\\\\\"annotation\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"                    for vm,vn in zip(valuem,valuen):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                            if vmk==\\\\\\\"points\\\\\\\" and vnk==\\\\\\\"points\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                for v1,v2 in zip(vmv,vnv):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                        #for v11,v22 in zip(vv1,vv2):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                        if vv1==vv2:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                            num_matches = num_matches +1 \\\\n\\\",\\n\",\n",
      "      \"    \\\"                                        elif vv1!=vv2:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                            num_non_matches=num_non_matches+1\\\\n\\\",\\n\",\n",
      "      \"    \\\"    print(\\\\\\\"success\\\\\\\")\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    return num_matches, num_non_matches\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 32,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"success\\\\n\\\",\\n\",\n",
      "      \"      \\\"(23, 37)\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"print(compare_annotations(m,n))\\\\n\\\",\\n\",\n",
      "      \"    \\\"#print(m1)\\\\n\\\",\\n\",\n",
      "      \"    \\\"#print(n1)\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 33,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# you will primarily focus on implementing this compare_annotations method\\\\n\\\",\\n\",\n",
      "      \"    \\\"def compare_annotations(m, n):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    num_non_matches = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # you will need to implement this method\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # {'label': ['Person'],\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # 'points': [{'start': 85,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #  'end': 116,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #  'text': 'A group of students and teachers'}]}\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # You will need to compare the annoatations between the reference and your own\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # that is the character offset is correct\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for smallm,smalln in zip(m,n):\\\\n\\\",\\n\",\n",
      "      \"    \\\"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\n\\\",\\n\",\n",
      "      \"    \\\"                if keym==\\\\\\\"annotation\\\\\\\" and keyn==\\\\\\\"annotation\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"                    for vm,vn in zip(valuem,valuen):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                            if vmk==\\\\\\\"points\\\\\\\" and vnk==\\\\\\\"points\\\\\\\":\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                for v1,v2 in zip(vmv,vnv):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                        #for v11,v22 in zip(vv1,vv2):\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                        if vv1==vv2:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                            num_matches = num_matches +1 \\\\n\\\",\\n\",\n",
      "      \"    \\\"                                        elif vv1!=vv2:\\\\n\\\",\\n\",\n",
      "      \"    \\\"                                            num_non_matches=num_non_matches+1\\\\n\\\",\\n\",\n",
      "      \"    \\\"    print(\\\\\\\"success\\\\\\\")\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    return num_matches, num_non_matches\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"def compare_annotation_files(mm, nn):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    m1,n1=compare_annotations(mm,nn)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return m1,n1\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 34,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"success\\\\n\\\",\\n\",\n",
      "      \"      \\\"(23, 37)\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"m=my_annotations[:]\\\\n\\\",\\n\",\n",
      "      \"    \\\"n=reference_annotations[:]\\\\n\\\",\\n\",\n",
      "      \"    \\\"print(compare_annotation_files(m, n))\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 35,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"success\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"val1,val2=compare_annotation_files(reference_annotations, my_annotations)\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 36,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"data\\\": {\\n\",\n",
      "      \"      \\\"text/plain\\\": [\\n\",\n",
      "      \"       \\\"23\\\"\\n\",\n",
      "      \"      ]\\n\",\n",
      "      \"     },\\n\",\n",
      "      \"     \\\"execution_count\\\": 36,\\n\",\n",
      "      \"     \\\"metadata\\\": {},\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"execute_result\\\"\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"val1\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 37,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"data\\\": {\\n\",\n",
      "      \"      \\\"text/plain\\\": [\\n\",\n",
      "      \"       \\\"37\\\"\\n\",\n",
      "      \"      ]\\n\",\n",
      "      \"     },\\n\",\n",
      "      \"     \\\"execution_count\\\": 37,\\n\",\n",
      "      \"     \\\"metadata\\\": {},\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"execute_result\\\"\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"val2\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 3:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"With the numbers now available, try to determine the Cohen's Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"The rest of the formula should be as discussed in class.\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Report the numbers you calculate.\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 4:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\n\\\",\\n\",\n",
      "      \"    \\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\n\\\",\\n\",\n",
      "      \"    \\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\n\\\",\\n\",\n",
      "      \"    \\\"    A brief explanation of the Cohen's Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 5:\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"Now you will compare the output of two extractors over a small dataset of news.\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 38,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"import spacy\\\\n\\\",\\n\",\n",
      "      \"    \\\"import os\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 39,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# here we are just using two different spacy models.\\\\n\\\",\\n\",\n",
      "      \"    \\\"# you will need to ensure that you have both models installed\\\\n\\\",\\n\",\n",
      "      \"    \\\"model_1 = spacy.load(\\\\\\\"en_core_web_sm\\\\\\\")\\\\n\\\",\\n\",\n",
      "      \"    \\\"model_2 = spacy.load(\\\\\\\"en_core_web_md\\\\\\\")\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 40,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"from os import listdir\\\\n\\\",\\n\",\n",
      "      \"    \\\"from os.path import isfile, join\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 41,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"data\\\": {\\n\",\n",
      "      \"      \\\"text/plain\\\": [\\n\",\n",
      "      \"       \\\"'C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\user\\\\\\\\\\\\\\\\NLP_HW\\\\\\\\\\\\\\\\HW3'\\\"\\n\",\n",
      "      \"      ]\\n\",\n",
      "      \"     },\\n\",\n",
      "      \"     \\\"execution_count\\\": 41,\\n\",\n",
      "      \"     \\\"metadata\\\": {},\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"execute_result\\\"\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"os.getcwd()\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 42,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"dir_base = os.getcwd()\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 43,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\n\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\n\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":379,\\\\\\\"end\\\\\\\":386,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":293,\\\\\\\"end\\\\\\\":296,\\\\\\\"text\\\\\\\":\\\\\\\"Irma\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":267,\\\\\\\"end\\\\\\\":272,\\\\\\\"text\\\\\\\":\\\\\\\"Harvey\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":74,\\\\\\\"end\\\\\\\":79,\\\\\\\"text\\\\\\\":\\\\\\\"Hardin\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":64,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":42,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Chief Deputy Jonathan Blackmon\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1541085438000,\\\\\\\"last_updated_at\\\\\\\":1541085438000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\n\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\n\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":453,\\\\\\\"end\\\\\\\":460,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":315,\\\\\\\"end\\\\\\\":325,\\\\\\\"text\\\\\\\":\\\\\\\"the leaders\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":80,\\\\\\\"end\\\\\\\":91,\\\\\\\"text\\\\\\\":\\\\\\\"eter O’Neill\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":32,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":26,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Scott Morrison\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1541085568000,\\\\\\\"last_updated_at\\\\\\\":1541085568000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\n\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\n\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":416,\\\\\\\"end\\\\\\\":420,\\\\\\\"text\\\\\\\":\\\\\\\"Clark\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":269,\\\\\\\"end\\\\\\\":275,\\\\\\\"text\\\\\\\":\\\\\\\"Montana\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":245,\\\\\\\"end\\\\\\\":259,\\\\\\\"text\\\\\\\":\\\\\\\"the quarterback\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":40,\\\\\\\"end\\\\\\\":44,\\\\\\\"text\\\\\\\":\\\\\\\"Clark\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":33,\\\\\\\"end\\\\\\\":44,\\\\\\\"text\\\\\\\":\\\\\\\"Dwight Clark\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":4,\\\\\\\"end\\\\\\\":10,\\\\\\\"text\\\\\\\":\\\\\\\"Montana\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":0,\\\\\\\"end\\\\\\\":10,\\\\\\\"text\\\\\\\":\\\\\\\"Joe Montana\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1541085542000,\\\\\\\"last_updated_at\\\\\\\":1541085542000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\n\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":816,\\\\\\\"end\\\\\\\":825,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":701,\\\\\\\"end\\\\\\\":710,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":588,\\\\\\\"end\\\\\\\":594,\\\\\\\"text\\\\\\\":\\\\\\\"Merritt\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":576,\\\\\\\"end\\\\\\\":581,\\\\\\\"text\\\\\\\":\\\\\\\"Walker\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":532,\\\\\\\"end\\\\\\\":537,\\\\\\\"text\\\\\\\":\\\\\\\"Walker\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":527,\\\\\\\"end\\\\\\\":537,\\\\\\\"text\\\\\\\":\\\\\\\"Doug Walker\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":501,\\\\\\\"end\\\\\\\":510,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":224,\\\\\\\"end\\\\\\\":230,\\\\\\\"text\\\\\\\":\\\\\\\"Merritt\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":218,\\\\\\\"end\\\\\\\":231,\\\\\\\"text\\\\\\\":\\\\\\\"Piper Merritt,\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":183,\\\\\\\"end\\\\\\\":192,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":25,\\\\\\\"end\\\\\\\":34,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1541085478000,\\\\\\\"last_updated_at\\\\\\\":1541085478000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":85,\\\\\\\"end\\\\\\\":116,\\\\\\\"text\\\\\\\":\\\\\\\"A group of students and teachers\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":44,\\\\\\\"end\\\\\\\":60,\\\\\\\"text\\\\\\\":\\\\\\\"George Washington\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1541085505000,\\\\\\\"last_updated_at\\\\\\\":1541085505000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\n\\\",\\n\",\n",
      "      \"      \\\" \\\\\\\"cells\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# Homework #3\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I've tagged.\\\\\\\\n\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Step 1:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Tag data. You'll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Once you've created an account you'll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Select the Document Annotation option under Text annotations.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    Provide a dataset name (you can use whatever)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    for the list of entities just input Person\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    for the tagging instructions provide whatever you would like\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    Then hit submit\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"You will then hit the \\\\\\\\\\\\\\\"Upload raw data\\\\\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you've identified all of them for a single document hit \\\\\\\\\\\\\\\"move to done\\\\\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"When you finish tagging all 5 documents, go into the project you've tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\\\\\"download\\\\\\\\\\\\\\\". You will want to have the \\\\\\\\\\\\\\\"complete items\\\\\\\\\\\\\\\" and \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\n\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Annotation guidelines:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    These are from the ACE Guidelines for Person:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"3.1 Persons (PER) \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Examples: \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"He is [a real turkey]\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"[The political cat of the year]\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"She’s known as [the brain of the family] \\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Step 2:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Look through the below code.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Implement the appropriate code to calculate these numbers.\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# import json\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"from pprint import pprint\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# method to read annotation file\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"def annotation_processor(annotation_file):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    annotation_array = []\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    read_annotation = open(annotation_file)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    for line in read_annotation:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        data = json.loads(line)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        annotation_array.append(data)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # here we return an array of the individual annotations\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    return annotation_array\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# calling the annotation processor function\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\\\\\\\n\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"reference_annotations = annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"my_annotations = annotation_processor('/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json')\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"def compare_annotations(reference_annotations, my_annotations):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    num_matches = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    num_non_matches = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # you will need to implement this method\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # {'label': ['Person'],\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # 'points': [{'start': 85,\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    #  'end': 116,\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    #  'text': 'A group of students and teachers'}]}\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # that is the character offset is correct\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    print(\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    return num_matches, num_non_matches\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    num_annotations_in_reference = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    num_annotations_in_mine = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # we want this method to calculate these two numbers\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # num_matches should simply count all the cases where we \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    num_matches = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    num_non_matches = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    num_partial_match = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    for annotation in reference_annotation_array:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        for my_annotation in my_annotation_array:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"            if (annotation[\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\"] == my_annotation[\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\"]):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\"], my_annotation[\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\"])\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        # implement the sum of the temp_num_matches to the num_matches\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    return num_matches, num_non_matches\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"print(compare_annotation_files(reference_annotations, my_annotations))\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Step 3:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"With the numbers now available, try to determine the Cohen's Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"The rest of the formula should be as discussed in class.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Report the numbers you calculate.\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Step 4:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    A brief explanation of the Cohen's Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Step 5:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Now you will compare the output of two extractors over a small dataset of news.\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"import spacy\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# here we are just using two different spacy models.\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# you will need to ensure that you have both models installed\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"model_1 = spacy.load(\\\\\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"model_2 = spacy.load(\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\")\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"from os import listdir\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"from os.path import isfile, join\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"dir_base = \\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"####\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"####\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"def read_file(filename):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    input_file_text = open(filename , encoding='utf-8').read()\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    return input_file_text\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"def read_directory_files(directory):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    file_texts = []\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    for f in files:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        file_text = read_file(join(directory, f))\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        print(file_text)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"        file_texts.append({\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\":f, \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": file_text })\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    return file_texts\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# here we will generate the list that contains all the files and their contents\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"text_corpus = read_directory_files(dir_base)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"print(text_corpus)\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# extract entities\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"def get_entities(document_text, model):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    analyzed_doc = model(document_text)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # here we are just limiting to a small set of entity types\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"GPE\\\\\\\\\\\\\\\"]]\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    return entities\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    print(reference_entities)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    print(test_entities)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # how many of the same entities are returned in the test entity set\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # test entity set and also if entities are not retrieved\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # are not in the reference entity set as well\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    correct_identified_entities = 0 \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # count the number of items in the test set \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # that are also in the reference set\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    correct_unidentified_entities = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # count the number of items that are in the reference set \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # that are not in the test set\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    spurious_identified_entites = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # count the number of items in the test set that are not in \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # the reference set\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # item is in the reference entity set\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # correct_identified_entities number\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    ###\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # Your code goes here\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    ###\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"overall_correct_identified_entities = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"overall_correct_unidentified_entities = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"overall_spurious_identified_entites = 0\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"for document in text_corpus:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # below you will see that entities_1 is from model_1\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # you can make a decision about which model output will be the reference output\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    entities_1 = get_entities(document[\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\"], model_1)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    entities_2 = get_entities(document[\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\"], model_2)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    # increment the overall variables\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\\n\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# now that you are outside the loop, determine the following values\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# what is the overall precision and recall?\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"# does this change if you change the reference model?\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Step 6: \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren't using a normal evaluation set, feel free to speculate as you wish.\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"markdown\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": [\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"Extra Credit: \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"    \\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"   ]\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"cell_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"execution_count\\\\\\\": null,\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"metadata\\\\\\\": {},\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"outputs\\\\\\\": [],\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"source\\\\\\\": []\\\\n\\\",\\n\",\n",
      "      \"      \\\"  }\\\\n\\\",\\n\",\n",
      "      \"      \\\" ],\\\\n\\\",\\n\",\n",
      "      \"      \\\" \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n\",\n",
      "      \"      \\\"  \\\\\\\"kernelspec\\\\\\\": {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"display_name\\\\\\\": \\\\\\\"Python 3\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"name\\\\\\\": \\\\\\\"python3\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"  },\\\\n\\\",\\n\",\n",
      "      \"      \\\"  \\\\\\\"language_info\\\\\\\": {\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"codemirror_mode\\\\\\\": {\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"name\\\\\\\": \\\\\\\"ipython\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"    \\\\\\\"version\\\\\\\": 3\\\\n\\\",\\n\",\n",
      "      \"      \\\"   },\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"file_extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"mimetype\\\\\\\": \\\\\\\"text/x-python\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"name\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"nbconvert_exporter\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"pygments_lexer\\\\\\\": \\\\\\\"ipython3\\\\\\\",\\\\n\\\",\\n\",\n",
      "      \"      \\\"   \\\\\\\"version\\\\\\\": \\\\\\\"3.7.2\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"  }\\\\n\\\",\\n\",\n",
      "      \"      \\\" },\\\\n\\\",\\n\",\n",
      "      \"      \\\" \\\\\\\"nbformat\\\\\\\": 4,\\\\n\\\",\\n\",\n",
      "      \"      \\\" \\\\\\\"nbformat_minor\\\\\\\": 2\\\\n\\\",\\n\",\n",
      "      \"      \\\"}\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    },\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    },\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stderr\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"IOPub data rate exceeded.\\\\n\\\",\\n\",\n",
      "      \"      \\\"The notebook server will temporarily stop sending output\\\\n\\\",\\n\",\n",
      "      \"      \\\"to the client in order to avoid crashing it.\\\\n\\\",\\n\",\n",
      "      \"      \\\"To change this limit, set the config variable\\\\n\\\",\\n\",\n",
      "      \"      \\\"`--NotebookApp.iopub_data_rate_limit`.\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"Current values:\\\\n\\\",\\n\",\n",
      "      \"      \\\"NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\\\\n\\\",\\n\",\n",
      "      \"      \\\"NotebookApp.rate_limit_window=3.0 (secs)\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    },\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\n\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\n\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":379,\\\\\\\"end\\\\\\\":386,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":74,\\\\\\\"end\\\\\\\":79,\\\\\\\"text\\\\\\\":\\\\\\\"Hardin\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":64,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":55,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Jonathan Blackmon\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954510000,\\\\\\\"last_updated_at\\\\\\\":1586954510000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"CORRECT\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\n\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\n\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":453,\\\\\\\"end\\\\\\\":460,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":79,\\\\\\\"end\\\\\\\":91,\\\\\\\"text\\\\\\\":\\\\\\\"Peter O’Neill\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":32,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":26,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Scott Morrison\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954448000,\\\\\\\"last_updated_at\\\\\\\":1586954448000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\n\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\n\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":0,\\\\\\\"end\\\\\\\":10,\\\\\\\"text\\\\\\\":\\\\\\\"Joe Montana\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954477000,\\\\\\\"last_updated_at\\\\\\\":1586954477000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\n\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":816,\\\\\\\"end\\\\\\\":825,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":701,\\\\\\\"end\\\\\\\":710,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":588,\\\\\\\"end\\\\\\\":594,\\\\\\\"text\\\\\\\":\\\\\\\"Merritt\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":576,\\\\\\\"end\\\\\\\":581,\\\\\\\"text\\\\\\\":\\\\\\\"Walker\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":532,\\\\\\\"end\\\\\\\":537,\\\\\\\"text\\\\\\\":\\\\\\\"Walker\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":501,\\\\\\\"end\\\\\\\":510,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":224,\\\\\\\"end\\\\\\\":230,\\\\\\\"text\\\\\\\":\\\\\\\"Merritt\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":218,\\\\\\\"end\\\\\\\":229,\\\\\\\"text\\\\\\\":\\\\\\\"Piper Merrit\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":183,\\\\\\\"end\\\\\\\":192,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":25,\\\\\\\"end\\\\\\\":34,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954335000,\\\\\\\"last_updated_at\\\\\\\":1586954335000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"{\\\\\\\"content\\\\\\\": \\\\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":44,\\\\\\\"end\\\\\\\":62,\\\\\\\"text\\\\\\\":\\\\\\\"George Washington’s\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954354000,\\\\\\\"last_updated_at\\\\\\\":1586954354000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    },\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stderr\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"IOPub data rate exceeded.\\\\n\\\",\\n\",\n",
      "      \"      \\\"The notebook server will temporarily stop sending output\\\\n\\\",\\n\",\n",
      "      \"      \\\"to the client in order to avoid crashing it.\\\\n\\\",\\n\",\n",
      "      \"      \\\"To change this limit, set the config variable\\\\n\\\",\\n\",\n",
      "      \"      \\\"`--NotebookApp.iopub_data_rate_limit`.\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\n\\\",\\n\",\n",
      "      \"      \\\"Current values:\\\\n\\\",\\n\",\n",
      "      \"      \\\"NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\\\\n\\\",\\n\",\n",
      "      \"      \\\"NotebookApp.rate_limit_window=3.0 (secs)\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    },\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
      "      \"     \\\"text\\\": [\\n\",\n",
      "      \"      \\\"\\\\n\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"#dir_base = \\\\\\\"/GWU/NATURAL LANGUAGE PROCESSiNG/s20_ds_nlp-master/homeworks/homework_3/news_data\\\\\\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"####\\\\n\\\",\\n\",\n",
      "      \"    \\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\n\\\",\\n\",\n",
      "      \"    \\\"####\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"def read_file(filename):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    input_file_text = open(filename , encoding='utf-8').read()\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return input_file_text\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"def read_directory_files(directory):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    file_texts = []\\\\n\\\",\\n\",\n",
      "      \"    \\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\n\\\",\\n\",\n",
      "      \"    \\\"    for f in files:\\\\n\\\",\\n\",\n",
      "      \"    \\\"        file_text = read_file(join(directory, f))\\\\n\\\",\\n\",\n",
      "      \"    \\\"        print(file_text)\\\\n\\\",\\n\",\n",
      "      \"    \\\"        file_texts.append({\\\\\\\"file\\\\\\\":f, \\\\\\\"content\\\\\\\": file_text })\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return file_texts\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"# here we will generate the list that contains all the files and their contents\\\\n\\\",\\n\",\n",
      "      \"    \\\"text_corpus = read_directory_files(dir_base)\\\\n\\\",\\n\",\n",
      "      \"    \\\"print(text_corpus)\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 44,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# extract entities\\\\n\\\",\\n\",\n",
      "      \"    \\\"def get_entities(document_text, model):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    analyzed_doc = model(document_text)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # here we are just limiting to a small set of entity types\\\\n\\\",\\n\",\n",
      "      \"    \\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\"PER\\\\\\\", \\\\\\\"ORG\\\\\\\", \\\\\\\"LOC\\\\\\\", \\\\\\\"GPE\\\\\\\"]]\\\\n\\\",\\n\",\n",
      "      \"    \\\"    return entities\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"def compare_entities_from_document(reference_entities, test_entities):\\\\n\\\",\\n\",\n",
      "      \"    \\\"    print(reference_entities)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    print(test_entities)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # here we need to calculate how different the reference and test entity sets are\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # how many of the same entities are returned in the test entity set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # So we need to identify the correctly identified entities that are also in the \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # test entity set and also if entities are not retrieved\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # we also want to count the number of entities that are in the test entity set that\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # are not in the reference entity set as well\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # in this case we will only concern ourselves with exact matches of entities\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # thus, a match is the same portion of text and the same entity type\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # hint: this is easy if you try to use normal comparisons\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    correct_identified_entities = 0 \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # count the number of items in the test set \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # that are also in the reference set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    correct_unidentified_entities = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # count the number of items that are in the reference set \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # that are not in the test set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    spurious_identified_entites = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # count the number of items in the test set that are not in \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # the reference set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # item is in the reference entity set\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # so if an item in the test set is in the reference then you would increment the \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # correct_identified_entities number\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    ###\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # Your code goes here\\\\n\\\",\\n\",\n",
      "      \"    \\\"    ###\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": 45,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [\\n\",\n",
      "      \"    {\\n\",\n",
      "      \"     \\\"ename\\\": \\\"ValueError\\\",\\n\",\n",
      "      \"     \\\"evalue\\\": \\\"[E088] Text of length 2211708 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\\",\\n\",\n",
      "      \"     \\\"output_type\\\": \\\"error\\\",\\n\",\n",
      "      \"     \\\"traceback\\\": [\\n\",\n",
      "      \"      \\\"\\\\u001b[1;31m---------------------------------------------------------------------------\\\\u001b[0m\\\",\\n\",\n",
      "      \"      \\\"\\\\u001b[1;31mValueError\\\\u001b[0m                                Traceback (most recent call last)\\\",\\n\",\n",
      "      \"      \\\"\\\\u001b[1;32m<ipython-input-45-5fe2e813ecf8>\\\\u001b[0m in \\\\u001b[0;36m<module>\\\\u001b[1;34m\\\\u001b[0m\\\\n\\\\u001b[0;32m      6\\\\u001b[0m     \\\\u001b[1;31m# below you will see that entities_1 is from model_1\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32m      7\\\\u001b[0m     \\\\u001b[1;31m# you can make a decision about which model output will be the reference output\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[1;32m----> 8\\\\u001b[1;33m     \\\\u001b[0mentities_1\\\\u001b[0m \\\\u001b[1;33m=\\\\u001b[0m \\\\u001b[0mget_entities\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mdocument\\\\u001b[0m\\\\u001b[1;33m[\\\\u001b[0m\\\\u001b[1;34m\\\\\\\"content\\\\\\\"\\\\u001b[0m\\\\u001b[1;33m]\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m \\\\u001b[0mmodel_1\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0m\\\\u001b[0;32m      9\\\\u001b[0m     \\\\u001b[0mentities_2\\\\u001b[0m \\\\u001b[1;33m=\\\\u001b[0m \\\\u001b[0mget_entities\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mdocument\\\\u001b[0m\\\\u001b[1;33m[\\\\u001b[0m\\\\u001b[1;34m\\\\\\\"content\\\\\\\"\\\\u001b[0m\\\\u001b[1;33m]\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m \\\\u001b[0mmodel_2\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32m     10\\\\u001b[0m     \\\\u001b[1;31m#correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\u001b[1;32m<ipython-input-44-627b81386c65>\\\\u001b[0m in \\\\u001b[0;36mget_entities\\\\u001b[1;34m(document_text, model)\\\\u001b[0m\\\\n\\\\u001b[0;32m      1\\\\u001b[0m \\\\u001b[1;31m# extract entities\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32m      2\\\\u001b[0m \\\\u001b[1;32mdef\\\\u001b[0m \\\\u001b[0mget_entities\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mdocument_text\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m \\\\u001b[0mmodel\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m:\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[1;32m----> 3\\\\u001b[1;33m     \\\\u001b[0manalyzed_doc\\\\u001b[0m \\\\u001b[1;33m=\\\\u001b[0m \\\\u001b[0mmodel\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mdocument_text\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0m\\\\u001b[0;32m      4\\\\u001b[0m     \\\\u001b[1;31m# here we are just limiting to a small set of entity types\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32m      5\\\\u001b[0m     \\\\u001b[0mentities\\\\u001b[0m \\\\u001b[1;33m=\\\\u001b[0m \\\\u001b[1;33m[\\\\u001b[0m\\\\u001b[0mentity\\\\u001b[0m \\\\u001b[1;32mfor\\\\u001b[0m \\\\u001b[0mentity\\\\u001b[0m \\\\u001b[1;32min\\\\u001b[0m \\\\u001b[0manalyzed_doc\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0ments\\\\u001b[0m \\\\u001b[1;32mif\\\\u001b[0m \\\\u001b[0mentity\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0mlabel_\\\\u001b[0m \\\\u001b[1;32min\\\\u001b[0m \\\\u001b[1;33m[\\\\u001b[0m\\\\u001b[1;34m\\\\\\\"PER\\\\\\\"\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m \\\\u001b[1;34m\\\\\\\"ORG\\\\\\\"\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m \\\\u001b[1;34m\\\\\\\"LOC\\\\\\\"\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m \\\\u001b[1;34m\\\\\\\"GPE\\\\\\\"\\\\u001b[0m\\\\u001b[1;33m]\\\\u001b[0m\\\\u001b[1;33m]\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\u001b[1;32m~\\\\\\\\Anaconda3\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\spacy\\\\\\\\language.py\\\\u001b[0m in \\\\u001b[0;36m__call__\\\\u001b[1;34m(self, text, disable, component_cfg)\\\\u001b[0m\\\\n\\\\u001b[0;32m    423\\\\u001b[0m         \\\\u001b[1;32mif\\\\u001b[0m \\\\u001b[0mlen\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mtext\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m \\\\u001b[1;33m>\\\\u001b[0m \\\\u001b[0mself\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0mmax_length\\\\u001b[0m\\\\u001b[1;33m:\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32m    424\\\\u001b[0m             raise ValueError(\\\\n\\\\u001b[1;32m--> 425\\\\u001b[1;33m                 \\\\u001b[0mErrors\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0mE088\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0mformat\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mlength\\\\u001b[0m\\\\u001b[1;33m=\\\\u001b[0m\\\\u001b[0mlen\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mtext\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m,\\\\u001b[0m \\\\u001b[0mmax_length\\\\u001b[0m\\\\u001b[1;33m=\\\\u001b[0m\\\\u001b[0mself\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0mmax_length\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0m\\\\u001b[0;32m    426\\\\u001b[0m             )\\\\n\\\\u001b[0;32m    427\\\\u001b[0m         \\\\u001b[0mdoc\\\\u001b[0m \\\\u001b[1;33m=\\\\u001b[0m \\\\u001b[0mself\\\\u001b[0m\\\\u001b[1;33m.\\\\u001b[0m\\\\u001b[0mmake_doc\\\\u001b[0m\\\\u001b[1;33m(\\\\u001b[0m\\\\u001b[0mtext\\\\u001b[0m\\\\u001b[1;33m)\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\",\\n\",\n",
      "      \"      \\\"\\\\u001b[1;31mValueError\\\\u001b[0m: [E088] Text of length 2211708 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\\"\\n\",\n",
      "      \"     ]\\n\",\n",
      "      \"    }\\n\",\n",
      "      \"   ],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"overall_correct_identified_entities = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"overall_correct_unidentified_entities = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"overall_spurious_identified_entites = 0\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"for document in text_corpus:\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # below you will see that entities_1 is from model_1\\\\n\\\",\\n\",\n",
      "      \"    \\\"    # you can make a decision about which model output will be the reference output\\\\n\\\",\\n\",\n",
      "      \"    \\\"    entities_1 = get_entities(document[\\\\\\\"content\\\\\\\"], model_1)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    entities_2 = get_entities(document[\\\\\\\"content\\\\\\\"], model_2)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    #correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\",\\n\",\n",
      "      \"    \\\"    # increment the overall variables\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\\n\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"# now that you are outside the loop, determine the following values\\\\n\\\",\\n\",\n",
      "      \"    \\\"precision = # determine which set of numbers above needed to calculate\\\\n\\\",\\n\",\n",
      "      \"    \\\"recall = # determine which set of numbers above needed to calculate\\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"# what is the overall precision and recall?\\\\n\\\",\\n\",\n",
      "      \"    \\\"# does this change if you change the reference model?\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Step 6: \\\\n\\\",\\n\",\n",
      "      \"    \\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren't using a normal evaluation set, feel free to speculate as you wish.\\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"markdown\\\",\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"source\\\": [\\n\",\n",
      "      \"    \\\"Extra Credit: \\\\n\\\",\\n\",\n",
      "      \"    \\\"\\\\n\\\",\\n\",\n",
      "      \"    \\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\n\\\",\\n\",\n",
      "      \"    \\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\n\\\",\\n\",\n",
      "      \"    \\\"    \\\"\\n\",\n",
      "      \"   ]\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  {\\n\",\n",
      "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
      "      \"   \\\"execution_count\\\": null,\\n\",\n",
      "      \"   \\\"metadata\\\": {},\\n\",\n",
      "      \"   \\\"outputs\\\": [],\\n\",\n",
      "      \"   \\\"source\\\": []\\n\",\n",
      "      \"  }\\n\",\n",
      "      \" ],\\n\",\n",
      "      \" \\\"metadata\\\": {\\n\",\n",
      "      \"  \\\"kernelspec\\\": {\\n\",\n",
      "      \"   \\\"display_name\\\": \\\"Python 3\\\",\\n\",\n",
      "      \"   \\\"language\\\": \\\"python\\\",\\n\",\n",
      "      \"   \\\"name\\\": \\\"python3\\\"\\n\",\n",
      "      \"  },\\n\",\n",
      "      \"  \\\"language_info\\\": {\\n\",\n",
      "      \"   \\\"codemirror_mode\\\": {\\n\",\n",
      "      \"    \\\"name\\\": \\\"ipython\\\",\\n\",\n",
      "      \"    \\\"version\\\": 3\\n\",\n",
      "      \"   },\\n\",\n",
      "      \"   \\\"file_extension\\\": \\\".py\\\",\\n\",\n",
      "      \"   \\\"mimetype\\\": \\\"text/x-python\\\",\\n\",\n",
      "      \"   \\\"name\\\": \\\"python\\\",\\n\",\n",
      "      \"   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n\",\n",
      "      \"   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n\",\n",
      "      \"   \\\"version\\\": \\\"3.7.2\\\"\\n\",\n",
      "      \"  }\\n\",\n",
      "      \" },\\n\",\n",
      "      \" \\\"nbformat\\\": 4,\\n\",\n",
      "      \" \\\"nbformat_minor\\\": 2\\n\",\n",
      "      \"}\\n\"\n",
      "     ]\n",
      "    },\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"\\n\",\n",
      "      \"{\\\"content\\\": \\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\n\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\n\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":379,\\\"end\\\":386,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":74,\\\"end\\\":79,\\\"text\\\":\\\"Hardin\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":64,\\\"end\\\":71,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":55,\\\"end\\\":71,\\\"text\\\":\\\"Jonathan Blackmon\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954510000,\\\"last_updated_at\\\":1586954510000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"CORRECT\\\"}}\\n\",\n",
      "      \"{\\\"content\\\": \\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\n\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\n\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":453,\\\"end\\\":460,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":79,\\\"end\\\":91,\\\"text\\\":\\\"Peter O’Neill\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":32,\\\"end\\\":39,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":26,\\\"end\\\":39,\\\"text\\\":\\\"Scott Morrison\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954448000,\\\"last_updated_at\\\":1586954448000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"{\\\"content\\\": \\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\n\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\n\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":0,\\\"end\\\":10,\\\"text\\\":\\\"Joe Montana\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954477000,\\\"last_updated_at\\\":1586954477000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"{\\\"content\\\": \\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\n\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\n\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":816,\\\"end\\\":825,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":701,\\\"end\\\":710,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":588,\\\"end\\\":594,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":576,\\\"end\\\":581,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":532,\\\"end\\\":537,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":501,\\\"end\\\":510,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":224,\\\"end\\\":230,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":218,\\\"end\\\":229,\\\"text\\\":\\\"Piper Merrit\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":183,\\\"end\\\":192,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":25,\\\"end\\\":34,\\\"text\\\":\\\"John Deere\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954335000,\\\"last_updated_at\\\":1586954335000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"{\\\"content\\\": \\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":44,\\\"end\\\":62,\\\"text\\\":\\\"George Washington’s\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954354000,\\\"last_updated_at\\\":1586954354000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\",\n",
      "      \"\\n\",\n",
      "      \"[{'file': 'annotated.json', 'content': '{\\\"content\\\": \\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\n\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\n\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":379,\\\"end\\\":386,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":293,\\\"end\\\":296,\\\"text\\\":\\\"Irma\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":267,\\\"end\\\":272,\\\"text\\\":\\\"Harvey\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":74,\\\"end\\\":79,\\\"text\\\":\\\"Hardin\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":64,\\\"end\\\":71,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":42,\\\"end\\\":71,\\\"text\\\":\\\"Chief Deputy Jonathan Blackmon\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085438000,\\\"last_updated_at\\\":1541085438000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n{\\\"content\\\": \\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\n\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\n\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":453,\\\"end\\\":460,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":315,\\\"end\\\":325,\\\"text\\\":\\\"the leaders\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":80,\\\"end\\\":91,\\\"text\\\":\\\"eter O’Neill\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":32,\\\"end\\\":39,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":26,\\\"end\\\":39,\\\"text\\\":\\\"Scott Morrison\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085568000,\\\"last_updated_at\\\":1541085568000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n{\\\"content\\\": \\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\n\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\n\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":416,\\\"end\\\":420,\\\"text\\\":\\\"Clark\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":269,\\\"end\\\":275,\\\"text\\\":\\\"Montana\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":245,\\\"end\\\":259,\\\"text\\\":\\\"the quarterback\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":40,\\\"end\\\":44,\\\"text\\\":\\\"Clark\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":33,\\\"end\\\":44,\\\"text\\\":\\\"Dwight Clark\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":4,\\\"end\\\":10,\\\"text\\\":\\\"Montana\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":0,\\\"end\\\":10,\\\"text\\\":\\\"Joe Montana\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085542000,\\\"last_updated_at\\\":1541085542000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n{\\\"content\\\": \\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\n\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":816,\\\"end\\\":825,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":701,\\\"end\\\":710,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":588,\\\"end\\\":594,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":576,\\\"end\\\":581,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":532,\\\"end\\\":537,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":527,\\\"end\\\":537,\\\"text\\\":\\\"Doug Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":501,\\\"end\\\":510,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":224,\\\"end\\\":230,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":218,\\\"end\\\":231,\\\"text\\\":\\\"Piper Merritt,\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":183,\\\"end\\\":192,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":25,\\\"end\\\":34,\\\"text\\\":\\\"John Deere\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085478000,\\\"last_updated_at\\\":1541085478000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n{\\\"content\\\": \\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":85,\\\"end\\\":116,\\\"text\\\":\\\"A group of students and teachers\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":44,\\\"end\\\":60,\\\"text\\\":\\\"George Washington\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085505000,\\\"last_updated_at\\\":1541085505000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n'}, {'file': 'homework_3.ipynb', 'content': '{\\\\n \\\"cells\\\": [\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"# Homework #3\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\\\'ve tagged.\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 1:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Tag data. You\\\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Once you\\\\'ve created an account you\\\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\n\\\",\\\\n    \\\"Select the Document Annotation option under Text annotations.\\\\\\\\n\\\",\\\\n    \\\"    Provide a dataset name (you can use whatever)\\\\\\\\n\\\",\\\\n    \\\"    for the list of entities just input Person\\\\\\\\n\\\",\\\\n    \\\"    for the tagging instructions provide whatever you would like\\\\\\\\n\\\",\\\\n    \\\"    Then hit submit\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"You will then hit the \\\\\\\\\\\"Upload raw data\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\\\'ve identified all of them for a single document hit \\\\\\\\\\\"move to done\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"When you finish tagging all 5 documents, go into the project you\\\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\"download\\\\\\\\\\\". You will want to have the \\\\\\\\\\\"complete items\\\\\\\\\\\" and \\\\\\\\\\\"json\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Annotation guidelines:\\\\\\\\n\\\",\\\\n    \\\"    These are from the ACE Guidelines for Person:\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"3.1 Persons (PER) \\\\\\\\n\\\",\\\\n    \\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Examples: \\\\\\\\n\\\",\\\\n    \\\"He is [a real turkey]\\\\\\\\n\\\",\\\\n    \\\"[The political cat of the year]\\\\\\\\n\\\",\\\\n    \\\"She’s known as [the brain of the family] \\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 2:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Look through the below code.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Implement the appropriate code to calculate these numbers.\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# import json\\\\\\\\n\\\",\\\\n    \\\"from pprint import pprint\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"# method to read annotation file\\\\\\\\n\\\",\\\\n    \\\"def annotation_processor(annotation_file):\\\\\\\\n\\\",\\\\n    \\\"    annotation_array = []\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\n\\\",\\\\n    \\\"    read_annotation = open(annotation_file)\\\\\\\\n\\\",\\\\n    \\\"    for line in read_annotation:\\\\\\\\n\\\",\\\\n    \\\"        data = json.loads(line)\\\\\\\\n\\\",\\\\n    \\\"        annotation_array.append(data)\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"    # here we return an array of the individual annotations\\\\\\\\n\\\",\\\\n    \\\"    return annotation_array\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"# calling the annotation processor function\\\\\\\\n\\\",\\\\n    \\\"annotation_processor(\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\')\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\n\\\",\\\\n    \\\"reference_annotations = annotation_processor(\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\')\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\n\\\",\\\\n    \\\"my_annotations = annotation_processor(\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\')\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\n\\\",\\\\n    \\\"def compare_annotations(reference_annotations, my_annotations):\\\\\\\\n\\\",\\\\n    \\\"    num_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    num_non_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    # you will need to implement this method\\\\\\\\n\\\",\\\\n    \\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\",\\\\n    \\\"    # {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n    \\\"    # \\\\'points\\\\': [{\\\\'start\\\\': 85,\\\\\\\\n\\\",\\\\n    \\\"    #  \\\\'end\\\\': 116,\\\\\\\\n\\\",\\\\n    \\\"    #  \\\\'text\\\\': \\\\'A group of students and teachers\\\\'}]}\\\\\\\\n\\\",\\\\n    \\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\",\\\\n    \\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\",\\\\n    \\\"    # that is the character offset is correct\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    print(\\\\\\\\\\\"success\\\\\\\\\\\")\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    return num_matches, num_non_matches\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\\\\\n\\\",\\\\n    \\\"    num_annotations_in_reference = 0\\\\\\\\n\\\",\\\\n    \\\"    num_annotations_in_mine = 0\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # we want this method to calculate these two numbers\\\\\\\\n\\\",\\\\n    \\\"    # num_matches should simply count all the cases where we \\\\\\\\n\\\",\\\\n    \\\"    num_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\\\\\n\\\",\\\\n    \\\"    num_non_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\\\\\n\\\",\\\\n    \\\"    num_partial_match = 0\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    for annotation in reference_annotation_array:\\\\\\\\n\\\",\\\\n    \\\"        for my_annotation in my_annotation_array:\\\\\\\\n\\\",\\\\n    \\\"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\\\\\n\\\",\\\\n    \\\"            if (annotation[\\\\\\\\\\\"content\\\\\\\\\\\"] == my_annotation[\\\\\\\\\\\"content\\\\\\\\\\\"]):\\\\\\\\n\\\",\\\\n    \\\"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\\\\\\\"annotation\\\\\\\\\\\"], my_annotation[\\\\\\\\\\\"annotation\\\\\\\\\\\"])\\\\\\\\n\\\",\\\\n    \\\"        \\\\\\\\n\\\",\\\\n    \\\"        # implement the sum of the temp_num_matches to the num_matches\\\\\\\\n\\\",\\\\n    \\\"        \\\\\\\\n\\\",\\\\n    \\\"    return num_matches, num_non_matches\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"print(compare_annotation_files(reference_annotations, my_annotations))\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 3:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"With the numbers now available, try to determine the Cohen\\\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"The rest of the formula should be as discussed in class.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Report the numbers you calculate.\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 4:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\n\\\",\\\\n    \\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\n\\\",\\\\n    \\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\n\\\",\\\\n    \\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\n\\\",\\\\n    \\\"    A brief explanation of the Cohen\\\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 5:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Now you will compare the output of two extractors over a small dataset of news.\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"import spacy\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# here we are just using two different spacy models.\\\\\\\\n\\\",\\\\n    \\\"# you will need to ensure that you have both models installed\\\\\\\\n\\\",\\\\n    \\\"model_1 = spacy.load(\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\")\\\\\\\\n\\\",\\\\n    \\\"model_2 = spacy.load(\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\")\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"from os import listdir\\\\\\\\n\\\",\\\\n    \\\"from os.path import isfile, join\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"dir_base = \\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"####\\\\\\\\n\\\",\\\\n    \\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\n\\\",\\\\n    \\\"####\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"def read_file(filename):\\\\\\\\n\\\",\\\\n    \\\"    input_file_text = open(filename , encoding=\\\\'utf-8\\\\').read()\\\\\\\\n\\\",\\\\n    \\\"    return input_file_text\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"def read_directory_files(directory):\\\\\\\\n\\\",\\\\n    \\\"    file_texts = []\\\\\\\\n\\\",\\\\n    \\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\n\\\",\\\\n    \\\"    for f in files:\\\\\\\\n\\\",\\\\n    \\\"        file_text = read_file(join(directory, f))\\\\\\\\n\\\",\\\\n    \\\"        print(file_text)\\\\\\\\n\\\",\\\\n    \\\"        file_texts.append({\\\\\\\\\\\"file\\\\\\\\\\\":f, \\\\\\\\\\\"content\\\\\\\\\\\": file_text })\\\\\\\\n\\\",\\\\n    \\\"    return file_texts\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"# here we will generate the list that contains all the files and their contents\\\\\\\\n\\\",\\\\n    \\\"text_corpus = read_directory_files(dir_base)\\\\\\\\n\\\",\\\\n    \\\"print(text_corpus)\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# extract entities\\\\\\\\n\\\",\\\\n    \\\"def get_entities(document_text, model):\\\\\\\\n\\\",\\\\n    \\\"    analyzed_doc = model(document_text)\\\\\\\\n\\\",\\\\n    \\\"    # here we are just limiting to a small set of entity types\\\\\\\\n\\\",\\\\n    \\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\"PER\\\\\\\\\\\", \\\\\\\\\\\"ORG\\\\\\\\\\\", \\\\\\\\\\\"LOC\\\\\\\\\\\", \\\\\\\\\\\"GPE\\\\\\\\\\\"]]\\\\\\\\n\\\",\\\\n    \\\"    return entities\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\n\\\",\\\\n    \\\"    print(reference_entities)\\\\\\\\n\\\",\\\\n    \\\"    print(test_entities)\\\\\\\\n\\\",\\\\n    \\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\n\\\",\\\\n    \\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\n\\\",\\\\n    \\\"    # how many of the same entities are returned in the test entity set\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\n\\\",\\\\n    \\\"    # test entity set and also if entities are not retrieved\\\\\\\\n\\\",\\\\n    \\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\n\\\",\\\\n    \\\"    # are not in the reference entity set as well\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\n\\\",\\\\n    \\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\n\\\",\\\\n    \\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    correct_identified_entities = 0 \\\\\\\\n\\\",\\\\n    \\\"    # count the number of items in the test set \\\\\\\\n\\\",\\\\n    \\\"    # that are also in the reference set\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    correct_unidentified_entities = 0\\\\\\\\n\\\",\\\\n    \\\"    # count the number of items that are in the reference set \\\\\\\\n\\\",\\\\n    \\\"    # that are not in the test set\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    spurious_identified_entites = 0\\\\\\\\n\\\",\\\\n    \\\"    # count the number of items in the test set that are not in \\\\\\\\n\\\",\\\\n    \\\"    # the reference set\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\n\\\",\\\\n    \\\"    # item is in the reference entity set\\\\\\\\n\\\",\\\\n    \\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\n\\\",\\\\n    \\\"    # correct_identified_entities number\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    ###\\\\\\\\n\\\",\\\\n    \\\"    # Your code goes here\\\\\\\\n\\\",\\\\n    \\\"    ###\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"overall_correct_identified_entities = 0\\\\\\\\n\\\",\\\\n    \\\"overall_correct_unidentified_entities = 0\\\\\\\\n\\\",\\\\n    \\\"overall_spurious_identified_entites = 0\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"for document in text_corpus:\\\\\\\\n\\\",\\\\n    \\\"    # below you will see that entities_1 is from model_1\\\\\\\\n\\\",\\\\n    \\\"    # you can make a decision about which model output will be the reference output\\\\\\\\n\\\",\\\\n    \\\"    entities_1 = get_entities(document[\\\\\\\\\\\"content\\\\\\\\\\\"], model_1)\\\\\\\\n\\\",\\\\n    \\\"    entities_2 = get_entities(document[\\\\\\\\\\\"content\\\\\\\\\\\"], model_2)\\\\\\\\n\\\",\\\\n    \\\"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # increment the overall variables\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# now that you are outside the loop, determine the following values\\\\\\\\n\\\",\\\\n    \\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\n\\\",\\\\n    \\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"# what is the overall precision and recall?\\\\\\\\n\\\",\\\\n    \\\"# does this change if you change the reference model?\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 6: \\\\\\\\n\\\",\\\\n    \\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\\\'t using a normal evaluation set, feel free to speculate as you wish.\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Extra Credit: \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\n\\\",\\\\n    \\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\n\\\",\\\\n    \\\"    \\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": []\\\\n  }\\\\n ],\\\\n \\\"metadata\\\": {\\\\n  \\\"kernelspec\\\": {\\\\n   \\\"display_name\\\": \\\"Python 3\\\",\\\\n   \\\"language\\\": \\\"python\\\",\\\\n   \\\"name\\\": \\\"python3\\\"\\\\n  },\\\\n  \\\"language_info\\\": {\\\\n   \\\"codemirror_mode\\\": {\\\\n    \\\"name\\\": \\\"ipython\\\",\\\\n    \\\"version\\\": 3\\\\n   },\\\\n   \\\"file_extension\\\": \\\".py\\\",\\\\n   \\\"mimetype\\\": \\\"text/x-python\\\",\\\\n   \\\"name\\\": \\\"python\\\",\\\\n   \\\"nbconvert_exporter\\\": \\\"python\\\",\\\\n   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\\\n   \\\"version\\\": \\\"3.7.2\\\"\\\\n  }\\\\n },\\\\n \\\"nbformat\\\": 4,\\\\n \\\"nbformat_minor\\\": 2\\\\n}\\\\n'}, {'file': 'homework_3_final.ipynb', 'content': '{\\\\n \\\"cells\\\": [\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"# Homework #3\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\\\'ve tagged.\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 1:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Tag data. You\\\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Once you\\\\'ve created an account you\\\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\n\\\",\\\\n    \\\"Select the Document Annotation option under Text annotations.\\\\\\\\n\\\",\\\\n    \\\"    Provide a dataset name (you can use whatever)\\\\\\\\n\\\",\\\\n    \\\"    for the list of entities just input Person\\\\\\\\n\\\",\\\\n    \\\"    for the tagging instructions provide whatever you would like\\\\\\\\n\\\",\\\\n    \\\"    Then hit submit\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"You will then hit the \\\\\\\\\\\"Upload raw data\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\\\'ve identified all of them for a single document hit \\\\\\\\\\\"move to done\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"When you finish tagging all 5 documents, go into the project you\\\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\"download\\\\\\\\\\\". You will want to have the \\\\\\\\\\\"complete items\\\\\\\\\\\" and \\\\\\\\\\\"json\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Annotation guidelines:\\\\\\\\n\\\",\\\\n    \\\"    These are from the ACE Guidelines for Person:\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"3.1 Persons (PER) \\\\\\\\n\\\",\\\\n    \\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Examples: \\\\\\\\n\\\",\\\\n    \\\"He is [a real turkey]\\\\\\\\n\\\",\\\\n    \\\"[The political cat of the year]\\\\\\\\n\\\",\\\\n    \\\"She’s known as [the brain of the family] \\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 2:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Look through the below code.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Implement the appropriate code to calculate these numbers.\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 24,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"data\\\": {\\\\n      \\\"text/plain\\\": [\\\\n       \\\"[{\\\\'content\\\\': \\\\'According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\',\\\\\\\\n\\\",\\\\n       \\\"  \\\\'annotation\\\\': [{\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 379, \\\\'end\\\\': 386, \\\\'text\\\\': \\\\'Blackmon\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 74, \\\\'end\\\\': 79, \\\\'text\\\\': \\\\'Hardin\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 64, \\\\'end\\\\': 71, \\\\'text\\\\': \\\\'Blackmon\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 55, \\\\'end\\\\': 71, \\\\'text\\\\': \\\\'Jonathan Blackmon\\\\'}]}],\\\\\\\\n\\\",\\\\n       \\\"  \\\\'extras\\\\': None,\\\\\\\\n\\\",\\\\n       \\\"  \\\\'metadata\\\\': {\\\\'first_done_at\\\\': 1586954510000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_at\\\\': 1586954510000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'sec_taken\\\\': 0,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_by\\\\': \\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'status\\\\': \\\\'done\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'evaluation\\\\': \\\\'CORRECT\\\\'}},\\\\\\\\n\\\",\\\\n       \\\" {\\\\'content\\\\': \\\\'Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\',\\\\\\\\n\\\",\\\\n       \\\"  \\\\'annotation\\\\': [{\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 453, \\\\'end\\\\': 460, \\\\'text\\\\': \\\\'Morrison\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 79, \\\\'end\\\\': 91, \\\\'text\\\\': \\\\'Peter O’Neill\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 32, \\\\'end\\\\': 39, \\\\'text\\\\': \\\\'Morrison\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 26, \\\\'end\\\\': 39, \\\\'text\\\\': \\\\'Scott Morrison\\\\'}]}],\\\\\\\\n\\\",\\\\n       \\\"  \\\\'extras\\\\': None,\\\\\\\\n\\\",\\\\n       \\\"  \\\\'metadata\\\\': {\\\\'first_done_at\\\\': 1586954448000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_at\\\\': 1586954448000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'sec_taken\\\\': 0,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_by\\\\': \\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'status\\\\': \\\\'done\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'evaluation\\\\': \\\\'NONE\\\\'}},\\\\\\\\n\\\",\\\\n       \\\" {\\\\'content\\\\': \\\\'Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\',\\\\\\\\n\\\",\\\\n       \\\"  \\\\'annotation\\\\': [{\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 0, \\\\'end\\\\': 10, \\\\'text\\\\': \\\\'Joe Montana\\\\'}]}],\\\\\\\\n\\\",\\\\n       \\\"  \\\\'extras\\\\': None,\\\\\\\\n\\\",\\\\n       \\\"  \\\\'metadata\\\\': {\\\\'first_done_at\\\\': 1586954477000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_at\\\\': 1586954477000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'sec_taken\\\\': 0,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_by\\\\': \\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'status\\\\': \\\\'done\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'evaluation\\\\': \\\\'NONE\\\\'}},\\\\\\\\n\\\",\\\\n       \\\" {\\\\'content\\\\': \\\\'To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\',\\\\\\\\n\\\",\\\\n       \\\"  \\\\'annotation\\\\': [{\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 816, \\\\'end\\\\': 825, \\\\'text\\\\': \\\\'John Deere\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 701, \\\\'end\\\\': 710, \\\\'text\\\\': \\\\'John Deere\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 588, \\\\'end\\\\': 594, \\\\'text\\\\': \\\\'Merritt\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 576, \\\\'end\\\\': 581, \\\\'text\\\\': \\\\'Walker\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 532, \\\\'end\\\\': 537, \\\\'text\\\\': \\\\'Walker\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 501, \\\\'end\\\\': 510, \\\\'text\\\\': \\\\'John Deere\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 224, \\\\'end\\\\': 230, \\\\'text\\\\': \\\\'Merritt\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 218, \\\\'end\\\\': 229, \\\\'text\\\\': \\\\'Piper Merrit\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 183, \\\\'end\\\\': 192, \\\\'text\\\\': \\\\'John Deere\\\\'}]},\\\\\\\\n\\\",\\\\n       \\\"   {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 25, \\\\'end\\\\': 34, \\\\'text\\\\': \\\\'John Deere\\\\'}]}],\\\\\\\\n\\\",\\\\n       \\\"  \\\\'extras\\\\': None,\\\\\\\\n\\\",\\\\n       \\\"  \\\\'metadata\\\\': {\\\\'first_done_at\\\\': 1586954335000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_at\\\\': 1586954335000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'sec_taken\\\\': 0,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_by\\\\': \\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'status\\\\': \\\\'done\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'evaluation\\\\': \\\\'NONE\\\\'}},\\\\\\\\n\\\",\\\\n       \\\" {\\\\'content\\\\': \\\\'A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\',\\\\\\\\n\\\",\\\\n       \\\"  \\\\'annotation\\\\': [{\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n       \\\"    \\\\'points\\\\': [{\\\\'start\\\\': 44, \\\\'end\\\\': 62, \\\\'text\\\\': \\\\'George Washington’s\\\\'}]}],\\\\\\\\n\\\",\\\\n       \\\"  \\\\'extras\\\\': None,\\\\\\\\n\\\",\\\\n       \\\"  \\\\'metadata\\\\': {\\\\'first_done_at\\\\': 1586954354000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_at\\\\': 1586954354000,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'sec_taken\\\\': 0,\\\\\\\\n\\\",\\\\n       \\\"   \\\\'last_updated_by\\\\': \\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'status\\\\': \\\\'done\\\\',\\\\\\\\n\\\",\\\\n       \\\"   \\\\'evaluation\\\\': \\\\'NONE\\\\'}}]\\\"\\\\n      ]\\\\n     },\\\\n     \\\"execution_count\\\": 24,\\\\n     \\\"metadata\\\": {},\\\\n     \\\"output_type\\\": \\\"execute_result\\\"\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"# import json\\\\\\\\n\\\",\\\\n    \\\"from pprint import pprint\\\\\\\\n\\\",\\\\n    \\\"import json\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"# method to read annotation file\\\\\\\\n\\\",\\\\n    \\\"def annotation_processor(annotation_file):\\\\\\\\n\\\",\\\\n    \\\"    annotation_array = []\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\n\\\",\\\\n    \\\"    read_annotation = open(annotation_file,encoding=\\\\'utf8\\\\')\\\\\\\\n\\\",\\\\n    \\\"    for line in read_annotation:\\\\\\\\n\\\",\\\\n    \\\"        data = json.loads(line)\\\\\\\\n\\\",\\\\n    \\\"        annotation_array.append(data)\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"    # here we return an array of the individual annotations\\\\\\\\n\\\",\\\\n    \\\"    return annotation_array\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"# calling the annotation processor function\\\\\\\\n\\\",\\\\n    \\\"annotation_processor(\\\\'Person_entites.json\\\\')\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 25,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"#import json\\\\\\\\n\\\",\\\\n    \\\"#person_dict = json.loads(\\\\'annotated.json\\\\')\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 26,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\n\\\",\\\\n    \\\"reference_annotations = annotation_processor(\\\\'Person_entites.json\\\\')\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\n\\\",\\\\n    \\\"my_annotations = annotation_processor(\\\\'annotated.json\\\\')\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 27,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"m=my_annotations[:]\\\\\\\\n\\\",\\\\n    \\\"n=reference_annotations[:]\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 28,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"num_matches = 0\\\\\\\\n\\\",\\\\n    \\\"num_non_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    # you will need to implement this method\\\\\\\\n\\\",\\\\n    \\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\",\\\\n    \\\"    # {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n    \\\"    # \\\\'points\\\\': [{\\\\'start\\\\': 85,\\\\\\\\n\\\",\\\\n    \\\"    #  \\\\'end\\\\': 116,\\\\\\\\n\\\",\\\\n    \\\"    #  \\\\'text\\\\': \\\\'A group of students and teachers\\\\'}]}\\\\\\\\n\\\",\\\\n    \\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\",\\\\n    \\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\",\\\\n    \\\"    # that is the character offset is correct\\\\\\\\n\\\",\\\\n    \\\"for smallm,smalln in zip(m,n):\\\\\\\\n\\\",\\\\n    \\\"    for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\n\\\",\\\\n    \\\"            if keym==\\\\\\\\\\\"annotation\\\\\\\\\\\" and keyn==\\\\\\\\\\\"annotation\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"                for vm,vn in zip(valuem,valuen):\\\\\\\\n\\\",\\\\n    \\\"                    for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\n\\\",\\\\n    \\\"                        if vmk==\\\\\\\\\\\"points\\\\\\\\\\\" and vnk==\\\\\\\\\\\"points\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"                            for v1,v2 in zip(vmv,vnv):\\\\\\\\n\\\",\\\\n    \\\"                                for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\n\\\",\\\\n    \\\"                                    #for v11,v22 in zip(vv1,vv2):\\\\\\\\n\\\",\\\\n    \\\"                                    if vv1==vv2:\\\\\\\\n\\\",\\\\n    \\\"                                        num_matches = num_matches +1 \\\\\\\\n\\\",\\\\n    \\\"                                    elif vv1!=vv2:\\\\\\\\n\\\",\\\\n    \\\"                                        num_non_matches=num_non_matches+1\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 29,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"23\\\\\\\\n\\\",\\\\n      \\\"37\\\\\\\\n\\\"\\\\n     ]\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"print(num_matches)\\\\\\\\n\\\",\\\\n    \\\"print(num_non_matches)\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 30,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 379\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 386\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Blackmon\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 293\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 296\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Irma\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 267\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 272\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Harvey\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 74\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 79\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Hardin\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 64\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 71\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Blackmon\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 42\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 71\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Chief Deputy Jonathan Blackmon\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 453\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 460\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Morrison\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 315\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 325\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value the leaders\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 80\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 91\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value eter O’Neill\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 32\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 39\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Morrison\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 26\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 39\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Scott Morrison\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 416\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 420\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Clark\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 269\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 275\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Montana\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 245\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 259\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value the quarterback\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 40\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 44\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Clark\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 33\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 44\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Dwight Clark\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 4\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 10\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Montana\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 0\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 10\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Joe Montana\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 816\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 825\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value John Deere\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 701\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 710\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value John Deere\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 588\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 594\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Merritt\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 576\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 581\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Walker\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 532\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 537\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Walker\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 527\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 537\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Doug Walker\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 501\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 510\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value John Deere\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 224\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 230\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Merritt\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 218\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 231\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value Piper Merritt,\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 183\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 192\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value John Deere\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 25\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 34\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value John Deere\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 85\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 116\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value A group of students and teachers\\\\\\\\n\\\",\\\\n      \\\"********\\\\\\\\n\\\",\\\\n      \\\"tag Person\\\\\\\\n\\\",\\\\n      \\\"keys start\\\\\\\\n\\\",\\\\n      \\\"value 44\\\\\\\\n\\\",\\\\n      \\\"keys end\\\\\\\\n\\\",\\\\n      \\\"value 60\\\\\\\\n\\\",\\\\n      \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value George Washington\\\\\\\\n\\\"\\\\n     ]\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"#final checking function- done- works!!!\\\\\\\\n\\\",\\\\n    \\\"m=my_annotations[0:5]\\\\\\\\n\\\",\\\\n    \\\"for small in m:\\\\\\\\n\\\",\\\\n    \\\"    for key,value in small.items():\\\\\\\\n\\\",\\\\n    \\\"        if key==\\\\\\\\\\\"annotation\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"            for v in value:\\\\\\\\n\\\",\\\\n    \\\"                print(\\\\\\\\\\\"********\\\\\\\\\\\")\\\\\\\\n\\\",\\\\n    \\\"                for vk,vv in v.items():\\\\\\\\n\\\",\\\\n    \\\"                    if vk==\\\\\\\\\\\"label\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"                        for vvl in vv:\\\\\\\\n\\\",\\\\n    \\\"                            print(\\\\\\\\\\\"tag\\\\\\\\\\\",vvl)\\\\\\\\n\\\",\\\\n    \\\"                    if vk==\\\\\\\\\\\"points\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"                        for vvl in vv:\\\\\\\\n\\\",\\\\n    \\\"                            for vvlk,vvlv in vvl.items():\\\\\\\\n\\\",\\\\n    \\\"                                print(\\\\\\\\\\\"keys\\\\\\\\\\\",vvlk)\\\\\\\\n\\\",\\\\n    \\\"                                print(\\\\\\\\\\\"value\\\\\\\\\\\",vvlv)\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 31,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\n\\\",\\\\n    \\\"def compare_annotations(m, n):\\\\\\\\n\\\",\\\\n    \\\"    num_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    num_non_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    # you will need to implement this method\\\\\\\\n\\\",\\\\n    \\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\",\\\\n    \\\"    # {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n    \\\"    # \\\\'points\\\\': [{\\\\'start\\\\': 85,\\\\\\\\n\\\",\\\\n    \\\"    #  \\\\'end\\\\': 116,\\\\\\\\n\\\",\\\\n    \\\"    #  \\\\'text\\\\': \\\\'A group of students and teachers\\\\'}]}\\\\\\\\n\\\",\\\\n    \\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\",\\\\n    \\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\",\\\\n    \\\"    # that is the character offset is correct\\\\\\\\n\\\",\\\\n    \\\"    for smallm,smalln in zip(m,n):\\\\\\\\n\\\",\\\\n    \\\"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\n\\\",\\\\n    \\\"                if keym==\\\\\\\\\\\"annotation\\\\\\\\\\\" and keyn==\\\\\\\\\\\"annotation\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"                    for vm,vn in zip(valuem,valuen):\\\\\\\\n\\\",\\\\n    \\\"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\n\\\",\\\\n    \\\"                            if vmk==\\\\\\\\\\\"points\\\\\\\\\\\" and vnk==\\\\\\\\\\\"points\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"                                for v1,v2 in zip(vmv,vnv):\\\\\\\\n\\\",\\\\n    \\\"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\n\\\",\\\\n    \\\"                                        #for v11,v22 in zip(vv1,vv2):\\\\\\\\n\\\",\\\\n    \\\"                                        if vv1==vv2:\\\\\\\\n\\\",\\\\n    \\\"                                            num_matches = num_matches +1 \\\\\\\\n\\\",\\\\n    \\\"                                        elif vv1!=vv2:\\\\\\\\n\\\",\\\\n    \\\"                                            num_non_matches=num_non_matches+1\\\\\\\\n\\\",\\\\n    \\\"    print(\\\\\\\\\\\"success\\\\\\\\\\\")\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    return num_matches, num_non_matches\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 32,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"success\\\\\\\\n\\\",\\\\n      \\\"(23, 37)\\\\\\\\n\\\"\\\\n     ]\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"print(compare_annotations(m,n))\\\\\\\\n\\\",\\\\n    \\\"#print(m1)\\\\\\\\n\\\",\\\\n    \\\"#print(n1)\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 33,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\n\\\",\\\\n    \\\"def compare_annotations(m, n):\\\\\\\\n\\\",\\\\n    \\\"    num_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    num_non_matches = 0\\\\\\\\n\\\",\\\\n    \\\"    # you will need to implement this method\\\\\\\\n\\\",\\\\n    \\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\",\\\\n    \\\"    # {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\n\\\",\\\\n    \\\"    # \\\\'points\\\\': [{\\\\'start\\\\': 85,\\\\\\\\n\\\",\\\\n    \\\"    #  \\\\'end\\\\': 116,\\\\\\\\n\\\",\\\\n    \\\"    #  \\\\'text\\\\': \\\\'A group of students and teachers\\\\'}]}\\\\\\\\n\\\",\\\\n    \\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\",\\\\n    \\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\",\\\\n    \\\"    # that is the character offset is correct\\\\\\\\n\\\",\\\\n    \\\"    for smallm,smalln in zip(m,n):\\\\\\\\n\\\",\\\\n    \\\"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\n\\\",\\\\n    \\\"                if keym==\\\\\\\\\\\"annotation\\\\\\\\\\\" and keyn==\\\\\\\\\\\"annotation\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"                    for vm,vn in zip(valuem,valuen):\\\\\\\\n\\\",\\\\n    \\\"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\n\\\",\\\\n    \\\"                            if vmk==\\\\\\\\\\\"points\\\\\\\\\\\" and vnk==\\\\\\\\\\\"points\\\\\\\\\\\":\\\\\\\\n\\\",\\\\n    \\\"                                for v1,v2 in zip(vmv,vnv):\\\\\\\\n\\\",\\\\n    \\\"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\n\\\",\\\\n    \\\"                                        #for v11,v22 in zip(vv1,vv2):\\\\\\\\n\\\",\\\\n    \\\"                                        if vv1==vv2:\\\\\\\\n\\\",\\\\n    \\\"                                            num_matches = num_matches +1 \\\\\\\\n\\\",\\\\n    \\\"                                        elif vv1!=vv2:\\\\\\\\n\\\",\\\\n    \\\"                                            num_non_matches=num_non_matches+1\\\\\\\\n\\\",\\\\n    \\\"    print(\\\\\\\\\\\"success\\\\\\\\\\\")\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    return num_matches, num_non_matches\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"def compare_annotation_files(mm, nn):\\\\\\\\n\\\",\\\\n    \\\"    m1,n1=compare_annotations(mm,nn)\\\\\\\\n\\\",\\\\n    \\\"    return m1,n1\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 34,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"success\\\\\\\\n\\\",\\\\n      \\\"(23, 37)\\\\\\\\n\\\"\\\\n     ]\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"m=my_annotations[:]\\\\\\\\n\\\",\\\\n    \\\"n=reference_annotations[:]\\\\\\\\n\\\",\\\\n    \\\"print(compare_annotation_files(m, n))\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 35,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"success\\\\\\\\n\\\"\\\\n     ]\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"val1,val2=compare_annotation_files(reference_annotations, my_annotations)\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 36,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"data\\\": {\\\\n      \\\"text/plain\\\": [\\\\n       \\\"23\\\"\\\\n      ]\\\\n     },\\\\n     \\\"execution_count\\\": 36,\\\\n     \\\"metadata\\\": {},\\\\n     \\\"output_type\\\": \\\"execute_result\\\"\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"val1\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 37,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"data\\\": {\\\\n      \\\"text/plain\\\": [\\\\n       \\\"37\\\"\\\\n      ]\\\\n     },\\\\n     \\\"execution_count\\\": 37,\\\\n     \\\"metadata\\\": {},\\\\n     \\\"output_type\\\": \\\"execute_result\\\"\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"val2\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 3:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"With the numbers now available, try to determine the Cohen\\\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"The rest of the formula should be as discussed in class.\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Report the numbers you calculate.\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 4:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\n\\\",\\\\n    \\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\n\\\",\\\\n    \\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\n\\\",\\\\n    \\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\n\\\",\\\\n    \\\"    A brief explanation of the Cohen\\\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 5:\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"Now you will compare the output of two extractors over a small dataset of news.\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 38,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"import spacy\\\\\\\\n\\\",\\\\n    \\\"import os\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 39,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# here we are just using two different spacy models.\\\\\\\\n\\\",\\\\n    \\\"# you will need to ensure that you have both models installed\\\\\\\\n\\\",\\\\n    \\\"model_1 = spacy.load(\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\")\\\\\\\\n\\\",\\\\n    \\\"model_2 = spacy.load(\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\")\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 40,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"from os import listdir\\\\\\\\n\\\",\\\\n    \\\"from os.path import isfile, join\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 41,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"data\\\": {\\\\n      \\\"text/plain\\\": [\\\\n       \\\"\\\\'C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\NLP_HW\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\HW3\\\\'\\\"\\\\n      ]\\\\n     },\\\\n     \\\"execution_count\\\": 41,\\\\n     \\\"metadata\\\": {},\\\\n     \\\"output_type\\\": \\\"execute_result\\\"\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"os.getcwd()\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 42,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"dir_base = os.getcwd()\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 43,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":379,\\\\\\\\\\\"end\\\\\\\\\\\":386,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":293,\\\\\\\\\\\"end\\\\\\\\\\\":296,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Irma\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":267,\\\\\\\\\\\"end\\\\\\\\\\\":272,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Harvey\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":74,\\\\\\\\\\\"end\\\\\\\\\\\":79,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Hardin\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":64,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":42,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Chief Deputy Jonathan Blackmon\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1541085438000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1541085438000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":453,\\\\\\\\\\\"end\\\\\\\\\\\":460,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Morrison\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":315,\\\\\\\\\\\"end\\\\\\\\\\\":325,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"the leaders\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":80,\\\\\\\\\\\"end\\\\\\\\\\\":91,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"eter O’Neill\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":32,\\\\\\\\\\\"end\\\\\\\\\\\":39,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Morrison\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":26,\\\\\\\\\\\"end\\\\\\\\\\\":39,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Scott Morrison\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1541085568000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1541085568000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":416,\\\\\\\\\\\"end\\\\\\\\\\\":420,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Clark\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":269,\\\\\\\\\\\"end\\\\\\\\\\\":275,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Montana\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":245,\\\\\\\\\\\"end\\\\\\\\\\\":259,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"the quarterback\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":40,\\\\\\\\\\\"end\\\\\\\\\\\":44,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Clark\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":33,\\\\\\\\\\\"end\\\\\\\\\\\":44,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Dwight Clark\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":4,\\\\\\\\\\\"end\\\\\\\\\\\":10,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Montana\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":0,\\\\\\\\\\\"end\\\\\\\\\\\":10,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Joe Montana\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1541085542000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1541085542000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":816,\\\\\\\\\\\"end\\\\\\\\\\\":825,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":701,\\\\\\\\\\\"end\\\\\\\\\\\":710,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":588,\\\\\\\\\\\"end\\\\\\\\\\\":594,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Merritt\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":576,\\\\\\\\\\\"end\\\\\\\\\\\":581,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Walker\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":532,\\\\\\\\\\\"end\\\\\\\\\\\":537,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Walker\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":527,\\\\\\\\\\\"end\\\\\\\\\\\":537,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Doug Walker\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":501,\\\\\\\\\\\"end\\\\\\\\\\\":510,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":224,\\\\\\\\\\\"end\\\\\\\\\\\":230,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Merritt\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":218,\\\\\\\\\\\"end\\\\\\\\\\\":231,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Piper Merritt,\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":183,\\\\\\\\\\\"end\\\\\\\\\\\":192,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":25,\\\\\\\\\\\"end\\\\\\\\\\\":34,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1541085478000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1541085478000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":85,\\\\\\\\\\\"end\\\\\\\\\\\":116,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"A group of students and teachers\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":44,\\\\\\\\\\\"end\\\\\\\\\\\":60,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"George Washington\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1541085505000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1541085505000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\n\\\",\\\\n      \\\" \\\\\\\\\\\"cells\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# Homework #3\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\\\'ve tagged.\\\\\\\\\\\\\\\\n\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Step 1:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Tag data. You\\\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Once you\\\\'ve created an account you\\\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Select the Document Annotation option under Text annotations.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    Provide a dataset name (you can use whatever)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    for the list of entities just input Person\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    for the tagging instructions provide whatever you would like\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    Then hit submit\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"You will then hit the \\\\\\\\\\\\\\\\\\\\\\\\\\\"Upload raw data\\\\\\\\\\\\\\\\\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\\\'ve identified all of them for a single document hit \\\\\\\\\\\\\\\\\\\\\\\\\\\"move to done\\\\\\\\\\\\\\\\\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"When you finish tagging all 5 documents, go into the project you\\\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\\\\\\\\\\\\\\\\\"download\\\\\\\\\\\\\\\\\\\\\\\\\\\". You will want to have the \\\\\\\\\\\\\\\\\\\\\\\\\\\"complete items\\\\\\\\\\\\\\\\\\\\\\\\\\\" and \\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\\\\\\\\\n\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Annotation guidelines:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    These are from the ACE Guidelines for Person:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"3.1 Persons (PER) \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Examples: \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"He is [a real turkey]\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"[The political cat of the year]\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"She’s known as [the brain of the family] \\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Step 2:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Look through the below code.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Implement the appropriate code to calculate these numbers.\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"from pprint import pprint\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# method to read annotation file\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"def annotation_processor(annotation_file):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    annotation_array = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    read_annotation = open(annotation_file)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    for line in read_annotation:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        data = json.loads(line)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        annotation_array.append(data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # here we return an array of the individual annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    return annotation_array\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# calling the annotation processor function\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"annotation_processor(\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\')\\\\\\\\\\\\\\\\n\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"reference_annotations = annotation_processor(\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\')\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"my_annotations = annotation_processor(\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\')\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"def compare_annotations(reference_annotations, my_annotations):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    num_matches = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # you will need to implement this method\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # {\\\\'label\\\\': [\\\\'Person\\\\'],\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # \\\\'points\\\\': [{\\\\'start\\\\': 85,\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    #  \\\\'end\\\\': 116,\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    #  \\\\'text\\\\': \\\\'A group of students and teachers\\\\'}]}\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # that is the character offset is correct\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    return num_matches, num_non_matches\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    num_annotations_in_reference = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    num_annotations_in_mine = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # we want this method to calculate these two numbers\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # num_matches should simply count all the cases where we \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    num_matches = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    num_partial_match = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    for annotation in reference_annotation_array:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        for my_annotation in my_annotation_array:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"            if (annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == my_annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\"]):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\\\\\\\"], my_annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        # implement the sum of the temp_num_matches to the num_matches\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    return num_matches, num_non_matches\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"print(compare_annotation_files(reference_annotations, my_annotations))\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Step 3:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"With the numbers now available, try to determine the Cohen\\\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"The rest of the formula should be as discussed in class.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Report the numbers you calculate.\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Step 4:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    A brief explanation of the Cohen\\\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Step 5:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Now you will compare the output of two extractors over a small dataset of news.\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"import spacy\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# here we are just using two different spacy models.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# you will need to ensure that you have both models installed\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"model_1 = spacy.load(\\\\\\\\\\\\\\\\\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"model_2 = spacy.load(\\\\\\\\\\\\\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"from os import listdir\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"from os.path import isfile, join\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"dir_base = \\\\\\\\\\\\\\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"####\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"####\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"def read_file(filename):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    input_file_text = open(filename , encoding=\\\\'utf-8\\\\').read()\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    return input_file_text\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"def read_directory_files(directory):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    file_texts = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    for f in files:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        file_text = read_file(join(directory, f))\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        print(file_text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"        file_texts.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\":f, \\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_text })\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    return file_texts\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# here we will generate the list that contains all the files and their contents\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"text_corpus = read_directory_files(dir_base)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"print(text_corpus)\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# extract entities\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"def get_entities(document_text, model):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    analyzed_doc = model(document_text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # here we are just limiting to a small set of entity types\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\\\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\"GPE\\\\\\\\\\\\\\\\\\\\\\\\\\\"]]\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    return entities\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    print(reference_entities)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    print(test_entities)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # how many of the same entities are returned in the test entity set\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # test entity set and also if entities are not retrieved\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # are not in the reference entity set as well\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    correct_identified_entities = 0 \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # count the number of items in the test set \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # that are also in the reference set\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    correct_unidentified_entities = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # count the number of items that are in the reference set \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # that are not in the test set\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    spurious_identified_entites = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # count the number of items in the test set that are not in \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # the reference set\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # item is in the reference entity set\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # correct_identified_entities number\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    ###\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # Your code goes here\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    ###\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"overall_correct_identified_entities = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"overall_correct_unidentified_entities = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"overall_spurious_identified_entites = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"for document in text_corpus:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # below you will see that entities_1 is from model_1\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # you can make a decision about which model output will be the reference output\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    entities_1 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\"], model_1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    entities_2 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\"], model_2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    # increment the overall variables\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# now that you are outside the loop, determine the following values\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# what is the overall precision and recall?\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"# does this change if you change the reference model?\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Step 6: \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\\\'t using a normal evaluation set, feel free to speculate as you wish.\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"markdown\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": [\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"Extra Credit: \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"    \\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"   ]\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"cell_type\\\\\\\\\\\": \\\\\\\\\\\"code\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"execution_count\\\\\\\\\\\": null,\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"metadata\\\\\\\\\\\": {},\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"outputs\\\\\\\\\\\": [],\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"source\\\\\\\\\\\": []\\\\\\\\n\\\",\\\\n      \\\"  }\\\\\\\\n\\\",\\\\n      \\\" ],\\\\\\\\n\\\",\\\\n      \\\" \\\\\\\\\\\"metadata\\\\\\\\\\\": {\\\\\\\\n\\\",\\\\n      \\\"  \\\\\\\\\\\"kernelspec\\\\\\\\\\\": {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"display_name\\\\\\\\\\\": \\\\\\\\\\\"Python 3\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"language\\\\\\\\\\\": \\\\\\\\\\\"python\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"name\\\\\\\\\\\": \\\\\\\\\\\"python3\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"  },\\\\\\\\n\\\",\\\\n      \\\"  \\\\\\\\\\\"language_info\\\\\\\\\\\": {\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"codemirror_mode\\\\\\\\\\\": {\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"name\\\\\\\\\\\": \\\\\\\\\\\"ipython\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"    \\\\\\\\\\\"version\\\\\\\\\\\": 3\\\\\\\\n\\\",\\\\n      \\\"   },\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"file_extension\\\\\\\\\\\": \\\\\\\\\\\".py\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"mimetype\\\\\\\\\\\": \\\\\\\\\\\"text/x-python\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"name\\\\\\\\\\\": \\\\\\\\\\\"python\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"nbconvert_exporter\\\\\\\\\\\": \\\\\\\\\\\"python\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"pygments_lexer\\\\\\\\\\\": \\\\\\\\\\\"ipython3\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n      \\\"   \\\\\\\\\\\"version\\\\\\\\\\\": \\\\\\\\\\\"3.7.2\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n      \\\"  }\\\\\\\\n\\\",\\\\n      \\\" },\\\\\\\\n\\\",\\\\n      \\\" \\\\\\\\\\\"nbformat\\\\\\\\\\\": 4,\\\\\\\\n\\\",\\\\n      \\\" \\\\\\\\\\\"nbformat_minor\\\\\\\\\\\": 2\\\\\\\\n\\\",\\\\n      \\\"}\\\\\\\\n\\\"\\\\n     ]\\\\n    },\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"\\\\\\\\n\\\"\\\\n     ]\\\\n    },\\\\n    {\\\\n     \\\"name\\\": \\\"stderr\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"IOPub data rate exceeded.\\\\\\\\n\\\",\\\\n      \\\"The notebook server will temporarily stop sending output\\\\\\\\n\\\",\\\\n      \\\"to the client in order to avoid crashing it.\\\\\\\\n\\\",\\\\n      \\\"To change this limit, set the config variable\\\\\\\\n\\\",\\\\n      \\\"`--NotebookApp.iopub_data_rate_limit`.\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\n\\\",\\\\n      \\\"Current values:\\\\\\\\n\\\",\\\\n      \\\"NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\\\\\\\\n\\\",\\\\n      \\\"NotebookApp.rate_limit_window=3.0 (secs)\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\n\\\"\\\\n     ]\\\\n    },\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":379,\\\\\\\\\\\"end\\\\\\\\\\\":386,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":74,\\\\\\\\\\\"end\\\\\\\\\\\":79,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Hardin\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":64,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":55,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Jonathan Blackmon\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1586954510000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1586954510000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"CORRECT\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":453,\\\\\\\\\\\"end\\\\\\\\\\\":460,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Morrison\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":79,\\\\\\\\\\\"end\\\\\\\\\\\":91,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Peter O’Neill\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":32,\\\\\\\\\\\"end\\\\\\\\\\\":39,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Morrison\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":26,\\\\\\\\\\\"end\\\\\\\\\\\":39,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Scott Morrison\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1586954448000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1586954448000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":0,\\\\\\\\\\\"end\\\\\\\\\\\":10,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Joe Montana\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1586954477000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1586954477000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":816,\\\\\\\\\\\"end\\\\\\\\\\\":825,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":701,\\\\\\\\\\\"end\\\\\\\\\\\":710,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":588,\\\\\\\\\\\"end\\\\\\\\\\\":594,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Merritt\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":576,\\\\\\\\\\\"end\\\\\\\\\\\":581,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Walker\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":532,\\\\\\\\\\\"end\\\\\\\\\\\":537,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Walker\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":501,\\\\\\\\\\\"end\\\\\\\\\\\":510,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":224,\\\\\\\\\\\"end\\\\\\\\\\\":230,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Merritt\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":218,\\\\\\\\\\\"end\\\\\\\\\\\":229,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Piper Merrit\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":183,\\\\\\\\\\\"end\\\\\\\\\\\":192,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":25,\\\\\\\\\\\"end\\\\\\\\\\\":34,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"John Deere\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1586954335000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1586954335000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"{\\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":44,\\\\\\\\\\\"end\\\\\\\\\\\":62,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"George Washington’s\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1586954354000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1586954354000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"NONE\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\n\\\"\\\\n     ]\\\\n    },\\\\n    {\\\\n     \\\"name\\\": \\\"stderr\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"IOPub data rate exceeded.\\\\\\\\n\\\",\\\\n      \\\"The notebook server will temporarily stop sending output\\\\\\\\n\\\",\\\\n      \\\"to the client in order to avoid crashing it.\\\\\\\\n\\\",\\\\n      \\\"To change this limit, set the config variable\\\\\\\\n\\\",\\\\n      \\\"`--NotebookApp.iopub_data_rate_limit`.\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\n\\\",\\\\n      \\\"Current values:\\\\\\\\n\\\",\\\\n      \\\"NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\\\\\\\\n\\\",\\\\n      \\\"NotebookApp.rate_limit_window=3.0 (secs)\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\n\\\"\\\\n     ]\\\\n    },\\\\n    {\\\\n     \\\"name\\\": \\\"stdout\\\",\\\\n     \\\"output_type\\\": \\\"stream\\\",\\\\n     \\\"text\\\": [\\\\n      \\\"\\\\\\\\n\\\"\\\\n     ]\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"#dir_base = \\\\\\\\\\\"/GWU/NATURAL LANGUAGE PROCESSiNG/s20_ds_nlp-master/homeworks/homework_3/news_data\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"####\\\\\\\\n\\\",\\\\n    \\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\n\\\",\\\\n    \\\"####\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"def read_file(filename):\\\\\\\\n\\\",\\\\n    \\\"    input_file_text = open(filename , encoding=\\\\'utf-8\\\\').read()\\\\\\\\n\\\",\\\\n    \\\"    return input_file_text\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"def read_directory_files(directory):\\\\\\\\n\\\",\\\\n    \\\"    file_texts = []\\\\\\\\n\\\",\\\\n    \\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\n\\\",\\\\n    \\\"    for f in files:\\\\\\\\n\\\",\\\\n    \\\"        file_text = read_file(join(directory, f))\\\\\\\\n\\\",\\\\n    \\\"        print(file_text)\\\\\\\\n\\\",\\\\n    \\\"        file_texts.append({\\\\\\\\\\\"file\\\\\\\\\\\":f, \\\\\\\\\\\"content\\\\\\\\\\\": file_text })\\\\\\\\n\\\",\\\\n    \\\"    return file_texts\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"# here we will generate the list that contains all the files and their contents\\\\\\\\n\\\",\\\\n    \\\"text_corpus = read_directory_files(dir_base)\\\\\\\\n\\\",\\\\n    \\\"print(text_corpus)\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 44,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# extract entities\\\\\\\\n\\\",\\\\n    \\\"def get_entities(document_text, model):\\\\\\\\n\\\",\\\\n    \\\"    analyzed_doc = model(document_text)\\\\\\\\n\\\",\\\\n    \\\"    # here we are just limiting to a small set of entity types\\\\\\\\n\\\",\\\\n    \\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\"PER\\\\\\\\\\\", \\\\\\\\\\\"ORG\\\\\\\\\\\", \\\\\\\\\\\"LOC\\\\\\\\\\\", \\\\\\\\\\\"GPE\\\\\\\\\\\"]]\\\\\\\\n\\\",\\\\n    \\\"    return entities\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\n\\\",\\\\n    \\\"    print(reference_entities)\\\\\\\\n\\\",\\\\n    \\\"    print(test_entities)\\\\\\\\n\\\",\\\\n    \\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\n\\\",\\\\n    \\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\n\\\",\\\\n    \\\"    # how many of the same entities are returned in the test entity set\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\n\\\",\\\\n    \\\"    # test entity set and also if entities are not retrieved\\\\\\\\n\\\",\\\\n    \\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\n\\\",\\\\n    \\\"    # are not in the reference entity set as well\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\n\\\",\\\\n    \\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\n\\\",\\\\n    \\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    correct_identified_entities = 0 \\\\\\\\n\\\",\\\\n    \\\"    # count the number of items in the test set \\\\\\\\n\\\",\\\\n    \\\"    # that are also in the reference set\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    correct_unidentified_entities = 0\\\\\\\\n\\\",\\\\n    \\\"    # count the number of items that are in the reference set \\\\\\\\n\\\",\\\\n    \\\"    # that are not in the test set\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    spurious_identified_entites = 0\\\\\\\\n\\\",\\\\n    \\\"    # count the number of items in the test set that are not in \\\\\\\\n\\\",\\\\n    \\\"    # the reference set\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\n\\\",\\\\n    \\\"    # item is in the reference entity set\\\\\\\\n\\\",\\\\n    \\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\n\\\",\\\\n    \\\"    # correct_identified_entities number\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    ###\\\\\\\\n\\\",\\\\n    \\\"    # Your code goes here\\\\\\\\n\\\",\\\\n    \\\"    ###\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": 45,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [\\\\n    {\\\\n     \\\"ename\\\": \\\"ValueError\\\",\\\\n     \\\"evalue\\\": \\\"[E088] Text of length 2211708 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you\\\\'re not using the parser or NER, it\\\\'s probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\\",\\\\n     \\\"output_type\\\": \\\"error\\\",\\\\n     \\\"traceback\\\": [\\\\n      \\\"\\\\\\\\u001b[1;31m---------------------------------------------------------------------------\\\\\\\\u001b[0m\\\",\\\\n      \\\"\\\\\\\\u001b[1;31mValueError\\\\\\\\u001b[0m                                Traceback (most recent call last)\\\",\\\\n      \\\"\\\\\\\\u001b[1;32m<ipython-input-45-5fe2e813ecf8>\\\\\\\\u001b[0m in \\\\\\\\u001b[0;36m<module>\\\\\\\\u001b[1;34m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      6\\\\\\\\u001b[0m     \\\\\\\\u001b[1;31m# below you will see that entities_1 is from model_1\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      7\\\\\\\\u001b[0m     \\\\\\\\u001b[1;31m# you can make a decision about which model output will be the reference output\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[1;32m----> 8\\\\\\\\u001b[1;33m     \\\\\\\\u001b[0mentities_1\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[0mget_entities\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mdocument\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m[\\\\\\\\u001b[0m\\\\\\\\u001b[1;34m\\\\\\\\\\\"content\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m]\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[0mmodel_1\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0m\\\\\\\\u001b[0;32m      9\\\\\\\\u001b[0m     \\\\\\\\u001b[0mentities_2\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[0mget_entities\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mdocument\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m[\\\\\\\\u001b[0m\\\\\\\\u001b[1;34m\\\\\\\\\\\"content\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m]\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[0mmodel_2\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m     10\\\\\\\\u001b[0m     \\\\\\\\u001b[1;31m#correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\u001b[1;32m<ipython-input-44-627b81386c65>\\\\\\\\u001b[0m in \\\\\\\\u001b[0;36mget_entities\\\\\\\\u001b[1;34m(document_text, model)\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      1\\\\\\\\u001b[0m \\\\\\\\u001b[1;31m# extract entities\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      2\\\\\\\\u001b[0m \\\\\\\\u001b[1;32mdef\\\\\\\\u001b[0m \\\\\\\\u001b[0mget_entities\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mdocument_text\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[0mmodel\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m:\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[1;32m----> 3\\\\\\\\u001b[1;33m     \\\\\\\\u001b[0manalyzed_doc\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[0mmodel\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mdocument_text\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0m\\\\\\\\u001b[0;32m      4\\\\\\\\u001b[0m     \\\\\\\\u001b[1;31m# here we are just limiting to a small set of entity types\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      5\\\\\\\\u001b[0m     \\\\\\\\u001b[0mentities\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m[\\\\\\\\u001b[0m\\\\\\\\u001b[0mentity\\\\\\\\u001b[0m \\\\\\\\u001b[1;32mfor\\\\\\\\u001b[0m \\\\\\\\u001b[0mentity\\\\\\\\u001b[0m \\\\\\\\u001b[1;32min\\\\\\\\u001b[0m \\\\\\\\u001b[0manalyzed_doc\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0ments\\\\\\\\u001b[0m \\\\\\\\u001b[1;32mif\\\\\\\\u001b[0m \\\\\\\\u001b[0mentity\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mlabel_\\\\\\\\u001b[0m \\\\\\\\u001b[1;32min\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m[\\\\\\\\u001b[0m\\\\\\\\u001b[1;34m\\\\\\\\\\\"PER\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[1;34m\\\\\\\\\\\"ORG\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[1;34m\\\\\\\\\\\"LOC\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[1;34m\\\\\\\\\\\"GPE\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m]\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m]\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\Anaconda3\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\spacy\\\\\\\\\\\\\\\\language.py\\\\\\\\u001b[0m in \\\\\\\\u001b[0;36m__call__\\\\\\\\u001b[1;34m(self, text, disable, component_cfg)\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m    423\\\\\\\\u001b[0m         \\\\\\\\u001b[1;32mif\\\\\\\\u001b[0m \\\\\\\\u001b[0mlen\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mtext\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m>\\\\\\\\u001b[0m \\\\\\\\u001b[0mself\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mmax_length\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m:\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m    424\\\\\\\\u001b[0m             raise ValueError(\\\\\\\\n\\\\\\\\u001b[1;32m--> 425\\\\\\\\u001b[1;33m                 \\\\\\\\u001b[0mErrors\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mE088\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mformat\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mlength\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m\\\\\\\\u001b[0mlen\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mtext\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[0mmax_length\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m\\\\\\\\u001b[0mself\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mmax_length\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0m\\\\\\\\u001b[0;32m    426\\\\\\\\u001b[0m             )\\\\\\\\n\\\\\\\\u001b[0;32m    427\\\\\\\\u001b[0m         \\\\\\\\u001b[0mdoc\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[0mself\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mmake_doc\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mtext\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\",\\\\n      \\\"\\\\\\\\u001b[1;31mValueError\\\\\\\\u001b[0m: [E088] Text of length 2211708 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you\\\\'re not using the parser or NER, it\\\\'s probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\\"\\\\n     ]\\\\n    }\\\\n   ],\\\\n   \\\"source\\\": [\\\\n    \\\"overall_correct_identified_entities = 0\\\\\\\\n\\\",\\\\n    \\\"overall_correct_unidentified_entities = 0\\\\\\\\n\\\",\\\\n    \\\"overall_spurious_identified_entites = 0\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"for document in text_corpus:\\\\\\\\n\\\",\\\\n    \\\"    # below you will see that entities_1 is from model_1\\\\\\\\n\\\",\\\\n    \\\"    # you can make a decision about which model output will be the reference output\\\\\\\\n\\\",\\\\n    \\\"    entities_1 = get_entities(document[\\\\\\\\\\\"content\\\\\\\\\\\"], model_1)\\\\\\\\n\\\",\\\\n    \\\"    entities_2 = get_entities(document[\\\\\\\\\\\"content\\\\\\\\\\\"], model_2)\\\\\\\\n\\\",\\\\n    \\\"    #correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\",\\\\n    \\\"    # increment the overall variables\\\\\\\\n\\\",\\\\n    \\\"    \\\\\\\\n\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": [\\\\n    \\\"# now that you are outside the loop, determine the following values\\\\\\\\n\\\",\\\\n    \\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\n\\\",\\\\n    \\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"# what is the overall precision and recall?\\\\\\\\n\\\",\\\\n    \\\"# does this change if you change the reference model?\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Step 6: \\\\\\\\n\\\",\\\\n    \\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\\\'t using a normal evaluation set, feel free to speculate as you wish.\\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"markdown\\\",\\\\n   \\\"metadata\\\": {},\\\\n   \\\"source\\\": [\\\\n    \\\"Extra Credit: \\\\\\\\n\\\",\\\\n    \\\"\\\\\\\\n\\\",\\\\n    \\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\n\\\",\\\\n    \\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\n\\\",\\\\n    \\\"    \\\"\\\\n   ]\\\\n  },\\\\n  {\\\\n   \\\"cell_type\\\": \\\"code\\\",\\\\n   \\\"execution_count\\\": null,\\\\n   \\\"metadata\\\": {},\\\\n   \\\"outputs\\\": [],\\\\n   \\\"source\\\": []\\\\n  }\\\\n ],\\\\n \\\"metadata\\\": {\\\\n  \\\"kernelspec\\\": {\\\\n   \\\"display_name\\\": \\\"Python 3\\\",\\\\n   \\\"language\\\": \\\"python\\\",\\\\n   \\\"name\\\": \\\"python3\\\"\\\\n  },\\\\n  \\\"language_info\\\": {\\\\n   \\\"codemirror_mode\\\": {\\\\n    \\\"name\\\": \\\"ipython\\\",\\\\n    \\\"version\\\": 3\\\\n   },\\\\n   \\\"file_extension\\\": \\\".py\\\",\\\\n   \\\"mimetype\\\": \\\"text/x-python\\\",\\\\n   \\\"name\\\": \\\"python\\\",\\\\n   \\\"nbconvert_exporter\\\": \\\"python\\\",\\\\n   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\\\n   \\\"version\\\": \\\"3.7.2\\\"\\\\n  }\\\\n },\\\\n \\\"nbformat\\\": 4,\\\\n \\\"nbformat_minor\\\": 2\\\\n}\\\\n'}, {'file': 'Person_entites.json', 'content': '{\\\"content\\\": \\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\n\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\n\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":379,\\\"end\\\":386,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":74,\\\"end\\\":79,\\\"text\\\":\\\"Hardin\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":64,\\\"end\\\":71,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":55,\\\"end\\\":71,\\\"text\\\":\\\"Jonathan Blackmon\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954510000,\\\"last_updated_at\\\":1586954510000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"CORRECT\\\"}}\\\\n{\\\"content\\\": \\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\n\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\n\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":453,\\\"end\\\":460,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":79,\\\"end\\\":91,\\\"text\\\":\\\"Peter O’Neill\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":32,\\\"end\\\":39,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":26,\\\"end\\\":39,\\\"text\\\":\\\"Scott Morrison\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954448000,\\\"last_updated_at\\\":1586954448000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n{\\\"content\\\": \\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\n\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\n\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":0,\\\"end\\\":10,\\\"text\\\":\\\"Joe Montana\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954477000,\\\"last_updated_at\\\":1586954477000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n{\\\"content\\\": \\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\n\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":816,\\\"end\\\":825,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":701,\\\"end\\\":710,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":588,\\\"end\\\":594,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":576,\\\"end\\\":581,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":532,\\\"end\\\":537,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":501,\\\"end\\\":510,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":224,\\\"end\\\":230,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":218,\\\"end\\\":229,\\\"text\\\":\\\"Piper Merrit\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":183,\\\"end\\\":192,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":25,\\\"end\\\":34,\\\"text\\\":\\\"John Deere\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954335000,\\\"last_updated_at\\\":1586954335000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n{\\\"content\\\": \\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":44,\\\"end\\\":62,\\\"text\\\":\\\"George Washington’s\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954354000,\\\"last_updated_at\\\":1586954354000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n'}]\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"#dir_base = \\\"/GWU/NATURAL LANGUAGE PROCESSiNG/s20_ds_nlp-master/homeworks/homework_3/news_data\\\"\\n\",\n",
      "    \"\\n\",\n",
      "    \"\\n\",\n",
      "    \"####\\n\",\n",
      "    \"# Notice: We are reusing code from class notes... remember these kind of building blocks\\n\",\n",
      "    \"####\\n\",\n",
      "    \"\\n\",\n",
      "    \"def read_file(filename):\\n\",\n",
      "    \"    input_file_text = open(filename , encoding='utf-8').read()\\n\",\n",
      "    \"    return input_file_text\\n\",\n",
      "    \"\\n\",\n",
      "    \"    \\n\",\n",
      "    \"def read_directory_files(directory):\\n\",\n",
      "    \"    file_texts = []\\n\",\n",
      "    \"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\n\",\n",
      "    \"    for f in files:\\n\",\n",
      "    \"        file_text = read_file(join(directory, f))\\n\",\n",
      "    \"        print(file_text)\\n\",\n",
      "    \"        file_texts.append({\\\"file\\\":f, \\\"content\\\": file_text })\\n\",\n",
      "    \"    return file_texts\\n\",\n",
      "    \"    \\n\",\n",
      "    \"# here we will generate the list that contains all the files and their contents\\n\",\n",
      "    \"text_corpus = read_directory_files(dir_base)\\n\",\n",
      "    \"print(text_corpus)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 21,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"# extract entities\\n\",\n",
      "    \"def get_entities(document_text, model):\\n\",\n",
      "    \"    analyzed_doc = model(document_text)\\n\",\n",
      "    \"    # here we are just limiting to a small set of entity types\\n\",\n",
      "    \"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\"PER\\\", \\\"ORG\\\", \\\"LOC\\\", \\\"GPE\\\"]]\\n\",\n",
      "    \"    return entities\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 65,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"for document in text_corpus[:]:\\n\",\n",
      "    \"    entities_1 = get_entities(document[\\\"content\\\"], model_1)\\n\",\n",
      "    \"    entities_2 = get_entities(document[\\\"content\\\"], model_2)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 66,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"28\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 66,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"len(entities_1)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 67,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"23\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 67,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"len(entities_2)\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 69,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"1\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 69,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"match\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 70,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"22\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 70,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"unmatch\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 71,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"data\": {\n",
      "      \"text/plain\": [\n",
      "       \"0\"\n",
      "      ]\n",
      "     },\n",
      "     \"execution_count\": 71,\n",
      "     \"metadata\": {},\n",
      "     \"output_type\": \"execute_result\"\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"spmatch\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 105,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": [\n",
      "    \"def compare_entities_from_document(reference_entities, test_entities):\\n\",\n",
      "    \"    print(reference_entities)\\n\",\n",
      "    \"    print(test_entities)\\n\",\n",
      "    \"    # here we need to calculate how different the reference and test entity sets are\\n\",\n",
      "    \"    # Since we treat the reference entity set as the ground truth we are trying to find \\n\",\n",
      "    \"    # how many of the same entities are returned in the test entity set\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # So we need to identify the correctly identified entities that are also in the \\n\",\n",
      "    \"    # test entity set and also if entities are not retrieved\\n\",\n",
      "    \"    # we also want to count the number of entities that are in the test entity set that\\n\",\n",
      "    \"    # are not in the reference entity set as well\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # in this case we will only concern ourselves with exact matches of entities\\n\",\n",
      "    \"    # thus, a match is the same portion of text and the same entity type\\n\",\n",
      "    \"    # hint: this is easy if you try to use normal comparisons\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    correct_identified_entities = 0 \\n\",\n",
      "    \"    # count the number of items in the test set \\n\",\n",
      "    \"    # that are also in the reference set\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    correct_unidentified_entities = 0\\n\",\n",
      "    \"    # count the number of items that are in the reference set \\n\",\n",
      "    \"    # that are not in the test set\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    spurious_identified_entites = 0\\n\",\n",
      "    \"    # count the number of items in the test set that are not in \\n\",\n",
      "    \"    # the reference set\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    \\n\",\n",
      "    \"    # one way you could do this is to iterate over the test entity list and see if each\\n\",\n",
      "    \"    # item is in the reference entity set\\n\",\n",
      "    \"    # so if an item in the test set is in the reference then you would increment the \\n\",\n",
      "    \"    # correct_identified_entities number\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    ###\\n\",\n",
      "    \"    # Your code goes here\\n\",\n",
      "    \"    ###\\n\",\n",
      "    \"    sp = [value for value in test_entities if value not in reference_entities] \\n\",\n",
      "    \"    match = [value for value in reference_entities if value  in test_entities]\\n\",\n",
      "    \"    unmatch = [value for value in reference_entities if value  not in test_entities]\\n\",\n",
      "    \"    correct_identified_entities=len(match)\\n\",\n",
      "    \"    correct_unidentified_entities=len(unmatch)\\n\",\n",
      "    \"    spurious_identified_entites=len(sp)\\n\",\n",
      "    \"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\n\",\n",
      "    \"    \\n\",\n",
      "    \"\\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 106,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"[Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon]\\n\",\n",
      "      \"[Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus, statement.\\\\n\\\\n“I, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon’s]\\n\",\n",
      "      \"[Text annotations.\\\\n, \\\\\\\"download\\\\, num_matches, non-matches.\\\\n, class.\\\\n, analyzed_doc.ents, entities_1, model_1)\\\\n, entities_2, kernelspec]\\n\",\n",
      "      \"[tagged.\\\\n, \\\\\\\"download\\\\, \\\\\\\"json\\\\, json, the ACE Guidelines, code.\\\\n, pprint, read_annotation:\\\\n\\\", num_non_matches, this:\\\\n\\\", own\\\\n, num_non_matches\\\\n, num_non_matches, num_non_matches, num_non_matches, os.path, dir_base, files:\\\\n, \\\\\\\"GPE\\\\\\\"]]\\\\n\\\", correct_unidentified_entities, entities_1, model_1)\\\\n, correct_unidentified_entities, cell_type, cell_type, ipython]\\n\",\n",
      "      \"[Text annotations.\\\\n, \\\\\\\"download\\\\, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, zip(smallm.items(),smalln.items, zip(valuem, zip(vm.items(),vn.items()):\\\\n\\\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, m:\\\\n, v.items():\\\\n\\\", zip(m, zip(smallm.items(),smalln.items, zip(valuem, zip(vm.items(),vn.items()):\\\\n\\\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, zip(vv1,vv2):\\\\n, num_matches, zip(m, zip(smallm.items(),smalln.items, zip(valuem, zip(vm.items(),vn.items()):\\\\n\\\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, zip(vv1,vv2):\\\\n, num_matches, compare_annotations(mm, non-matches.\\\\n, class.\\\\n, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, FFA.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":816,\\\\\\\"end\\\\\\\":825,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":701,\\\\\\\"end\\\\\\\":710,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":588,\\\\\\\"end\\\\\\\":594,\\\\\\\"text\\\\\\\":\\\\\\\"Merritt\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":576,\\\\\\\"end\\\\\\\":581,\\\\\\\"text\\\\\\\":\\\\\\\"Walker\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":532,\\\\\\\"end\\\\\\\":537,\\\\\\\"text\\\\\\\":\\\\\\\"Walker\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":527,\\\\\\\"end\\\\\\\":537,\\\\\\\"text\\\\\\\":\\\\\\\"Doug Walker\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":501,\\\\\\\"end\\\\\\\":510,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":224,\\\\\\\"end\\\\\\\":230,\\\\\\\"text\\\\\\\":\\\\\\\"Merritt\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":218,\\\\\\\"end\\\\\\\":231,\\\\\\\"text\\\\\\\":\\\\\\\"Piper Merritt,\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":183,\\\\\\\"end\\\\\\\":192,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":25,\\\\\\\"end\\\\\\\":34,\\\\\\\"text\\\\\\\":\\\\\\\"John Deere\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1541085478000,\\\\\\\"last_updated_at\\\\\\\":1541085478000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\", \\\\\\\"A, Mount Vernon estate.\\\\\\\\nA, done\\\\\\\\\\\\, annotations\\\\\\\\n\\\\\\\",\\\\n, num_matches, num_matches, news.\\\\\\\"\\\\n, spacy.load(\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\")\\\\\\\"\\\\n, \\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3, encoding='utf-8').read()\\\\\\\\n\\\\\\\",\\\\n, types\\\\\\\\n\\\\\\\",\\\\n, analyzed_doc.ents, \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\, entities_1, entities_2, IOPub, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, speech.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":453,\\\\\\\"end\\\\\\\":460,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":79,\\\\\\\"end\\\\\\\":91,\\\\\\\"text\\\\\\\":\\\\\\\"Peter O’Neill\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":32,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":26,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Scott Morrison\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954448000,\\\\\\\"last_updated_at\\\\\\\":1586954448000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, \\\\\\\"A, Mount Vernon estate.\\\\\\\\nA, IOPub, dir_base, analyzed_doc.ents, NER, NER, entities_1, model_1\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32, \\\\u001b[0;36mget_entities\\\\u001b[1;34m(document_text, \\\\u001b[0;36m__call__\\\\u001b[1;34m(self,, NER, NER, entities_1, model_1)\\\\n, entities_2, kernelspec]\\n\",\n",
      "      \"[tagged.\\\\n, \\\\\\\"download\\\\, \\\\\\\"json\\\\, json, the ACE Guidelines, code.\\\\n, Polk County Sheriff’s, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus Island.\\\\\\\\n\\\\\\\\nThe, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s, encoding='utf8')\\\\n, num_non_matches, own\\\\n, smallm, smalln, zip(m, n):\\\\n\\\", keym, valuem, keyn, valuen, keyn==\\\\\\\"annotation\\\\\\\":\\\\n, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, m:\\\\n, small.items():\\\\n\\\", vk, vv, v.items():\\\\n\\\", vvl, vv:\\\\n, vvl, vv:\\\\n, vvlk, vvlv, vvl.items():\\\\n, n):\\\\n\\\", num_matches, num_non_matches, this:\\\\n\\\", own\\\\n, smallm, smalln, zip(m, n):\\\\n\\\", keym, valuem, keyn, valuen, keyn==\\\\\\\"annotation\\\\\\\":\\\\n, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches, n):\\\\n\\\", num_matches, num_non_matches, this:\\\\n\\\", own\\\\n, smallm, smalln, zip(m, n):\\\\n\\\", keym, valuem, keyn, valuen, keyn==\\\\\\\"annotation\\\\\\\":\\\\n, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches\\\\n, print(compare_annotation_files(m, n), cell_type, os.path, Polk County Sheriff’s, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, well.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":379,\\\\\\\"end\\\\\\\":386,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":293,\\\\\\\"end\\\\\\\":296,\\\\\\\"text\\\\\\\":\\\\\\\"Irma\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":267,\\\\\\\"end\\\\\\\":272,\\\\\\\"text\\\\\\\":\\\\\\\"Harvey\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":74,\\\\\\\"end\\\\\\\":79,\\\\\\\"text\\\\\\\":\\\\\\\"Hardin\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":64,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":42,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Chief, Papua New Guinea, Sydney, Manus Island.\\\\\\\\n\\\\\\\\nThe, the Pacific for the Pacific’s, Morrison, Montana, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s, period.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":85,\\\\\\\"end\\\\\\\":116,\\\\\\\"text\\\\\\\":\\\\\\\"A, submit\\\\\\\\n\\\\\\\",\\\\n\\\", done\\\\\\\\\\\\, \\\\\\\\\\\\\\\"json\\\\\\\\\\\\, json, the ACE Guidelines, \\\\\\\"She, num_matches, num_non_matches, method\\\\\\\\n\\\\\\\",\\\\n, num_matches, num_non_matches, num_non_matches, isfile, join\\\\\\\"\\\\n, blocks\\\\\\\\n\\\\\\\",\\\\n\\\", input_file_text, \\\\\\\\\\\\\\\"content\\\\\\\\\\\\, types\\\\\\\\n\\\\\\\",\\\\n\\\", entity.label_, \\\\\\\\\\\\\\\"PER\\\\\\\\\\\\, \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\, entities\\\\\\\\n\\\\\\\",\\\\n\\\", type\\\\\\\\n\\\\\\\",\\\\n\\\", correct_unidentified_entities, each\\\\\\\\n\\\\\\\",\\\\n\\\", correct_unidentified_entities, entities_1, correct_unidentified_entities, variables\\\\\\\\n\\\\\\\",\\\\n, IOPub, Polk County Sheriff’s, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus Island.\\\\\\\\n\\\\\\\\nThe, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s, IOPub, files:\\\\n, model):\\\\n\\\", \\\\\\\"GPE\\\\\\\"]]\\\\n\\\", correct_unidentified_entities, entities_1, correct_unidentified_entities, \\\\u001b[0;36mget_entities\\\\u001b[1;34m(document_text, model)\\\\u001b[0m\\\\n\\\\u001b[0;32m, \\\\u001b[0;36m__call__\\\\u001b[1;34m(self, 426\\\\u001b[0m             , entities_1, model_1)\\\\n, correct_unidentified_entities, cell_type, cell_type, ipython]\\n\",\n",
      "      \"[Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon]\\n\",\n",
      "      \"[Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus, statement.\\\\n\\\\n“I, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon’s]\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"for document in text_corpus:\\n\",\n",
      "    \"    # below you will see that entities_1 is from model_1\\n\",\n",
      "    \"    # you can make a decision about which model output will be the reference output\\n\",\n",
      "    \"    entities_1 = get_entities(document[\\\"content\\\"], model_1)\\n\",\n",
      "    \"    entities_2 = get_entities(document[\\\"content\\\"], model_2)\\n\",\n",
      "    \"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\n\",\n",
      "    \"    \\n\",\n",
      "    \"    \\n\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": []\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": 109,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [\n",
      "    {\n",
      "     \"name\": \"stdout\",\n",
      "     \"output_type\": \"stream\",\n",
      "     \"text\": [\n",
      "      \"14\\n\",\n",
      "      \"0.5\\n\",\n",
      "      \"0.5\\n\"\n",
      "     ]\n",
      "    }\n",
      "   ],\n",
      "   \"source\": [\n",
      "    \"# now that you are outside the loop, determine the following values\\n\",\n",
      "    \"#fn=(len(entities_1)+len(entities_2))-(correct_identified_entities+correct_unidentified_entities+spurious_identified_entites)\\n\",\n",
      "    \"precision = correct_identified_entities/(correct_identified_entities+spurious_identified_entites)\\n\",\n",
      "    \"# determine which set of numbers above needed to calculate\\n\",\n",
      "    \"recall = correct_identified_entities/(correct_identified_entities+correct_unidentified_entities)\\n\",\n",
      "    \"# determine which set of numbers above needed to calculate\\n\",\n",
      "    \"print(fn)\\n\",\n",
      "    \"print(precision)\\n\",\n",
      "    \"print(recall)\\n\",\n",
      "    \"# what is the overall precision and recall?\\n\",\n",
      "    \"# does this change if you change the reference model?\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Step 6: \\n\",\n",
      "    \"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren't using a normal evaluation set, feel free to speculate as you wish.\"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"Extra Credit: \\n\",\n",
      "    \"\\n\",\n",
      "    \"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\n\",\n",
      "    \"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\n\",\n",
      "    \"    \"\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"cell_type\": \"code\",\n",
      "   \"execution_count\": null,\n",
      "   \"metadata\": {},\n",
      "   \"outputs\": [],\n",
      "   \"source\": []\n",
      "  }\n",
      " ],\n",
      " \"metadata\": {\n",
      "  \"kernelspec\": {\n",
      "   \"display_name\": \"Python 3\",\n",
      "   \"language\": \"python\",\n",
      "   \"name\": \"python3\"\n",
      "  },\n",
      "  \"language_info\": {\n",
      "   \"codemirror_mode\": {\n",
      "    \"name\": \"ipython\",\n",
      "    \"version\": 3\n",
      "   },\n",
      "   \"file_extension\": \".py\",\n",
      "   \"mimetype\": \"text/x-python\",\n",
      "   \"name\": \"python\",\n",
      "   \"nbconvert_exporter\": \"python\",\n",
      "   \"pygments_lexer\": \"ipython3\",\n",
      "   \"version\": \"3.7.2\"\n",
      "  }\n",
      " },\n",
      " \"nbformat\": 4,\n",
      " \"nbformat_minor\": 2\n",
      "}\n",
      "\n",
      "{\"content\": \"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\n\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\n\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":379,\"end\":386,\"text\":\"Blackmon\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":74,\"end\":79,\"text\":\"Hardin\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":64,\"end\":71,\"text\":\"Blackmon\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":55,\"end\":71,\"text\":\"Jonathan Blackmon\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954510000,\"last_updated_at\":1586954510000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"CORRECT\"}}\n",
      "{\"content\": \"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\n\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\n\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":453,\"end\":460,\"text\":\"Morrison\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":79,\"end\":91,\"text\":\"Peter O’Neill\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":32,\"end\":39,\"text\":\"Morrison\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":26,\"end\":39,\"text\":\"Scott Morrison\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954448000,\"last_updated_at\":1586954448000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "{\"content\": \"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\n\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\n\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":0,\"end\":10,\"text\":\"Joe Montana\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954477000,\"last_updated_at\":1586954477000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "{\"content\": \"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\n\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\n\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":816,\"end\":825,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":701,\"end\":710,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":588,\"end\":594,\"text\":\"Merritt\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":576,\"end\":581,\"text\":\"Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":532,\"end\":537,\"text\":\"Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":501,\"end\":510,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":224,\"end\":230,\"text\":\"Merritt\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":218,\"end\":229,\"text\":\"Piper Merrit\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":183,\"end\":192,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":25,\"end\":34,\"text\":\"John Deere\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954335000,\"last_updated_at\":1586954335000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "{\"content\": \"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":44,\"end\":62,\"text\":\"George Washington’s\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954354000,\"last_updated_at\":1586954354000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
      "\n",
      "[{'file': 'annotated.json', 'content': '{\"content\": \"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\n\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\n\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":379,\"end\":386,\"text\":\"Blackmon\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":293,\"end\":296,\"text\":\"Irma\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":267,\"end\":272,\"text\":\"Harvey\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":74,\"end\":79,\"text\":\"Hardin\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":64,\"end\":71,\"text\":\"Blackmon\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":42,\"end\":71,\"text\":\"Chief Deputy Jonathan Blackmon\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085438000,\"last_updated_at\":1541085438000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n{\"content\": \"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\n\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\n\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":453,\"end\":460,\"text\":\"Morrison\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":315,\"end\":325,\"text\":\"the leaders\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":80,\"end\":91,\"text\":\"eter O’Neill\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":32,\"end\":39,\"text\":\"Morrison\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":26,\"end\":39,\"text\":\"Scott Morrison\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085568000,\"last_updated_at\":1541085568000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n{\"content\": \"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\n\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\n\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":416,\"end\":420,\"text\":\"Clark\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":269,\"end\":275,\"text\":\"Montana\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":245,\"end\":259,\"text\":\"the quarterback\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":40,\"end\":44,\"text\":\"Clark\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":33,\"end\":44,\"text\":\"Dwight Clark\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":4,\"end\":10,\"text\":\"Montana\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":0,\"end\":10,\"text\":\"Joe Montana\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085542000,\"last_updated_at\":1541085542000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n{\"content\": \"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\n\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\n\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":816,\"end\":825,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":701,\"end\":710,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":588,\"end\":594,\"text\":\"Merritt\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":576,\"end\":581,\"text\":\"Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":532,\"end\":537,\"text\":\"Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":527,\"end\":537,\"text\":\"Doug Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":501,\"end\":510,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":224,\"end\":230,\"text\":\"Merritt\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":218,\"end\":231,\"text\":\"Piper Merritt,\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":183,\"end\":192,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":25,\"end\":34,\"text\":\"John Deere\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085478000,\"last_updated_at\":1541085478000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n{\"content\": \"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":85,\"end\":116,\"text\":\"A group of students and teachers\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":44,\"end\":60,\"text\":\"George Washington\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1541085505000,\"last_updated_at\":1541085505000,\"sec_taken\":0,\"last_updated_by\":\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n'}, {'file': 'homework_3.ipynb', 'content': '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"# Homework #3\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\'ve tagged.\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 1:\\\\n\",\\n    \"\\\\n\",\\n    \"Tag data. You\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\n\",\\n    \"\\\\n\",\\n    \"Once you\\'ve created an account you\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\n\",\\n    \"Select the Document Annotation option under Text annotations.\\\\n\",\\n    \"    Provide a dataset name (you can use whatever)\\\\n\",\\n    \"    for the list of entities just input Person\\\\n\",\\n    \"    for the tagging instructions provide whatever you would like\\\\n\",\\n    \"    Then hit submit\\\\n\",\\n    \"    \\\\n\",\\n    \"You will then hit the \\\\\"Upload raw data\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\n\",\\n    \"\\\\n\",\\n    \"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\'ve identified all of them for a single document hit \\\\\"move to done\\\\\". Use the guidelines contained in the next cell.\\\\n\",\\n    \"\\\\n\",\\n    \"When you finish tagging all 5 documents, go into the project you\\'ve tagged and hit the options button in the top right. You will then hit \\\\\"download\\\\\". You will want to have the \\\\\"complete items\\\\\" and \\\\\"json\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\n\",\\n    \"\\\\n\",\\n    \"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Annotation guidelines:\\\\n\",\\n    \"    These are from the ACE Guidelines for Person:\\\\n\",\\n    \"    \\\\n\",\\n    \"3.1 Persons (PER) \\\\n\",\\n    \"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\n\",\\n    \"\\\\n\",\\n    \"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\n\",\\n    \"\\\\n\",\\n    \"Examples: \\\\n\",\\n    \"He is [a real turkey]\\\\n\",\\n    \"[The political cat of the year]\\\\n\",\\n    \"She’s known as [the brain of the family] \"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 2:\\\\n\",\\n    \"\\\\n\",\\n    \"Look through the below code.\\\\n\",\\n    \"\\\\n\",\\n    \"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\n\",\\n    \"\\\\n\",\\n    \"Implement the appropriate code to calculate these numbers.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# import json\\\\n\",\\n    \"from pprint import pprint\\\\n\",\\n    \"\\\\n\",\\n    \"\\\\n\",\\n    \"# method to read annotation file\\\\n\",\\n    \"def annotation_processor(annotation_file):\\\\n\",\\n    \"    annotation_array = []\\\\n\",\\n    \"\\\\n\",\\n    \"    # here we need to be careful and process each line of the annotation file separately\\\\n\",\\n    \"    read_annotation = open(annotation_file)\\\\n\",\\n    \"    for line in read_annotation:\\\\n\",\\n    \"        data = json.loads(line)\\\\n\",\\n    \"        annotation_array.append(data)\\\\n\",\\n    \"\\\\n\",\\n    \"    # here we return an array of the individual annotations\\\\n\",\\n    \"    return annotation_array\\\\n\",\\n    \"    \\\\n\",\\n    \"# calling the annotation processor function\\\\n\",\\n    \"annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# here we will create two objects to store the reference annotations and your own annotations\\\\n\",\\n    \"reference_annotations = annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\n\",\\n    \"\\\\n\",\\n    \"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\n\",\\n    \"my_annotations = annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\n\",\\n    \"\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# you will primarily focus on implementing this compare_annotations method\\\\n\",\\n    \"def compare_annotations(reference_annotations, my_annotations):\\\\n\",\\n    \"    num_matches = 0\\\\n\",\\n    \"    num_non_matches = 0\\\\n\",\\n    \"    # you will need to implement this method\\\\n\",\\n    \"    # The annotations you will get in the parameters are arrays of objects like this:\\\\n\",\\n    \"    # {\\'label\\': [\\'Person\\'],\\\\n\",\\n    \"    # \\'points\\': [{\\'start\\': 85,\\\\n\",\\n    \"    #  \\'end\\': 116,\\\\n\",\\n    \"    #  \\'text\\': \\'A group of students and teachers\\'}]}\\\\n\",\\n    \"    # You will need to compare the annoatations between the reference and your own\\\\n\",\\n    \"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\n\",\\n    \"    # that is the character offset is correct\\\\n\",\\n    \"    \\\\n\",\\n    \"    print(\\\\\"success\\\\\")\\\\n\",\\n    \"    \\\\n\",\\n    \"    return num_matches, num_non_matches\\\\n\",\\n    \"    \\\\n\",\\n    \"\\\\n\",\\n    \"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\n\",\\n    \"    num_annotations_in_reference = 0\\\\n\",\\n    \"    num_annotations_in_mine = 0\\\\n\",\\n    \"    \\\\n\",\\n    \"    # we want this method to calculate these two numbers\\\\n\",\\n    \"    # num_matches should simply count all the cases where we \\\\n\",\\n    \"    num_matches = 0\\\\n\",\\n    \"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\n\",\\n    \"    num_non_matches = 0\\\\n\",\\n    \"    \\\\n\",\\n    \"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\n\",\\n    \"    num_partial_match = 0\\\\n\",\\n    \"    \\\\n\",\\n    \"    for annotation in reference_annotation_array:\\\\n\",\\n    \"        for my_annotation in my_annotation_array:\\\\n\",\\n    \"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\n\",\\n    \"            if (annotation[\\\\\"content\\\\\"] == my_annotation[\\\\\"content\\\\\"]):\\\\n\",\\n    \"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\"annotation\\\\\"], my_annotation[\\\\\"annotation\\\\\"])\\\\n\",\\n    \"        \\\\n\",\\n    \"        # implement the sum of the temp_num_matches to the num_matches\\\\n\",\\n    \"        \\\\n\",\\n    \"    return num_matches, num_non_matches\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"print(compare_annotation_files(reference_annotations, my_annotations))\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 3:\\\\n\",\\n    \"\\\\n\",\\n    \"With the numbers now available, try to determine the Cohen\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\n\",\\n    \"\\\\n\",\\n    \"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\n\",\\n    \"\\\\n\",\\n    \"The rest of the formula should be as discussed in class.\\\\n\",\\n    \"\\\\n\",\\n    \"Report the numbers you calculate.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 4:\\\\n\",\\n    \"\\\\n\",\\n    \"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\n\",\\n    \"    What kind of differences there are between your annotations and the ones I have provided.\\\\n\",\\n    \"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\n\",\\n    \"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\n\",\\n    \"    A brief explanation of the Cohen\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 5:\\\\n\",\\n    \"\\\\n\",\\n    \"Now you will compare the output of two extractors over a small dataset of news.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"import spacy\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# here we are just using two different spacy models.\\\\n\",\\n    \"# you will need to ensure that you have both models installed\\\\n\",\\n    \"model_1 = spacy.load(\\\\\"en_core_web_sm\\\\\")\\\\n\",\\n    \"model_2 = spacy.load(\\\\\"en_core_web_md\\\\\")\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"from os import listdir\\\\n\",\\n    \"from os.path import isfile, join\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"dir_base = \\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\"\\\\n\",\\n    \"\\\\n\",\\n    \"\\\\n\",\\n    \"####\\\\n\",\\n    \"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\n\",\\n    \"####\\\\n\",\\n    \"\\\\n\",\\n    \"def read_file(filename):\\\\n\",\\n    \"    input_file_text = open(filename , encoding=\\'utf-8\\').read()\\\\n\",\\n    \"    return input_file_text\\\\n\",\\n    \"\\\\n\",\\n    \"    \\\\n\",\\n    \"def read_directory_files(directory):\\\\n\",\\n    \"    file_texts = []\\\\n\",\\n    \"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\n\",\\n    \"    for f in files:\\\\n\",\\n    \"        file_text = read_file(join(directory, f))\\\\n\",\\n    \"        print(file_text)\\\\n\",\\n    \"        file_texts.append({\\\\\"file\\\\\":f, \\\\\"content\\\\\": file_text })\\\\n\",\\n    \"    return file_texts\\\\n\",\\n    \"    \\\\n\",\\n    \"# here we will generate the list that contains all the files and their contents\\\\n\",\\n    \"text_corpus = read_directory_files(dir_base)\\\\n\",\\n    \"print(text_corpus)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# extract entities\\\\n\",\\n    \"def get_entities(document_text, model):\\\\n\",\\n    \"    analyzed_doc = model(document_text)\\\\n\",\\n    \"    # here we are just limiting to a small set of entity types\\\\n\",\\n    \"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\"PER\\\\\", \\\\\"ORG\\\\\", \\\\\"LOC\\\\\", \\\\\"GPE\\\\\"]]\\\\n\",\\n    \"    return entities\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"def compare_entities_from_document(reference_entities, test_entities):\\\\n\",\\n    \"    print(reference_entities)\\\\n\",\\n    \"    print(test_entities)\\\\n\",\\n    \"    # here we need to calculate how different the reference and test entity sets are\\\\n\",\\n    \"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\n\",\\n    \"    # how many of the same entities are returned in the test entity set\\\\n\",\\n    \"    \\\\n\",\\n    \"    # So we need to identify the correctly identified entities that are also in the \\\\n\",\\n    \"    # test entity set and also if entities are not retrieved\\\\n\",\\n    \"    # we also want to count the number of entities that are in the test entity set that\\\\n\",\\n    \"    # are not in the reference entity set as well\\\\n\",\\n    \"    \\\\n\",\\n    \"    # in this case we will only concern ourselves with exact matches of entities\\\\n\",\\n    \"    # thus, a match is the same portion of text and the same entity type\\\\n\",\\n    \"    # hint: this is easy if you try to use normal comparisons\\\\n\",\\n    \"    \\\\n\",\\n    \"    correct_identified_entities = 0 \\\\n\",\\n    \"    # count the number of items in the test set \\\\n\",\\n    \"    # that are also in the reference set\\\\n\",\\n    \"    \\\\n\",\\n    \"    correct_unidentified_entities = 0\\\\n\",\\n    \"    # count the number of items that are in the reference set \\\\n\",\\n    \"    # that are not in the test set\\\\n\",\\n    \"    \\\\n\",\\n    \"    spurious_identified_entites = 0\\\\n\",\\n    \"    # count the number of items in the test set that are not in \\\\n\",\\n    \"    # the reference set\\\\n\",\\n    \"    \\\\n\",\\n    \"    \\\\n\",\\n    \"    # one way you could do this is to iterate over the test entity list and see if each\\\\n\",\\n    \"    # item is in the reference entity set\\\\n\",\\n    \"    # so if an item in the test set is in the reference then you would increment the \\\\n\",\\n    \"    # correct_identified_entities number\\\\n\",\\n    \"    \\\\n\",\\n    \"    ###\\\\n\",\\n    \"    # Your code goes here\\\\n\",\\n    \"    ###\\\\n\",\\n    \"    \\\\n\",\\n    \"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\n\",\\n    \"    \\\\n\",\\n    \"\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"overall_correct_identified_entities = 0\\\\n\",\\n    \"overall_correct_unidentified_entities = 0\\\\n\",\\n    \"overall_spurious_identified_entites = 0\\\\n\",\\n    \"\\\\n\",\\n    \"for document in text_corpus:\\\\n\",\\n    \"    # below you will see that entities_1 is from model_1\\\\n\",\\n    \"    # you can make a decision about which model output will be the reference output\\\\n\",\\n    \"    entities_1 = get_entities(document[\\\\\"content\\\\\"], model_1)\\\\n\",\\n    \"    entities_2 = get_entities(document[\\\\\"content\\\\\"], model_2)\\\\n\",\\n    \"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\n\",\\n    \"    \\\\n\",\\n    \"    # increment the overall variables\\\\n\",\\n    \"    \\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# now that you are outside the loop, determine the following values\\\\n\",\\n    \"precision = # determine which set of numbers above needed to calculate\\\\n\",\\n    \"recall = # determine which set of numbers above needed to calculate\\\\n\",\\n    \"\\\\n\",\\n    \"# what is the overall precision and recall?\\\\n\",\\n    \"# does this change if you change the reference model?\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 6: \\\\n\",\\n    \"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\'t using a normal evaluation set, feel free to speculate as you wish.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Extra Credit: \\\\n\",\\n    \"\\\\n\",\\n    \"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\n\",\\n    \"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\n\",\\n    \"    \"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": []\\n  }\\n ],\\n \"metadata\": {\\n  \"kernelspec\": {\\n   \"display_name\": \"Python 3\",\\n   \"language\": \"python\",\\n   \"name\": \"python3\"\\n  },\\n  \"language_info\": {\\n   \"codemirror_mode\": {\\n    \"name\": \"ipython\",\\n    \"version\": 3\\n   },\\n   \"file_extension\": \".py\",\\n   \"mimetype\": \"text/x-python\",\\n   \"name\": \"python\",\\n   \"nbconvert_exporter\": \"python\",\\n   \"pygments_lexer\": \"ipython3\",\\n   \"version\": \"3.7.2\"\\n  }\\n },\\n \"nbformat\": 4,\\n \"nbformat_minor\": 2\\n}\\n'}, {'file': 'homework_3_final.ipynb', 'content': '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"# Homework #3\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\'ve tagged.\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 1:\\\\n\",\\n    \"\\\\n\",\\n    \"Tag data. You\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\n\",\\n    \"\\\\n\",\\n    \"Once you\\'ve created an account you\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\n\",\\n    \"Select the Document Annotation option under Text annotations.\\\\n\",\\n    \"    Provide a dataset name (you can use whatever)\\\\n\",\\n    \"    for the list of entities just input Person\\\\n\",\\n    \"    for the tagging instructions provide whatever you would like\\\\n\",\\n    \"    Then hit submit\\\\n\",\\n    \"    \\\\n\",\\n    \"You will then hit the \\\\\"Upload raw data\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\n\",\\n    \"\\\\n\",\\n    \"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\'ve identified all of them for a single document hit \\\\\"move to done\\\\\". Use the guidelines contained in the next cell.\\\\n\",\\n    \"\\\\n\",\\n    \"When you finish tagging all 5 documents, go into the project you\\'ve tagged and hit the options button in the top right. You will then hit \\\\\"download\\\\\". You will want to have the \\\\\"complete items\\\\\" and \\\\\"json\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\n\",\\n    \"\\\\n\",\\n    \"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Annotation guidelines:\\\\n\",\\n    \"    These are from the ACE Guidelines for Person:\\\\n\",\\n    \"    \\\\n\",\\n    \"3.1 Persons (PER) \\\\n\",\\n    \"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\n\",\\n    \"\\\\n\",\\n    \"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\n\",\\n    \"\\\\n\",\\n    \"Examples: \\\\n\",\\n    \"He is [a real turkey]\\\\n\",\\n    \"[The political cat of the year]\\\\n\",\\n    \"She’s known as [the brain of the family] \"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 2:\\\\n\",\\n    \"\\\\n\",\\n    \"Look through the below code.\\\\n\",\\n    \"\\\\n\",\\n    \"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\n\",\\n    \"\\\\n\",\\n    \"Implement the appropriate code to calculate these numbers.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 1,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"[{\\'content\\': \\'According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\n\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\n\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\',\\\\n\",\\n       \"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 379, \\'end\\': 386, \\'text\\': \\'Blackmon\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 74, \\'end\\': 79, \\'text\\': \\'Hardin\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 64, \\'end\\': 71, \\'text\\': \\'Blackmon\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 55, \\'end\\': 71, \\'text\\': \\'Jonathan Blackmon\\'}]}],\\\\n\",\\n       \"  \\'extras\\': None,\\\\n\",\\n       \"  \\'metadata\\': {\\'first_done_at\\': 1586954510000,\\\\n\",\\n       \"   \\'last_updated_at\\': 1586954510000,\\\\n\",\\n       \"   \\'sec_taken\\': 0,\\\\n\",\\n       \"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\n\",\\n       \"   \\'status\\': \\'done\\',\\\\n\",\\n       \"   \\'evaluation\\': \\'CORRECT\\'}},\\\\n\",\\n       \" {\\'content\\': \\'Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\n\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\n\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\',\\\\n\",\\n       \"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 453, \\'end\\': 460, \\'text\\': \\'Morrison\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 79, \\'end\\': 91, \\'text\\': \\'Peter O’Neill\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 32, \\'end\\': 39, \\'text\\': \\'Morrison\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 26, \\'end\\': 39, \\'text\\': \\'Scott Morrison\\'}]}],\\\\n\",\\n       \"  \\'extras\\': None,\\\\n\",\\n       \"  \\'metadata\\': {\\'first_done_at\\': 1586954448000,\\\\n\",\\n       \"   \\'last_updated_at\\': 1586954448000,\\\\n\",\\n       \"   \\'sec_taken\\': 0,\\\\n\",\\n       \"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\n\",\\n       \"   \\'status\\': \\'done\\',\\\\n\",\\n       \"   \\'evaluation\\': \\'NONE\\'}},\\\\n\",\\n       \" {\\'content\\': \\'Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\n\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\n\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\',\\\\n\",\\n       \"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 0, \\'end\\': 10, \\'text\\': \\'Joe Montana\\'}]}],\\\\n\",\\n       \"  \\'extras\\': None,\\\\n\",\\n       \"  \\'metadata\\': {\\'first_done_at\\': 1586954477000,\\\\n\",\\n       \"   \\'last_updated_at\\': 1586954477000,\\\\n\",\\n       \"   \\'sec_taken\\': 0,\\\\n\",\\n       \"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\n\",\\n       \"   \\'status\\': \\'done\\',\\\\n\",\\n       \"   \\'evaluation\\': \\'NONE\\'}},\\\\n\",\\n       \" {\\'content\\': \\'To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\n\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\',\\\\n\",\\n       \"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 816, \\'end\\': 825, \\'text\\': \\'John Deere\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 701, \\'end\\': 710, \\'text\\': \\'John Deere\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 588, \\'end\\': 594, \\'text\\': \\'Merritt\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 576, \\'end\\': 581, \\'text\\': \\'Walker\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 532, \\'end\\': 537, \\'text\\': \\'Walker\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 501, \\'end\\': 510, \\'text\\': \\'John Deere\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 224, \\'end\\': 230, \\'text\\': \\'Merritt\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 218, \\'end\\': 229, \\'text\\': \\'Piper Merrit\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 183, \\'end\\': 192, \\'text\\': \\'John Deere\\'}]},\\\\n\",\\n       \"   {\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 25, \\'end\\': 34, \\'text\\': \\'John Deere\\'}]}],\\\\n\",\\n       \"  \\'extras\\': None,\\\\n\",\\n       \"  \\'metadata\\': {\\'first_done_at\\': 1586954335000,\\\\n\",\\n       \"   \\'last_updated_at\\': 1586954335000,\\\\n\",\\n       \"   \\'sec_taken\\': 0,\\\\n\",\\n       \"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\n\",\\n       \"   \\'status\\': \\'done\\',\\\\n\",\\n       \"   \\'evaluation\\': \\'NONE\\'}},\\\\n\",\\n       \" {\\'content\\': \\'A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\',\\\\n\",\\n       \"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\n\",\\n       \"    \\'points\\': [{\\'start\\': 44, \\'end\\': 62, \\'text\\': \\'George Washington’s\\'}]}],\\\\n\",\\n       \"  \\'extras\\': None,\\\\n\",\\n       \"  \\'metadata\\': {\\'first_done_at\\': 1586954354000,\\\\n\",\\n       \"   \\'last_updated_at\\': 1586954354000,\\\\n\",\\n       \"   \\'sec_taken\\': 0,\\\\n\",\\n       \"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\n\",\\n       \"   \\'status\\': \\'done\\',\\\\n\",\\n       \"   \\'evaluation\\': \\'NONE\\'}}]\"\\n      ]\\n     },\\n     \"execution_count\": 1,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"# import json\\\\n\",\\n    \"from pprint import pprint\\\\n\",\\n    \"import json\\\\n\",\\n    \"\\\\n\",\\n    \"# method to read annotation file\\\\n\",\\n    \"def annotation_processor(annotation_file):\\\\n\",\\n    \"    annotation_array = []\\\\n\",\\n    \"\\\\n\",\\n    \"    # here we need to be careful and process each line of the annotation file separately\\\\n\",\\n    \"    read_annotation = open(annotation_file,encoding=\\'utf8\\')\\\\n\",\\n    \"    for line in read_annotation:\\\\n\",\\n    \"        data = json.loads(line)\\\\n\",\\n    \"        annotation_array.append(data)\\\\n\",\\n    \"\\\\n\",\\n    \"    # here we return an array of the individual annotations\\\\n\",\\n    \"    return annotation_array\\\\n\",\\n    \"    \\\\n\",\\n    \"# calling the annotation processor function\\\\n\",\\n    \"annotation_processor(\\'Person_entites.json\\')\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 2,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"#import json\\\\n\",\\n    \"#person_dict = json.loads(\\'annotated.json\\')\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 3,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# here we will create two objects to store the reference annotations and your own annotations\\\\n\",\\n    \"reference_annotations = annotation_processor(\\'Person_entites.json\\')\\\\n\",\\n    \"\\\\n\",\\n    \"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\n\",\\n    \"my_annotations = annotation_processor(\\'annotated.json\\')\\\\n\",\\n    \"\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 4,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"m=my_annotations[:]\\\\n\",\\n    \"n=reference_annotations[:]\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 5,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# you will primarily focus on implementing this compare_annotations method\\\\n\",\\n    \"def compare_annotations(m, n):\\\\n\",\\n    \"    num_matches = 0\\\\n\",\\n    \"    num_non_matches = 0\\\\n\",\\n    \"    # you will need to implement this method\\\\n\",\\n    \"    # The annotations you will get in the parameters are arrays of objects like this:\\\\n\",\\n    \"    # {\\'label\\': [\\'Person\\'],\\\\n\",\\n    \"    # \\'points\\': [{\\'start\\': 85,\\\\n\",\\n    \"    #  \\'end\\': 116,\\\\n\",\\n    \"    #  \\'text\\': \\'A group of students and teachers\\'}]}\\\\n\",\\n    \"    # You will need to compare the annoatations between the reference and your own\\\\n\",\\n    \"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\n\",\\n    \"    # that is the character offset is correct\\\\n\",\\n    \"    for smallm,smalln in zip(m,n):\\\\n\",\\n    \"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\n\",\\n    \"                if keym==\\\\\"annotation\\\\\" and keyn==\\\\\"annotation\\\\\":\\\\n\",\\n    \"                    for vm,vn in zip(valuem,valuen):\\\\n\",\\n    \"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\n\",\\n    \"                            if vmk==\\\\\"points\\\\\" and vnk==\\\\\"points\\\\\":\\\\n\",\\n    \"                                for v1,v2 in zip(vmv,vnv):\\\\n\",\\n    \"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\n\",\\n    \"                                        #for v11,v22 in zip(vv1,vv2):\\\\n\",\\n    \"                                        if vv1==vv2:\\\\n\",\\n    \"                                            num_matches = num_matches +1 \\\\n\",\\n    \"                                        elif vv1!=vv2:\\\\n\",\\n    \"                                            num_non_matches=num_non_matches+1\\\\n\",\\n    \"    print(\\\\\"success\\\\\")\\\\n\",\\n    \"    \\\\n\",\\n    \"    return num_matches, num_non_matches\\\\n\",\\n    \"    \\\\n\",\\n    \"\\\\n\",\\n    \"def compare_annotation_files(mm, nn):\\\\n\",\\n    \"    m1,n1=compare_annotations(mm,nn)\\\\n\",\\n    \"    return m1,n1\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 6,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"success\\\\n\",\\n      \"(23, 37)\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"m=my_annotations[:]\\\\n\",\\n    \"n=reference_annotations[:]\\\\n\",\\n    \"print(compare_annotation_files(m, n))\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 7,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"success\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"val1,val2=compare_annotation_files(reference_annotations, my_annotations)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 8,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"23\"\\n      ]\\n     },\\n     \"execution_count\": 8,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"val1\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 9,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"37\"\\n      ]\\n     },\\n     \"execution_count\": 9,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"val2\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 3:\\\\n\",\\n    \"\\\\n\",\\n    \"With the numbers now available, try to determine the Cohen\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\n\",\\n    \"\\\\n\",\\n    \"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\n\",\\n    \"\\\\n\",\\n    \"The rest of the formula should be as discussed in class.\\\\n\",\\n    \"\\\\n\",\\n    \"Report the numbers you calculate.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Cohen Kappa calculation: \\\\n\",\\n    \"        - number of matches:val1: 23\\\\n\",\\n    \"        - number of non matches: val2: 37\\\\n\",\\n    \"        - probability of random agreement: 0.3.\\\\n\",\\n    \"        \\\\n\",\\n    \"## Calculations:\\\\n\",\\n    \"    - Observed Values: 23/60= 0.38\\\\n\",\\n    \"    - Kappa: (0.38-0.3)/(1-0.3)\\\\n\",\\n    \"    - Kappa: 0.11\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 4:\\\\n\",\\n    \"\\\\n\",\\n    \"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\n\",\\n    \"    What kind of differences there are between your annotations and the ones I have provided.\\\\n\",\\n    \"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\n\",\\n    \"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\n\",\\n    \"    A brief explanation of the Cohen\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 5:\\\\n\",\\n    \"\\\\n\",\\n    \"Now you will compare the output of two extractors over a small dataset of news.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 10,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"import spacy\\\\n\",\\n    \"import os\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 11,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# here we are just using two different spacy models.\\\\n\",\\n    \"# you will need to ensure that you have both models installed\\\\n\",\\n    \"model_1 = spacy.load(\\\\\"en_core_web_sm\\\\\")\\\\n\",\\n    \"model_2 = spacy.load(\\\\\"en_core_web_md\\\\\")\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 17,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"from os import listdir\\\\n\",\\n    \"from os.path import isfile, join\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 18,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"\\'C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\user\\\\\\\\\\\\\\\\NLP_HW\\\\\\\\\\\\\\\\HW3\\'\"\\n      ]\\n     },\\n     \"execution_count\": 18,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"os.getcwd()\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 19,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"dir_base = os.getcwd()\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 20,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"{\\\\\"content\\\\\": \\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\n\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\n\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":379,\\\\\"end\\\\\":386,\\\\\"text\\\\\":\\\\\"Blackmon\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":293,\\\\\"end\\\\\":296,\\\\\"text\\\\\":\\\\\"Irma\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":267,\\\\\"end\\\\\":272,\\\\\"text\\\\\":\\\\\"Harvey\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":74,\\\\\"end\\\\\":79,\\\\\"text\\\\\":\\\\\"Hardin\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":64,\\\\\"end\\\\\":71,\\\\\"text\\\\\":\\\\\"Blackmon\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":42,\\\\\"end\\\\\":71,\\\\\"text\\\\\":\\\\\"Chief Deputy Jonathan Blackmon\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085438000,\\\\\"last_updated_at\\\\\":1541085438000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\n\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\n\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":453,\\\\\"end\\\\\":460,\\\\\"text\\\\\":\\\\\"Morrison\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":315,\\\\\"end\\\\\":325,\\\\\"text\\\\\":\\\\\"the leaders\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":80,\\\\\"end\\\\\":91,\\\\\"text\\\\\":\\\\\"eter O’Neill\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":32,\\\\\"end\\\\\":39,\\\\\"text\\\\\":\\\\\"Morrison\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":26,\\\\\"end\\\\\":39,\\\\\"text\\\\\":\\\\\"Scott Morrison\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085568000,\\\\\"last_updated_at\\\\\":1541085568000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\n\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\n\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":416,\\\\\"end\\\\\":420,\\\\\"text\\\\\":\\\\\"Clark\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":269,\\\\\"end\\\\\":275,\\\\\"text\\\\\":\\\\\"Montana\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":245,\\\\\"end\\\\\":259,\\\\\"text\\\\\":\\\\\"the quarterback\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":40,\\\\\"end\\\\\":44,\\\\\"text\\\\\":\\\\\"Clark\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":33,\\\\\"end\\\\\":44,\\\\\"text\\\\\":\\\\\"Dwight Clark\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":4,\\\\\"end\\\\\":10,\\\\\"text\\\\\":\\\\\"Montana\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":0,\\\\\"end\\\\\":10,\\\\\"text\\\\\":\\\\\"Joe Montana\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085542000,\\\\\"last_updated_at\\\\\":1541085542000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\n\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":816,\\\\\"end\\\\\":825,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":701,\\\\\"end\\\\\":710,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":588,\\\\\"end\\\\\":594,\\\\\"text\\\\\":\\\\\"Merritt\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":576,\\\\\"end\\\\\":581,\\\\\"text\\\\\":\\\\\"Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":532,\\\\\"end\\\\\":537,\\\\\"text\\\\\":\\\\\"Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":527,\\\\\"end\\\\\":537,\\\\\"text\\\\\":\\\\\"Doug Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":501,\\\\\"end\\\\\":510,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":224,\\\\\"end\\\\\":230,\\\\\"text\\\\\":\\\\\"Merritt\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":218,\\\\\"end\\\\\":231,\\\\\"text\\\\\":\\\\\"Piper Merritt,\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":183,\\\\\"end\\\\\":192,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":25,\\\\\"end\\\\\":34,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085478000,\\\\\"last_updated_at\\\\\":1541085478000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":85,\\\\\"end\\\\\":116,\\\\\"text\\\\\":\\\\\"A group of students and teachers\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":44,\\\\\"end\\\\\":60,\\\\\"text\\\\\":\\\\\"George Washington\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085505000,\\\\\"last_updated_at\\\\\":1541085505000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"\\\\n\",\\n      \"{\\\\n\",\\n      \" \\\\\"cells\\\\\": [\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# Homework #3\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\'ve tagged.\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 1:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Tag data. You\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Once you\\'ve created an account you\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Select the Document Annotation option under Text annotations.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Provide a dataset name (you can use whatever)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for the list of entities just input Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for the tagging instructions provide whatever you would like\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Then hit submit\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"You will then hit the \\\\\\\\\\\\\"Upload raw data\\\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\'ve identified all of them for a single document hit \\\\\\\\\\\\\"move to done\\\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"When you finish tagging all 5 documents, go into the project you\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\\\"download\\\\\\\\\\\\\". You will want to have the \\\\\\\\\\\\\"complete items\\\\\\\\\\\\\" and \\\\\\\\\\\\\"json\\\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Annotation guidelines:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    These are from the ACE Guidelines for Person:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"3.1 Persons (PER) \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Examples: \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"He is [a real turkey]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"[The political cat of the year]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"She’s known as [the brain of the family] \\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 2:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Look through the below code.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Implement the appropriate code to calculate these numbers.\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# import json\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"from pprint import pprint\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# method to read annotation file\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def annotation_processor(annotation_file):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    annotation_array = []\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    read_annotation = open(annotation_file)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for line in read_annotation:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        data = json.loads(line)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        annotation_array.append(data)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # here we return an array of the individual annotations\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return annotation_array\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# calling the annotation processor function\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"reference_annotations = annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"my_annotations = annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def compare_annotations(reference_annotations, my_annotations):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_non_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # you will need to implement this method\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # \\'points\\': [{\\'start\\': 85,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #  \\'end\\': 116,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #  \\'text\\': \\'A group of students and teachers\\'}]}\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # that is the character offset is correct\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    print(\\\\\\\\\\\\\"success\\\\\\\\\\\\\")\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return num_matches, num_non_matches\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_annotations_in_reference = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_annotations_in_mine = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # we want this method to calculate these two numbers\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # num_matches should simply count all the cases where we \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_non_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_partial_match = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for annotation in reference_annotation_array:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        for my_annotation in my_annotation_array:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"            if (annotation[\\\\\\\\\\\\\"content\\\\\\\\\\\\\"] == my_annotation[\\\\\\\\\\\\\"content\\\\\\\\\\\\\"]):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\"], my_annotation[\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\"])\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        # implement the sum of the temp_num_matches to the num_matches\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return num_matches, num_non_matches\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"print(compare_annotation_files(reference_annotations, my_annotations))\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 3:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"With the numbers now available, try to determine the Cohen\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"The rest of the formula should be as discussed in class.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Report the numbers you calculate.\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 4:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    A brief explanation of the Cohen\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 5:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Now you will compare the output of two extractors over a small dataset of news.\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"import spacy\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# here we are just using two different spacy models.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# you will need to ensure that you have both models installed\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"model_1 = spacy.load(\\\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\\\")\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"model_2 = spacy.load(\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\")\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"from os import listdir\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"from os.path import isfile, join\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"dir_base = \\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"####\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"####\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def read_file(filename):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    input_file_text = open(filename , encoding=\\'utf-8\\').read()\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return input_file_text\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def read_directory_files(directory):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    file_texts = []\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for f in files:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        file_text = read_file(join(directory, f))\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        print(file_text)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        file_texts.append({\\\\\\\\\\\\\"file\\\\\\\\\\\\\":f, \\\\\\\\\\\\\"content\\\\\\\\\\\\\": file_text })\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return file_texts\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# here we will generate the list that contains all the files and their contents\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"text_corpus = read_directory_files(dir_base)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"print(text_corpus)\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# extract entities\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def get_entities(document_text, model):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    analyzed_doc = model(document_text)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # here we are just limiting to a small set of entity types\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\\\"PER\\\\\\\\\\\\\", \\\\\\\\\\\\\"ORG\\\\\\\\\\\\\", \\\\\\\\\\\\\"LOC\\\\\\\\\\\\\", \\\\\\\\\\\\\"GPE\\\\\\\\\\\\\"]]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return entities\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    print(reference_entities)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    print(test_entities)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # how many of the same entities are returned in the test entity set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # test entity set and also if entities are not retrieved\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # are not in the reference entity set as well\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    correct_identified_entities = 0 \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # count the number of items in the test set \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # that are also in the reference set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    correct_unidentified_entities = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # count the number of items that are in the reference set \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # that are not in the test set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    spurious_identified_entites = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # count the number of items in the test set that are not in \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # the reference set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # item is in the reference entity set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # correct_identified_entities number\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    ###\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # Your code goes here\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    ###\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"overall_correct_identified_entities = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"overall_correct_unidentified_entities = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"overall_spurious_identified_entites = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"for document in text_corpus:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # below you will see that entities_1 is from model_1\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # you can make a decision about which model output will be the reference output\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    entities_1 = get_entities(document[\\\\\\\\\\\\\"content\\\\\\\\\\\\\"], model_1)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    entities_2 = get_entities(document[\\\\\\\\\\\\\"content\\\\\\\\\\\\\"], model_2)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # increment the overall variables\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# now that you are outside the loop, determine the following values\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# what is the overall precision and recall?\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# does this change if you change the reference model?\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 6: \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\'t using a normal evaluation set, feel free to speculate as you wish.\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Extra Credit: \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": []\\\\n\",\\n      \"  }\\\\n\",\\n      \" ],\\\\n\",\\n      \" \\\\\"metadata\\\\\": {\\\\n\",\\n      \"  \\\\\"kernelspec\\\\\": {\\\\n\",\\n      \"   \\\\\"display_name\\\\\": \\\\\"Python 3\\\\\",\\\\n\",\\n      \"   \\\\\"language\\\\\": \\\\\"python\\\\\",\\\\n\",\\n      \"   \\\\\"name\\\\\": \\\\\"python3\\\\\"\\\\n\",\\n      \"  },\\\\n\",\\n      \"  \\\\\"language_info\\\\\": {\\\\n\",\\n      \"   \\\\\"codemirror_mode\\\\\": {\\\\n\",\\n      \"    \\\\\"name\\\\\": \\\\\"ipython\\\\\",\\\\n\",\\n      \"    \\\\\"version\\\\\": 3\\\\n\",\\n      \"   },\\\\n\",\\n      \"   \\\\\"file_extension\\\\\": \\\\\".py\\\\\",\\\\n\",\\n      \"   \\\\\"mimetype\\\\\": \\\\\"text/x-python\\\\\",\\\\n\",\\n      \"   \\\\\"name\\\\\": \\\\\"python\\\\\",\\\\n\",\\n      \"   \\\\\"nbconvert_exporter\\\\\": \\\\\"python\\\\\",\\\\n\",\\n      \"   \\\\\"pygments_lexer\\\\\": \\\\\"ipython3\\\\\",\\\\n\",\\n      \"   \\\\\"version\\\\\": \\\\\"3.7.2\\\\\"\\\\n\",\\n      \"  }\\\\n\",\\n      \" },\\\\n\",\\n      \" \\\\\"nbformat\\\\\": 4,\\\\n\",\\n      \" \\\\\"nbformat_minor\\\\\": 2\\\\n\",\\n      \"}\\\\n\"\\n     ]\\n    },\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"\\\\n\",\\n      \"{\\\\n\",\\n      \" \\\\\"cells\\\\\": [\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# Homework #3\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\'ve tagged.\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 1:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Tag data. You\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Once you\\'ve created an account you\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Select the Document Annotation option under Text annotations.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Provide a dataset name (you can use whatever)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for the list of entities just input Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for the tagging instructions provide whatever you would like\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Then hit submit\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"You will then hit the \\\\\\\\\\\\\"Upload raw data\\\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\'ve identified all of them for a single document hit \\\\\\\\\\\\\"move to done\\\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"When you finish tagging all 5 documents, go into the project you\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\\\"download\\\\\\\\\\\\\". You will want to have the \\\\\\\\\\\\\"complete items\\\\\\\\\\\\\" and \\\\\\\\\\\\\"json\\\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Annotation guidelines:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    These are from the ACE Guidelines for Person:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"3.1 Persons (PER) \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Examples: \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"He is [a real turkey]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"[The political cat of the year]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"She’s known as [the brain of the family] \\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 2:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Look through the below code.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Implement the appropriate code to calculate these numbers.\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 24,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"data\\\\\": {\\\\n\",\\n      \"      \\\\\"text/plain\\\\\": [\\\\n\",\\n      \"       \\\\\"[{\\'content\\': \\'According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 379, \\'end\\': 386, \\'text\\': \\'Blackmon\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 74, \\'end\\': 79, \\'text\\': \\'Hardin\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 64, \\'end\\': 71, \\'text\\': \\'Blackmon\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 55, \\'end\\': 71, \\'text\\': \\'Jonathan Blackmon\\'}]}],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'extras\\': None,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'metadata\\': {\\'first_done_at\\': 1586954510000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_at\\': 1586954510000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'sec_taken\\': 0,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'status\\': \\'done\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'evaluation\\': \\'CORRECT\\'}},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\" {\\'content\\': \\'Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 453, \\'end\\': 460, \\'text\\': \\'Morrison\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 79, \\'end\\': 91, \\'text\\': \\'Peter O’Neill\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 32, \\'end\\': 39, \\'text\\': \\'Morrison\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 26, \\'end\\': 39, \\'text\\': \\'Scott Morrison\\'}]}],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'extras\\': None,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'metadata\\': {\\'first_done_at\\': 1586954448000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_at\\': 1586954448000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'sec_taken\\': 0,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'status\\': \\'done\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'evaluation\\': \\'NONE\\'}},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\" {\\'content\\': \\'Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 0, \\'end\\': 10, \\'text\\': \\'Joe Montana\\'}]}],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'extras\\': None,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'metadata\\': {\\'first_done_at\\': 1586954477000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_at\\': 1586954477000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'sec_taken\\': 0,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'status\\': \\'done\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'evaluation\\': \\'NONE\\'}},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\" {\\'content\\': \\'To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 816, \\'end\\': 825, \\'text\\': \\'John Deere\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 701, \\'end\\': 710, \\'text\\': \\'John Deere\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 588, \\'end\\': 594, \\'text\\': \\'Merritt\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 576, \\'end\\': 581, \\'text\\': \\'Walker\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 532, \\'end\\': 537, \\'text\\': \\'Walker\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 501, \\'end\\': 510, \\'text\\': \\'John Deere\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 224, \\'end\\': 230, \\'text\\': \\'Merritt\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 218, \\'end\\': 229, \\'text\\': \\'Piper Merrit\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 183, \\'end\\': 192, \\'text\\': \\'John Deere\\'}]},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 25, \\'end\\': 34, \\'text\\': \\'John Deere\\'}]}],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'extras\\': None,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'metadata\\': {\\'first_done_at\\': 1586954335000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_at\\': 1586954335000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'sec_taken\\': 0,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'status\\': \\'done\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'evaluation\\': \\'NONE\\'}},\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\" {\\'content\\': \\'A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'annotation\\': [{\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"    \\'points\\': [{\\'start\\': 44, \\'end\\': 62, \\'text\\': \\'George Washington’s\\'}]}],\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'extras\\': None,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"  \\'metadata\\': {\\'first_done_at\\': 1586954354000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_at\\': 1586954354000,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'sec_taken\\': 0,\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'last_updated_by\\': \\'GAUua4TByDWq4pqf203jFtL8DoL2\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'status\\': \\'done\\',\\\\\\\\n\\\\\",\\\\n\",\\n      \"       \\\\\"   \\'evaluation\\': \\'NONE\\'}}]\\\\\"\\\\n\",\\n      \"      ]\\\\n\",\\n      \"     },\\\\n\",\\n      \"     \\\\\"execution_count\\\\\": 24,\\\\n\",\\n      \"     \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"execute_result\\\\\"\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# import json\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"from pprint import pprint\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"import json\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# method to read annotation file\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def annotation_processor(annotation_file):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    annotation_array = []\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    read_annotation = open(annotation_file,encoding=\\'utf8\\')\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for line in read_annotation:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        data = json.loads(line)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        annotation_array.append(data)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # here we return an array of the individual annotations\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return annotation_array\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# calling the annotation processor function\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"annotation_processor(\\'Person_entites.json\\')\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 25,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"#import json\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"#person_dict = json.loads(\\'annotated.json\\')\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 26,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"reference_annotations = annotation_processor(\\'Person_entites.json\\')\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"my_annotations = annotation_processor(\\'annotated.json\\')\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 27,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"m=my_annotations[:]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"n=reference_annotations[:]\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 28,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"num_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"num_non_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # you will need to implement this method\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # \\'points\\': [{\\'start\\': 85,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #  \\'end\\': 116,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #  \\'text\\': \\'A group of students and teachers\\'}]}\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # that is the character offset is correct\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"for smallm,smalln in zip(m,n):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"            if keym==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\" and keyn==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                for vm,vn in zip(valuem,valuen):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                    for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                        if vmk==\\\\\\\\\\\\\"points\\\\\\\\\\\\\" and vnk==\\\\\\\\\\\\\"points\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                            for v1,v2 in zip(vmv,vnv):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                    #for v11,v22 in zip(vv1,vv2):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                    if vv1==vv2:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                        num_matches = num_matches +1 \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                    elif vv1!=vv2:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                        num_non_matches=num_non_matches+1\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 29,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"23\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"37\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"print(num_matches)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"print(num_non_matches)\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 30,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 379\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 386\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Blackmon\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 293\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 296\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Irma\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 267\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 272\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Harvey\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 74\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 79\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Hardin\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 64\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 71\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Blackmon\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 42\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 71\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Chief Deputy Jonathan Blackmon\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 453\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 460\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Morrison\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 315\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 325\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value the leaders\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 80\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 91\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value eter O’Neill\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 32\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 39\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Morrison\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 26\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 39\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Scott Morrison\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 416\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 420\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Clark\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 269\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 275\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Montana\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 245\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 259\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value the quarterback\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 40\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 44\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Clark\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 33\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 44\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Dwight Clark\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 4\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 10\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Montana\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 10\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Joe Montana\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 816\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 825\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value John Deere\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 701\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 710\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value John Deere\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 588\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 594\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Merritt\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 576\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 581\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Walker\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 532\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 537\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Walker\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 527\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 537\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Doug Walker\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 501\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 510\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value John Deere\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 224\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 230\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Merritt\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 218\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 231\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value Piper Merritt,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 183\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 192\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value John Deere\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 25\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 34\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value John Deere\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 85\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 116\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value A group of students and teachers\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"********\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"tag Person\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys start\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 44\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys end\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value 60\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"keys text\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"value George Washington\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"#final checking function- done- works!!!\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"m=my_annotations[0:5]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"for small in m:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for key,value in small.items():\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        if key==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"            for v in value:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                print(\\\\\\\\\\\\\"********\\\\\\\\\\\\\")\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                for vk,vv in v.items():\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                    if vk==\\\\\\\\\\\\\"label\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                        for vvl in vv:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                            print(\\\\\\\\\\\\\"tag\\\\\\\\\\\\\",vvl)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                    if vk==\\\\\\\\\\\\\"points\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                        for vvl in vv:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                            for vvlk,vvlv in vvl.items():\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                print(\\\\\\\\\\\\\"keys\\\\\\\\\\\\\",vvlk)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                print(\\\\\\\\\\\\\"value\\\\\\\\\\\\\",vvlv)\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 31,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def compare_annotations(m, n):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_non_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # you will need to implement this method\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # \\'points\\': [{\\'start\\': 85,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #  \\'end\\': 116,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #  \\'text\\': \\'A group of students and teachers\\'}]}\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # that is the character offset is correct\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for smallm,smalln in zip(m,n):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                if keym==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\" and keyn==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                    for vm,vn in zip(valuem,valuen):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                            if vmk==\\\\\\\\\\\\\"points\\\\\\\\\\\\\" and vnk==\\\\\\\\\\\\\"points\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                for v1,v2 in zip(vmv,vnv):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                        #for v11,v22 in zip(vv1,vv2):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                        if vv1==vv2:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                            num_matches = num_matches +1 \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                        elif vv1!=vv2:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                            num_non_matches=num_non_matches+1\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    print(\\\\\\\\\\\\\"success\\\\\\\\\\\\\")\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return num_matches, num_non_matches\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 32,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"success\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"(23, 37)\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"print(compare_annotations(m,n))\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"#print(m1)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"#print(n1)\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 33,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def compare_annotations(m, n):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    num_non_matches = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # you will need to implement this method\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # {\\'label\\': [\\'Person\\'],\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # \\'points\\': [{\\'start\\': 85,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #  \\'end\\': 116,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #  \\'text\\': \\'A group of students and teachers\\'}]}\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # that is the character offset is correct\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for smallm,smalln in zip(m,n):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                if keym==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\" and keyn==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                    for vm,vn in zip(valuem,valuen):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                            if vmk==\\\\\\\\\\\\\"points\\\\\\\\\\\\\" and vnk==\\\\\\\\\\\\\"points\\\\\\\\\\\\\":\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                for v1,v2 in zip(vmv,vnv):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                        #for v11,v22 in zip(vv1,vv2):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                        if vv1==vv2:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                            num_matches = num_matches +1 \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                        elif vv1!=vv2:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"                                            num_non_matches=num_non_matches+1\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    print(\\\\\\\\\\\\\"success\\\\\\\\\\\\\")\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return num_matches, num_non_matches\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def compare_annotation_files(mm, nn):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    m1,n1=compare_annotations(mm,nn)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return m1,n1\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 34,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"success\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"(23, 37)\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"m=my_annotations[:]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"n=reference_annotations[:]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"print(compare_annotation_files(m, n))\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 35,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"success\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"val1,val2=compare_annotation_files(reference_annotations, my_annotations)\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 36,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"data\\\\\": {\\\\n\",\\n      \"      \\\\\"text/plain\\\\\": [\\\\n\",\\n      \"       \\\\\"23\\\\\"\\\\n\",\\n      \"      ]\\\\n\",\\n      \"     },\\\\n\",\\n      \"     \\\\\"execution_count\\\\\": 36,\\\\n\",\\n      \"     \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"execute_result\\\\\"\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"val1\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 37,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"data\\\\\": {\\\\n\",\\n      \"      \\\\\"text/plain\\\\\": [\\\\n\",\\n      \"       \\\\\"37\\\\\"\\\\n\",\\n      \"      ]\\\\n\",\\n      \"     },\\\\n\",\\n      \"     \\\\\"execution_count\\\\\": 37,\\\\n\",\\n      \"     \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"execute_result\\\\\"\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"val2\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 3:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"With the numbers now available, try to determine the Cohen\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"The rest of the formula should be as discussed in class.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Report the numbers you calculate.\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 4:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    A brief explanation of the Cohen\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 5:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Now you will compare the output of two extractors over a small dataset of news.\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 38,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"import spacy\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"import os\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 39,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# here we are just using two different spacy models.\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# you will need to ensure that you have both models installed\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"model_1 = spacy.load(\\\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\\\")\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"model_2 = spacy.load(\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\")\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 40,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"from os import listdir\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"from os.path import isfile, join\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 41,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"data\\\\\": {\\\\n\",\\n      \"      \\\\\"text/plain\\\\\": [\\\\n\",\\n      \"       \\\\\"\\'C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\NLP_HW\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\HW3\\'\\\\\"\\\\n\",\\n      \"      ]\\\\n\",\\n      \"     },\\\\n\",\\n      \"     \\\\\"execution_count\\\\\": 41,\\\\n\",\\n      \"     \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"execute_result\\\\\"\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"os.getcwd()\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 42,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"dir_base = os.getcwd()\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 43,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":379,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":386,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":293,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":296,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Irma\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":267,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":272,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Harvey\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":74,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":79,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Hardin\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":64,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":71,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":42,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":71,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Chief Deputy Jonathan Blackmon\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1541085438000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1541085438000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":453,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":460,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":315,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":325,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"the leaders\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":80,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":91,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"eter O’Neill\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":32,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":39,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":26,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":39,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Scott Morrison\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1541085568000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1541085568000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":416,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":420,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Clark\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":269,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":275,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Montana\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":245,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":259,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"the quarterback\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":40,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":44,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Clark\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":33,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":44,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Dwight Clark\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":4,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":10,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Montana\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":10,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Joe Montana\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1541085542000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1541085542000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":816,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":825,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":701,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":710,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":588,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":594,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":576,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":581,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":532,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":537,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":527,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":537,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Doug Walker\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":501,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":510,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":224,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":230,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":218,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":231,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Piper Merritt,\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":183,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":192,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":25,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":34,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1541085478000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1541085478000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":85,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":116,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"A group of students and teachers\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":44,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":60,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"George Washington\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1541085505000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1541085505000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\" \\\\\\\\\\\\\"cells\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# Homework #3\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\'ve tagged.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Step 1:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Tag data. You\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Once you\\'ve created an account you\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Select the Document Annotation option under Text annotations.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    Provide a dataset name (you can use whatever)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    for the list of entities just input Person\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    for the tagging instructions provide whatever you would like\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    Then hit submit\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"You will then hit the \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Upload raw data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\'ve identified all of them for a single document hit \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"move to done\\\\\\\\\\\\\\\\\\\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"When you finish tagging all 5 documents, go into the project you\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"download\\\\\\\\\\\\\\\\\\\\\\\\\\\\\". You will want to have the \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"complete items\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" and \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Annotation guidelines:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    These are from the ACE Guidelines for Person:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"3.1 Persons (PER) \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Examples: \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"He is [a real turkey]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"[The political cat of the year]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"She’s known as [the brain of the family] \\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Step 2:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Look through the below code.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Implement the appropriate code to calculate these numbers.\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"from pprint import pprint\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# method to read annotation file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"def annotation_processor(annotation_file):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    annotation_array = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    read_annotation = open(annotation_file)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    for line in read_annotation:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        data = json.loads(line)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        annotation_array.append(data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # here we return an array of the individual annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    return annotation_array\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# calling the annotation processor function\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"reference_annotations = annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"my_annotations = annotation_processor(\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"def compare_annotations(reference_annotations, my_annotations):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    num_matches = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # you will need to implement this method\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # {\\'label\\': [\\'Person\\'],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # \\'points\\': [{\\'start\\': 85,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    #  \\'end\\': 116,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    #  \\'text\\': \\'A group of students and teachers\\'}]}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # that is the character offset is correct\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    return num_matches, num_non_matches\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    num_annotations_in_reference = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    num_annotations_in_mine = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # we want this method to calculate these two numbers\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # num_matches should simply count all the cases where we \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    num_matches = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    num_partial_match = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    for annotation in reference_annotation_array:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        for my_annotation in my_annotation_array:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"            if (annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == my_annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], my_annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        # implement the sum of the temp_num_matches to the num_matches\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    return num_matches, num_non_matches\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"print(compare_annotation_files(reference_annotations, my_annotations))\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Step 3:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"With the numbers now available, try to determine the Cohen\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"The rest of the formula should be as discussed in class.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Report the numbers you calculate.\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Step 4:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    A brief explanation of the Cohen\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Step 5:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Now you will compare the output of two extractors over a small dataset of news.\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"import spacy\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# here we are just using two different spacy models.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# you will need to ensure that you have both models installed\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"model_1 = spacy.load(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"model_2 = spacy.load(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"from os import listdir\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"from os.path import isfile, join\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"dir_base = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"####\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"####\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"def read_file(filename):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    input_file_text = open(filename , encoding=\\'utf-8\\').read()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    return input_file_text\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"def read_directory_files(directory):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    file_texts = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    for f in files:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        file_text = read_file(join(directory, f))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        print(file_text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"        file_texts.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":f, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_text })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    return file_texts\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# here we will generate the list that contains all the files and their contents\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"text_corpus = read_directory_files(dir_base)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"print(text_corpus)\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# extract entities\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"def get_entities(document_text, model):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    analyzed_doc = model(document_text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # here we are just limiting to a small set of entity types\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"GPE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    return entities\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    print(reference_entities)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    print(test_entities)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # how many of the same entities are returned in the test entity set\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # test entity set and also if entities are not retrieved\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # are not in the reference entity set as well\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    correct_identified_entities = 0 \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # count the number of items in the test set \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # that are also in the reference set\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    correct_unidentified_entities = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # count the number of items that are in the reference set \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # that are not in the test set\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    spurious_identified_entites = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # count the number of items in the test set that are not in \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # the reference set\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # item is in the reference entity set\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # correct_identified_entities number\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    ###\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # Your code goes here\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    ###\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"overall_correct_identified_entities = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"overall_correct_unidentified_entities = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"overall_spurious_identified_entites = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"for document in text_corpus:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # below you will see that entities_1 is from model_1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # you can make a decision about which model output will be the reference output\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    entities_1 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], model_1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    entities_2 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], model_2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    # increment the overall variables\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# now that you are outside the loop, determine the following values\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# what is the overall precision and recall?\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"# does this change if you change the reference model?\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Step 6: \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\'t using a normal evaluation set, feel free to speculate as you wish.\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"markdown\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": [\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"Extra Credit: \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"    \\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   ]\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\": \\\\\\\\\\\\\"code\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\": null,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {},\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": [],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"source\\\\\\\\\\\\\": []\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  }\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\" ],\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\" \\\\\\\\\\\\\"metadata\\\\\\\\\\\\\": {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  \\\\\\\\\\\\\"kernelspec\\\\\\\\\\\\\": {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"display_name\\\\\\\\\\\\\": \\\\\\\\\\\\\"Python 3\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"language\\\\\\\\\\\\\": \\\\\\\\\\\\\"python\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"name\\\\\\\\\\\\\": \\\\\\\\\\\\\"python3\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  \\\\\\\\\\\\\"language_info\\\\\\\\\\\\\": {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"codemirror_mode\\\\\\\\\\\\\": {\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"name\\\\\\\\\\\\\": \\\\\\\\\\\\\"ipython\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"    \\\\\\\\\\\\\"version\\\\\\\\\\\\\": 3\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"file_extension\\\\\\\\\\\\\": \\\\\\\\\\\\\".py\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\": \\\\\\\\\\\\\"text/x-python\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"name\\\\\\\\\\\\\": \\\\\\\\\\\\\"python\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"nbconvert_exporter\\\\\\\\\\\\\": \\\\\\\\\\\\\"python\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"pygments_lexer\\\\\\\\\\\\\": \\\\\\\\\\\\\"ipython3\\\\\\\\\\\\\",\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"   \\\\\\\\\\\\\"version\\\\\\\\\\\\\": \\\\\\\\\\\\\"3.7.2\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"  }\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\" },\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\" \\\\\\\\\\\\\"nbformat\\\\\\\\\\\\\": 4,\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\" \\\\\\\\\\\\\"nbformat_minor\\\\\\\\\\\\\": 2\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"}\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    },\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    },\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stderr\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"IOPub data rate exceeded.\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"The notebook server will temporarily stop sending output\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"to the client in order to avoid crashing it.\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"To change this limit, set the config variable\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"`--NotebookApp.iopub_data_rate_limit`.\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"Current values:\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"NotebookApp.rate_limit_window=3.0 (secs)\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    },\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":379,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":386,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":74,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":79,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Hardin\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":64,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":71,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":55,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":71,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Jonathan Blackmon\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1586954510000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1586954510000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"CORRECT\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":453,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":460,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":79,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":91,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Peter O’Neill\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":32,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":39,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":26,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":39,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Scott Morrison\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1586954448000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1586954448000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":10,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Joe Montana\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1586954477000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1586954477000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":816,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":825,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":701,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":710,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":588,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":594,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":576,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":581,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":532,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":537,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":501,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":510,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":224,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":230,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":218,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":229,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Piper Merrit\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":183,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":192,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":25,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":34,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1586954335000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1586954335000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"{\\\\\\\\\\\\\"content\\\\\\\\\\\\\": \\\\\\\\\\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":44,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":62,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"George Washington’s\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1586954354000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1586954354000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    },\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stderr\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"IOPub data rate exceeded.\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"The notebook server will temporarily stop sending output\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"to the client in order to avoid crashing it.\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"To change this limit, set the config variable\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"`--NotebookApp.iopub_data_rate_limit`.\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"Current values:\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"NotebookApp.rate_limit_window=3.0 (secs)\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    },\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\n\",\\n      \"     \\\\\"text\\\\\": [\\\\n\",\\n      \"      \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"#dir_base = \\\\\\\\\\\\\"/GWU/NATURAL LANGUAGE PROCESSiNG/s20_ds_nlp-master/homeworks/homework_3/news_data\\\\\\\\\\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"####\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"####\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def read_file(filename):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    input_file_text = open(filename , encoding=\\'utf-8\\').read()\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return input_file_text\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def read_directory_files(directory):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    file_texts = []\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    for f in files:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        file_text = read_file(join(directory, f))\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        print(file_text)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"        file_texts.append({\\\\\\\\\\\\\"file\\\\\\\\\\\\\":f, \\\\\\\\\\\\\"content\\\\\\\\\\\\\": file_text })\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return file_texts\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# here we will generate the list that contains all the files and their contents\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"text_corpus = read_directory_files(dir_base)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"print(text_corpus)\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 44,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# extract entities\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"def get_entities(document_text, model):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    analyzed_doc = model(document_text)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # here we are just limiting to a small set of entity types\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\\\"PER\\\\\\\\\\\\\", \\\\\\\\\\\\\"ORG\\\\\\\\\\\\\", \\\\\\\\\\\\\"LOC\\\\\\\\\\\\\", \\\\\\\\\\\\\"GPE\\\\\\\\\\\\\"]]\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return entities\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    print(reference_entities)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    print(test_entities)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # how many of the same entities are returned in the test entity set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # test entity set and also if entities are not retrieved\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # are not in the reference entity set as well\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    correct_identified_entities = 0 \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # count the number of items in the test set \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # that are also in the reference set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    correct_unidentified_entities = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # count the number of items that are in the reference set \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # that are not in the test set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    spurious_identified_entites = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # count the number of items in the test set that are not in \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # the reference set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # item is in the reference entity set\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # correct_identified_entities number\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    ###\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # Your code goes here\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    ###\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": 45,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [\\\\n\",\\n      \"    {\\\\n\",\\n      \"     \\\\\"ename\\\\\": \\\\\"ValueError\\\\\",\\\\n\",\\n      \"     \\\\\"evalue\\\\\": \\\\\"[E088] Text of length 2211708 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you\\'re not using the parser or NER, it\\'s probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\\\\",\\\\n\",\\n      \"     \\\\\"output_type\\\\\": \\\\\"error\\\\\",\\\\n\",\\n      \"     \\\\\"traceback\\\\\": [\\\\n\",\\n      \"      \\\\\"\\\\\\\\u001b[1;31m---------------------------------------------------------------------------\\\\\\\\u001b[0m\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\u001b[1;31mValueError\\\\\\\\u001b[0m                                Traceback (most recent call last)\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\u001b[1;32m<ipython-input-45-5fe2e813ecf8>\\\\\\\\u001b[0m in \\\\\\\\u001b[0;36m<module>\\\\\\\\u001b[1;34m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      6\\\\\\\\u001b[0m     \\\\\\\\u001b[1;31m# below you will see that entities_1 is from model_1\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      7\\\\\\\\u001b[0m     \\\\\\\\u001b[1;31m# you can make a decision about which model output will be the reference output\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[1;32m----> 8\\\\\\\\u001b[1;33m     \\\\\\\\u001b[0mentities_1\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[0mget_entities\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mdocument\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m[\\\\\\\\u001b[0m\\\\\\\\u001b[1;34m\\\\\\\\\\\\\"content\\\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m]\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[0mmodel_1\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0m\\\\\\\\u001b[0;32m      9\\\\\\\\u001b[0m     \\\\\\\\u001b[0mentities_2\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[0mget_entities\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mdocument\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m[\\\\\\\\u001b[0m\\\\\\\\u001b[1;34m\\\\\\\\\\\\\"content\\\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m]\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[0mmodel_2\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m     10\\\\\\\\u001b[0m     \\\\\\\\u001b[1;31m#correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\u001b[1;32m<ipython-input-44-627b81386c65>\\\\\\\\u001b[0m in \\\\\\\\u001b[0;36mget_entities\\\\\\\\u001b[1;34m(document_text, model)\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      1\\\\\\\\u001b[0m \\\\\\\\u001b[1;31m# extract entities\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      2\\\\\\\\u001b[0m \\\\\\\\u001b[1;32mdef\\\\\\\\u001b[0m \\\\\\\\u001b[0mget_entities\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mdocument_text\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[0mmodel\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m:\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[1;32m----> 3\\\\\\\\u001b[1;33m     \\\\\\\\u001b[0manalyzed_doc\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[0mmodel\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mdocument_text\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0m\\\\\\\\u001b[0;32m      4\\\\\\\\u001b[0m     \\\\\\\\u001b[1;31m# here we are just limiting to a small set of entity types\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m      5\\\\\\\\u001b[0m     \\\\\\\\u001b[0mentities\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m[\\\\\\\\u001b[0m\\\\\\\\u001b[0mentity\\\\\\\\u001b[0m \\\\\\\\u001b[1;32mfor\\\\\\\\u001b[0m \\\\\\\\u001b[0mentity\\\\\\\\u001b[0m \\\\\\\\u001b[1;32min\\\\\\\\u001b[0m \\\\\\\\u001b[0manalyzed_doc\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0ments\\\\\\\\u001b[0m \\\\\\\\u001b[1;32mif\\\\\\\\u001b[0m \\\\\\\\u001b[0mentity\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mlabel_\\\\\\\\u001b[0m \\\\\\\\u001b[1;32min\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m[\\\\\\\\u001b[0m\\\\\\\\u001b[1;34m\\\\\\\\\\\\\"PER\\\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[1;34m\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[1;34m\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[1;34m\\\\\\\\\\\\\"GPE\\\\\\\\\\\\\"\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m]\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m]\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\Anaconda3\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\spacy\\\\\\\\\\\\\\\\language.py\\\\\\\\u001b[0m in \\\\\\\\u001b[0;36m__call__\\\\\\\\u001b[1;34m(self, text, disable, component_cfg)\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m    423\\\\\\\\u001b[0m         \\\\\\\\u001b[1;32mif\\\\\\\\u001b[0m \\\\\\\\u001b[0mlen\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mtext\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m>\\\\\\\\u001b[0m \\\\\\\\u001b[0mself\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mmax_length\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m:\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m    424\\\\\\\\u001b[0m             raise ValueError(\\\\\\\\n\\\\\\\\u001b[1;32m--> 425\\\\\\\\u001b[1;33m                 \\\\\\\\u001b[0mErrors\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mE088\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mformat\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mlength\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m\\\\\\\\u001b[0mlen\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mtext\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m,\\\\\\\\u001b[0m \\\\\\\\u001b[0mmax_length\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m\\\\\\\\u001b[0mself\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mmax_length\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0m\\\\\\\\u001b[0;32m    426\\\\\\\\u001b[0m             )\\\\\\\\n\\\\\\\\u001b[0;32m    427\\\\\\\\u001b[0m         \\\\\\\\u001b[0mdoc\\\\\\\\u001b[0m \\\\\\\\u001b[1;33m=\\\\\\\\u001b[0m \\\\\\\\u001b[0mself\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m.\\\\\\\\u001b[0m\\\\\\\\u001b[0mmake_doc\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m(\\\\\\\\u001b[0m\\\\\\\\u001b[0mtext\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m)\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\",\\\\n\",\\n      \"      \\\\\"\\\\\\\\u001b[1;31mValueError\\\\\\\\u001b[0m: [E088] Text of length 2211708 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you\\'re not using the parser or NER, it\\'s probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\\\\"\\\\n\",\\n      \"     ]\\\\n\",\\n      \"    }\\\\n\",\\n      \"   ],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"overall_correct_identified_entities = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"overall_correct_unidentified_entities = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"overall_spurious_identified_entites = 0\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"for document in text_corpus:\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # below you will see that entities_1 is from model_1\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # you can make a decision about which model output will be the reference output\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    entities_1 = get_entities(document[\\\\\\\\\\\\\"content\\\\\\\\\\\\\"], model_1)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    entities_2 = get_entities(document[\\\\\\\\\\\\\"content\\\\\\\\\\\\\"], model_2)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    #correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    # increment the overall variables\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\\\\n\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"# now that you are outside the loop, determine the following values\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# what is the overall precision and recall?\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"# does this change if you change the reference model?\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Step 6: \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\'t using a normal evaluation set, feel free to speculate as you wish.\\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"source\\\\\": [\\\\n\",\\n      \"    \\\\\"Extra Credit: \\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\n\\\\\",\\\\n\",\\n      \"    \\\\\"    \\\\\"\\\\n\",\\n      \"   ]\\\\n\",\\n      \"  },\\\\n\",\\n      \"  {\\\\n\",\\n      \"   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\n\",\\n      \"   \\\\\"execution_count\\\\\": null,\\\\n\",\\n      \"   \\\\\"metadata\\\\\": {},\\\\n\",\\n      \"   \\\\\"outputs\\\\\": [],\\\\n\",\\n      \"   \\\\\"source\\\\\": []\\\\n\",\\n      \"  }\\\\n\",\\n      \" ],\\\\n\",\\n      \" \\\\\"metadata\\\\\": {\\\\n\",\\n      \"  \\\\\"kernelspec\\\\\": {\\\\n\",\\n      \"   \\\\\"display_name\\\\\": \\\\\"Python 3\\\\\",\\\\n\",\\n      \"   \\\\\"language\\\\\": \\\\\"python\\\\\",\\\\n\",\\n      \"   \\\\\"name\\\\\": \\\\\"python3\\\\\"\\\\n\",\\n      \"  },\\\\n\",\\n      \"  \\\\\"language_info\\\\\": {\\\\n\",\\n      \"   \\\\\"codemirror_mode\\\\\": {\\\\n\",\\n      \"    \\\\\"name\\\\\": \\\\\"ipython\\\\\",\\\\n\",\\n      \"    \\\\\"version\\\\\": 3\\\\n\",\\n      \"   },\\\\n\",\\n      \"   \\\\\"file_extension\\\\\": \\\\\".py\\\\\",\\\\n\",\\n      \"   \\\\\"mimetype\\\\\": \\\\\"text/x-python\\\\\",\\\\n\",\\n      \"   \\\\\"name\\\\\": \\\\\"python\\\\\",\\\\n\",\\n      \"   \\\\\"nbconvert_exporter\\\\\": \\\\\"python\\\\\",\\\\n\",\\n      \"   \\\\\"pygments_lexer\\\\\": \\\\\"ipython3\\\\\",\\\\n\",\\n      \"   \\\\\"version\\\\\": \\\\\"3.7.2\\\\\"\\\\n\",\\n      \"  }\\\\n\",\\n      \" },\\\\n\",\\n      \" \\\\\"nbformat\\\\\": 4,\\\\n\",\\n      \" \\\\\"nbformat_minor\\\\\": 2\\\\n\",\\n      \"}\\\\n\"\\n     ]\\n    },\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\n\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\n\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":379,\\\\\"end\\\\\":386,\\\\\"text\\\\\":\\\\\"Blackmon\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":74,\\\\\"end\\\\\":79,\\\\\"text\\\\\":\\\\\"Hardin\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":64,\\\\\"end\\\\\":71,\\\\\"text\\\\\":\\\\\"Blackmon\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":55,\\\\\"end\\\\\":71,\\\\\"text\\\\\":\\\\\"Jonathan Blackmon\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954510000,\\\\\"last_updated_at\\\\\":1586954510000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"CORRECT\\\\\"}}\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\n\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\n\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":453,\\\\\"end\\\\\":460,\\\\\"text\\\\\":\\\\\"Morrison\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":79,\\\\\"end\\\\\":91,\\\\\"text\\\\\":\\\\\"Peter O’Neill\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":32,\\\\\"end\\\\\":39,\\\\\"text\\\\\":\\\\\"Morrison\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":26,\\\\\"end\\\\\":39,\\\\\"text\\\\\":\\\\\"Scott Morrison\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954448000,\\\\\"last_updated_at\\\\\":1586954448000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\n\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\n\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":0,\\\\\"end\\\\\":10,\\\\\"text\\\\\":\\\\\"Joe Montana\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954477000,\\\\\"last_updated_at\\\\\":1586954477000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\n\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":816,\\\\\"end\\\\\":825,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":701,\\\\\"end\\\\\":710,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":588,\\\\\"end\\\\\":594,\\\\\"text\\\\\":\\\\\"Merritt\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":576,\\\\\"end\\\\\":581,\\\\\"text\\\\\":\\\\\"Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":532,\\\\\"end\\\\\":537,\\\\\"text\\\\\":\\\\\"Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":501,\\\\\"end\\\\\":510,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":224,\\\\\"end\\\\\":230,\\\\\"text\\\\\":\\\\\"Merritt\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":218,\\\\\"end\\\\\":229,\\\\\"text\\\\\":\\\\\"Piper Merrit\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":183,\\\\\"end\\\\\":192,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":25,\\\\\"end\\\\\":34,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954335000,\\\\\"last_updated_at\\\\\":1586954335000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"{\\\\\"content\\\\\": \\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":44,\\\\\"end\\\\\":62,\\\\\"text\\\\\":\\\\\"George Washington’s\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954354000,\\\\\"last_updated_at\\\\\":1586954354000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\n\",\\n      \"\\\\n\",\\n      \"[{\\'file\\': \\'annotated.json\\', \\'content\\': \\'{\\\\\"content\\\\\": \\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":379,\\\\\"end\\\\\":386,\\\\\"text\\\\\":\\\\\"Blackmon\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":293,\\\\\"end\\\\\":296,\\\\\"text\\\\\":\\\\\"Irma\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":267,\\\\\"end\\\\\":272,\\\\\"text\\\\\":\\\\\"Harvey\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":74,\\\\\"end\\\\\":79,\\\\\"text\\\\\":\\\\\"Hardin\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":64,\\\\\"end\\\\\":71,\\\\\"text\\\\\":\\\\\"Blackmon\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":42,\\\\\"end\\\\\":71,\\\\\"text\\\\\":\\\\\"Chief Deputy Jonathan Blackmon\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085438000,\\\\\"last_updated_at\\\\\":1541085438000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n{\\\\\"content\\\\\": \\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":453,\\\\\"end\\\\\":460,\\\\\"text\\\\\":\\\\\"Morrison\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":315,\\\\\"end\\\\\":325,\\\\\"text\\\\\":\\\\\"the leaders\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":80,\\\\\"end\\\\\":91,\\\\\"text\\\\\":\\\\\"eter O’Neill\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":32,\\\\\"end\\\\\":39,\\\\\"text\\\\\":\\\\\"Morrison\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":26,\\\\\"end\\\\\":39,\\\\\"text\\\\\":\\\\\"Scott Morrison\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085568000,\\\\\"last_updated_at\\\\\":1541085568000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n{\\\\\"content\\\\\": \\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":416,\\\\\"end\\\\\":420,\\\\\"text\\\\\":\\\\\"Clark\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":269,\\\\\"end\\\\\":275,\\\\\"text\\\\\":\\\\\"Montana\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":245,\\\\\"end\\\\\":259,\\\\\"text\\\\\":\\\\\"the quarterback\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":40,\\\\\"end\\\\\":44,\\\\\"text\\\\\":\\\\\"Clark\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":33,\\\\\"end\\\\\":44,\\\\\"text\\\\\":\\\\\"Dwight Clark\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":4,\\\\\"end\\\\\":10,\\\\\"text\\\\\":\\\\\"Montana\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":0,\\\\\"end\\\\\":10,\\\\\"text\\\\\":\\\\\"Joe Montana\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085542000,\\\\\"last_updated_at\\\\\":1541085542000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n{\\\\\"content\\\\\": \\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":816,\\\\\"end\\\\\":825,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":701,\\\\\"end\\\\\":710,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":588,\\\\\"end\\\\\":594,\\\\\"text\\\\\":\\\\\"Merritt\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":576,\\\\\"end\\\\\":581,\\\\\"text\\\\\":\\\\\"Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":532,\\\\\"end\\\\\":537,\\\\\"text\\\\\":\\\\\"Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":527,\\\\\"end\\\\\":537,\\\\\"text\\\\\":\\\\\"Doug Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":501,\\\\\"end\\\\\":510,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":224,\\\\\"end\\\\\":230,\\\\\"text\\\\\":\\\\\"Merritt\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":218,\\\\\"end\\\\\":231,\\\\\"text\\\\\":\\\\\"Piper Merritt,\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":183,\\\\\"end\\\\\":192,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":25,\\\\\"end\\\\\":34,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085478000,\\\\\"last_updated_at\\\\\":1541085478000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n{\\\\\"content\\\\\": \\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":85,\\\\\"end\\\\\":116,\\\\\"text\\\\\":\\\\\"A group of students and teachers\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":44,\\\\\"end\\\\\":60,\\\\\"text\\\\\":\\\\\"George Washington\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1541085505000,\\\\\"last_updated_at\\\\\":1541085505000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n\\'}, {\\'file\\': \\'homework_3.ipynb\\', \\'content\\': \\'{\\\\\\\\n \\\\\"cells\\\\\": [\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# Homework #3\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\\\\\\\\\'ve tagged.\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 1:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Tag data. You\\\\\\\\\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Once you\\\\\\\\\\'ve created an account you\\\\\\\\\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Select the Document Annotation option under Text annotations.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    Provide a dataset name (you can use whatever)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for the list of entities just input Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for the tagging instructions provide whatever you would like\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    Then hit submit\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"You will then hit the \\\\\\\\\\\\\\\\\\\\\"Upload raw data\\\\\\\\\\\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\\\\\\\\\'ve identified all of them for a single document hit \\\\\\\\\\\\\\\\\\\\\"move to done\\\\\\\\\\\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"When you finish tagging all 5 documents, go into the project you\\\\\\\\\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\\\\\\\\\\\"download\\\\\\\\\\\\\\\\\\\\\". You will want to have the \\\\\\\\\\\\\\\\\\\\\"complete items\\\\\\\\\\\\\\\\\\\\\" and \\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Annotation guidelines:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    These are from the ACE Guidelines for Person:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"3.1 Persons (PER) \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Examples: \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"He is [a real turkey]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"[The political cat of the year]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"She’s known as [the brain of the family] \\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 2:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Look through the below code.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Implement the appropriate code to calculate these numbers.\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# import json\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"from pprint import pprint\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# method to read annotation file\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def annotation_processor(annotation_file):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    annotation_array = []\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    read_annotation = open(annotation_file)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for line in read_annotation:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        data = json.loads(line)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        annotation_array.append(data)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # here we return an array of the individual annotations\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return annotation_array\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# calling the annotation processor function\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"annotation_processor(\\\\\\\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\\\\\\\')\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"reference_annotations = annotation_processor(\\\\\\\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\\\\\\\')\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"my_annotations = annotation_processor(\\\\\\\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\\\\\\\')\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def compare_annotations(reference_annotations, my_annotations):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # you will need to implement this method\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 85,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #  \\\\\\\\\\'end\\\\\\\\\\': 116,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #  \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'A group of students and teachers\\\\\\\\\\'}]}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # that is the character offset is correct\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    print(\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return num_matches, num_non_matches\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_annotations_in_reference = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_annotations_in_mine = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # we want this method to calculate these two numbers\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # num_matches should simply count all the cases where we \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_partial_match = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for annotation in reference_annotation_array:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        for my_annotation in my_annotation_array:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"            if (annotation[\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\"] == my_annotation[\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\"]):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\"], my_annotation[\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        # implement the sum of the temp_num_matches to the num_matches\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return num_matches, num_non_matches\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"print(compare_annotation_files(reference_annotations, my_annotations))\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 3:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"With the numbers now available, try to determine the Cohen\\\\\\\\\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"The rest of the formula should be as discussed in class.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Report the numbers you calculate.\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 4:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    A brief explanation of the Cohen\\\\\\\\\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 5:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Now you will compare the output of two extractors over a small dataset of news.\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"import spacy\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# here we are just using two different spacy models.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# you will need to ensure that you have both models installed\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"model_1 = spacy.load(\\\\\\\\\\\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"model_2 = spacy.load(\\\\\\\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\\\\\\\")\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"from os import listdir\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"from os.path import isfile, join\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"dir_base = \\\\\\\\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"####\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"####\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def read_file(filename):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    input_file_text = open(filename , encoding=\\\\\\\\\\'utf-8\\\\\\\\\\').read()\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return input_file_text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def read_directory_files(directory):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    file_texts = []\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for f in files:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        file_text = read_file(join(directory, f))\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        print(file_text)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        file_texts.append({\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\":f, \\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": file_text })\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return file_texts\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# here we will generate the list that contains all the files and their contents\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"text_corpus = read_directory_files(dir_base)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"print(text_corpus)\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# extract entities\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def get_entities(document_text, model):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    analyzed_doc = model(document_text)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # here we are just limiting to a small set of entity types\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\"GPE\\\\\\\\\\\\\\\\\\\\\"]]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return entities\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    print(reference_entities)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    print(test_entities)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # how many of the same entities are returned in the test entity set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # test entity set and also if entities are not retrieved\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # are not in the reference entity set as well\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    correct_identified_entities = 0 \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # count the number of items in the test set \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # that are also in the reference set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    correct_unidentified_entities = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # count the number of items that are in the reference set \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # that are not in the test set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    spurious_identified_entites = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # count the number of items in the test set that are not in \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # the reference set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # item is in the reference entity set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # correct_identified_entities number\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    ###\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # Your code goes here\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    ###\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"overall_correct_identified_entities = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"overall_correct_unidentified_entities = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"overall_spurious_identified_entites = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"for document in text_corpus:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # below you will see that entities_1 is from model_1\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # you can make a decision about which model output will be the reference output\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    entities_1 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\"], model_1)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    entities_2 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\"], model_2)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # increment the overall variables\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# now that you are outside the loop, determine the following values\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# what is the overall precision and recall?\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# does this change if you change the reference model?\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 6: \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\\\\\\\\\'t using a normal evaluation set, feel free to speculate as you wish.\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Extra Credit: \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": []\\\\\\\\n  }\\\\\\\\n ],\\\\\\\\n \\\\\"metadata\\\\\": {\\\\\\\\n  \\\\\"kernelspec\\\\\": {\\\\\\\\n   \\\\\"display_name\\\\\": \\\\\"Python 3\\\\\",\\\\\\\\n   \\\\\"language\\\\\": \\\\\"python\\\\\",\\\\\\\\n   \\\\\"name\\\\\": \\\\\"python3\\\\\"\\\\\\\\n  },\\\\\\\\n  \\\\\"language_info\\\\\": {\\\\\\\\n   \\\\\"codemirror_mode\\\\\": {\\\\\\\\n    \\\\\"name\\\\\": \\\\\"ipython\\\\\",\\\\\\\\n    \\\\\"version\\\\\": 3\\\\\\\\n   },\\\\\\\\n   \\\\\"file_extension\\\\\": \\\\\".py\\\\\",\\\\\\\\n   \\\\\"mimetype\\\\\": \\\\\"text/x-python\\\\\",\\\\\\\\n   \\\\\"name\\\\\": \\\\\"python\\\\\",\\\\\\\\n   \\\\\"nbconvert_exporter\\\\\": \\\\\"python\\\\\",\\\\\\\\n   \\\\\"pygments_lexer\\\\\": \\\\\"ipython3\\\\\",\\\\\\\\n   \\\\\"version\\\\\": \\\\\"3.7.2\\\\\"\\\\\\\\n  }\\\\\\\\n },\\\\\\\\n \\\\\"nbformat\\\\\": 4,\\\\\\\\n \\\\\"nbformat_minor\\\\\": 2\\\\\\\\n}\\\\\\\\n\\'}, {\\'file\\': \\'homework_3_final.ipynb\\', \\'content\\': \\'{\\\\\\\\n \\\\\"cells\\\\\": [\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# Homework #3\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\\\\\\\\\'ve tagged.\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 1:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Tag data. You\\\\\\\\\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Once you\\\\\\\\\\'ve created an account you\\\\\\\\\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Select the Document Annotation option under Text annotations.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    Provide a dataset name (you can use whatever)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for the list of entities just input Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for the tagging instructions provide whatever you would like\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    Then hit submit\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"You will then hit the \\\\\\\\\\\\\\\\\\\\\"Upload raw data\\\\\\\\\\\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\\\\\\\\\'ve identified all of them for a single document hit \\\\\\\\\\\\\\\\\\\\\"move to done\\\\\\\\\\\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"When you finish tagging all 5 documents, go into the project you\\\\\\\\\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\\\\\\\\\\\"download\\\\\\\\\\\\\\\\\\\\\". You will want to have the \\\\\\\\\\\\\\\\\\\\\"complete items\\\\\\\\\\\\\\\\\\\\\" and \\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Annotation guidelines:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    These are from the ACE Guidelines for Person:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"3.1 Persons (PER) \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Examples: \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"He is [a real turkey]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"[The political cat of the year]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"She’s known as [the brain of the family] \\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 2:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Look through the below code.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Implement the appropriate code to calculate these numbers.\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 24,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"data\\\\\": {\\\\\\\\n      \\\\\"text/plain\\\\\": [\\\\\\\\n       \\\\\"[{\\\\\\\\\\'content\\\\\\\\\\': \\\\\\\\\\'According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'annotation\\\\\\\\\\': [{\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 379, \\\\\\\\\\'end\\\\\\\\\\': 386, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Blackmon\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 74, \\\\\\\\\\'end\\\\\\\\\\': 79, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Hardin\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 64, \\\\\\\\\\'end\\\\\\\\\\': 71, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Blackmon\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 55, \\\\\\\\\\'end\\\\\\\\\\': 71, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Jonathan Blackmon\\\\\\\\\\'}]}],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'extras\\\\\\\\\\': None,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'metadata\\\\\\\\\\': {\\\\\\\\\\'first_done_at\\\\\\\\\\': 1586954510000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_at\\\\\\\\\\': 1586954510000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'sec_taken\\\\\\\\\\': 0,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_by\\\\\\\\\\': \\\\\\\\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'status\\\\\\\\\\': \\\\\\\\\\'done\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'evaluation\\\\\\\\\\': \\\\\\\\\\'CORRECT\\\\\\\\\\'}},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\" {\\\\\\\\\\'content\\\\\\\\\\': \\\\\\\\\\'Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'annotation\\\\\\\\\\': [{\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 453, \\\\\\\\\\'end\\\\\\\\\\': 460, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Morrison\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 79, \\\\\\\\\\'end\\\\\\\\\\': 91, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Peter O’Neill\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 32, \\\\\\\\\\'end\\\\\\\\\\': 39, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Morrison\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 26, \\\\\\\\\\'end\\\\\\\\\\': 39, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Scott Morrison\\\\\\\\\\'}]}],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'extras\\\\\\\\\\': None,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'metadata\\\\\\\\\\': {\\\\\\\\\\'first_done_at\\\\\\\\\\': 1586954448000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_at\\\\\\\\\\': 1586954448000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'sec_taken\\\\\\\\\\': 0,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_by\\\\\\\\\\': \\\\\\\\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'status\\\\\\\\\\': \\\\\\\\\\'done\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'evaluation\\\\\\\\\\': \\\\\\\\\\'NONE\\\\\\\\\\'}},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\" {\\\\\\\\\\'content\\\\\\\\\\': \\\\\\\\\\'Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'annotation\\\\\\\\\\': [{\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 0, \\\\\\\\\\'end\\\\\\\\\\': 10, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Joe Montana\\\\\\\\\\'}]}],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'extras\\\\\\\\\\': None,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'metadata\\\\\\\\\\': {\\\\\\\\\\'first_done_at\\\\\\\\\\': 1586954477000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_at\\\\\\\\\\': 1586954477000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'sec_taken\\\\\\\\\\': 0,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_by\\\\\\\\\\': \\\\\\\\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'status\\\\\\\\\\': \\\\\\\\\\'done\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'evaluation\\\\\\\\\\': \\\\\\\\\\'NONE\\\\\\\\\\'}},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\" {\\\\\\\\\\'content\\\\\\\\\\': \\\\\\\\\\'To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'annotation\\\\\\\\\\': [{\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 816, \\\\\\\\\\'end\\\\\\\\\\': 825, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'John Deere\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 701, \\\\\\\\\\'end\\\\\\\\\\': 710, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'John Deere\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 588, \\\\\\\\\\'end\\\\\\\\\\': 594, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Merritt\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 576, \\\\\\\\\\'end\\\\\\\\\\': 581, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Walker\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 532, \\\\\\\\\\'end\\\\\\\\\\': 537, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Walker\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 501, \\\\\\\\\\'end\\\\\\\\\\': 510, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'John Deere\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 224, \\\\\\\\\\'end\\\\\\\\\\': 230, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Merritt\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 218, \\\\\\\\\\'end\\\\\\\\\\': 229, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'Piper Merrit\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 183, \\\\\\\\\\'end\\\\\\\\\\': 192, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'John Deere\\\\\\\\\\'}]},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 25, \\\\\\\\\\'end\\\\\\\\\\': 34, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'John Deere\\\\\\\\\\'}]}],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'extras\\\\\\\\\\': None,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'metadata\\\\\\\\\\': {\\\\\\\\\\'first_done_at\\\\\\\\\\': 1586954335000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_at\\\\\\\\\\': 1586954335000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'sec_taken\\\\\\\\\\': 0,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_by\\\\\\\\\\': \\\\\\\\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'status\\\\\\\\\\': \\\\\\\\\\'done\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'evaluation\\\\\\\\\\': \\\\\\\\\\'NONE\\\\\\\\\\'}},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\" {\\\\\\\\\\'content\\\\\\\\\\': \\\\\\\\\\'A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'annotation\\\\\\\\\\': [{\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"    \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 44, \\\\\\\\\\'end\\\\\\\\\\': 62, \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'George Washington’s\\\\\\\\\\'}]}],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'extras\\\\\\\\\\': None,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"  \\\\\\\\\\'metadata\\\\\\\\\\': {\\\\\\\\\\'first_done_at\\\\\\\\\\': 1586954354000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_at\\\\\\\\\\': 1586954354000,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'sec_taken\\\\\\\\\\': 0,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'last_updated_by\\\\\\\\\\': \\\\\\\\\\'GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'status\\\\\\\\\\': \\\\\\\\\\'done\\\\\\\\\\',\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n       \\\\\"   \\\\\\\\\\'evaluation\\\\\\\\\\': \\\\\\\\\\'NONE\\\\\\\\\\'}}]\\\\\"\\\\\\\\n      ]\\\\\\\\n     },\\\\\\\\n     \\\\\"execution_count\\\\\": 24,\\\\\\\\n     \\\\\"metadata\\\\\": {},\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"execute_result\\\\\"\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# import json\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"from pprint import pprint\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"import json\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# method to read annotation file\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def annotation_processor(annotation_file):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    annotation_array = []\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    read_annotation = open(annotation_file,encoding=\\\\\\\\\\'utf8\\\\\\\\\\')\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for line in read_annotation:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        data = json.loads(line)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        annotation_array.append(data)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # here we return an array of the individual annotations\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return annotation_array\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# calling the annotation processor function\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"annotation_processor(\\\\\\\\\\'Person_entites.json\\\\\\\\\\')\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 25,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"#import json\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"#person_dict = json.loads(\\\\\\\\\\'annotated.json\\\\\\\\\\')\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 26,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"reference_annotations = annotation_processor(\\\\\\\\\\'Person_entites.json\\\\\\\\\\')\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"my_annotations = annotation_processor(\\\\\\\\\\'annotated.json\\\\\\\\\\')\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 27,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"m=my_annotations[:]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"n=reference_annotations[:]\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 28,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"num_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # you will need to implement this method\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 85,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #  \\\\\\\\\\'end\\\\\\\\\\': 116,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #  \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'A group of students and teachers\\\\\\\\\\'}]}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # that is the character offset is correct\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"for smallm,smalln in zip(m,n):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"            if keym==\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\" and keyn==\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                for vm,vn in zip(valuem,valuen):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                    for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                        if vmk==\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\" and vnk==\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                            for v1,v2 in zip(vmv,vnv):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                    #for v11,v22 in zip(vv1,vv2):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                    if vv1==vv2:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                        num_matches = num_matches +1 \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                    elif vv1!=vv2:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                        num_non_matches=num_non_matches+1\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 29,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"23\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"37\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"print(num_matches)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"print(num_non_matches)\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 30,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 379\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 386\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Blackmon\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 293\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 296\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Irma\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 267\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 272\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Harvey\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 74\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 79\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Hardin\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 64\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 71\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Blackmon\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 42\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 71\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Chief Deputy Jonathan Blackmon\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 453\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 460\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Morrison\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 315\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 325\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value the leaders\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 80\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 91\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value eter O’Neill\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 32\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 39\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Morrison\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 26\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 39\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Scott Morrison\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 416\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 420\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Clark\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 269\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 275\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Montana\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 245\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 259\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value the quarterback\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 40\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 44\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Clark\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 33\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 44\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Dwight Clark\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 4\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 10\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Montana\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 10\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Joe Montana\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 816\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 825\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value John Deere\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 701\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 710\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value John Deere\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 588\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 594\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Merritt\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 576\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 581\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Walker\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 532\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 537\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Walker\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 527\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 537\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Doug Walker\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 501\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 510\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value John Deere\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 224\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 230\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Merritt\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 218\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 231\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value Piper Merritt,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 183\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 192\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value John Deere\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 25\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 34\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value John Deere\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 85\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 116\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value A group of students and teachers\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"********\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"tag Person\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys start\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 44\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys end\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value 60\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"keys text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"value George Washington\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"#final checking function- done- works!!!\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"m=my_annotations[0:5]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"for small in m:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for key,value in small.items():\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        if key==\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"            for v in value:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                print(\\\\\\\\\\\\\\\\\\\\\"********\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                for vk,vv in v.items():\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                    if vk==\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                        for vvl in vv:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                            print(\\\\\\\\\\\\\\\\\\\\\"tag\\\\\\\\\\\\\\\\\\\\\",vvl)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                    if vk==\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                        for vvl in vv:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                            for vvlk,vvlv in vvl.items():\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                print(\\\\\\\\\\\\\\\\\\\\\"keys\\\\\\\\\\\\\\\\\\\\\",vvlk)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                print(\\\\\\\\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\\\\\\\",vvlv)\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 31,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def compare_annotations(m, n):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # you will need to implement this method\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 85,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #  \\\\\\\\\\'end\\\\\\\\\\': 116,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #  \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'A group of students and teachers\\\\\\\\\\'}]}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # that is the character offset is correct\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for smallm,smalln in zip(m,n):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                if keym==\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\" and keyn==\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                    for vm,vn in zip(valuem,valuen):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                            if vmk==\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\" and vnk==\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                for v1,v2 in zip(vmv,vnv):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                        #for v11,v22 in zip(vv1,vv2):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                        if vv1==vv2:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                            num_matches = num_matches +1 \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                        elif vv1!=vv2:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                            num_non_matches=num_non_matches+1\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    print(\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return num_matches, num_non_matches\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 32,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"success\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"(23, 37)\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"print(compare_annotations(m,n))\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"#print(m1)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"#print(n1)\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 33,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def compare_annotations(m, n):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # you will need to implement this method\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 85,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #  \\\\\\\\\\'end\\\\\\\\\\': 116,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #  \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'A group of students and teachers\\\\\\\\\\'}]}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # that is the character offset is correct\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for smallm,smalln in zip(m,n):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        for (keym,valuem) , (keyn,valuen) in zip(smallm.items(),smalln.items()): \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                if keym==\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\" and keyn==\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                    for vm,vn in zip(valuem,valuen):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                        for (vmk,vmv) , (vnk,vnv) in zip(vm.items(),vn.items()):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                            if vmk==\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\" and vnk==\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                for v1,v2 in zip(vmv,vnv):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                    for (vk1,vv1) , (vk2,vv2) in zip(v1.items(),v2.items()):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                        #for v11,v22 in zip(vv1,vv2):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                        if vv1==vv2:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                            num_matches = num_matches +1 \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                        elif vv1!=vv2:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"                                            num_non_matches=num_non_matches+1\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    print(\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return num_matches, num_non_matches\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def compare_annotation_files(mm, nn):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    m1,n1=compare_annotations(mm,nn)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return m1,n1\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 34,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"success\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"(23, 37)\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"m=my_annotations[:]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"n=reference_annotations[:]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"print(compare_annotation_files(m, n))\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 35,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"success\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"val1,val2=compare_annotation_files(reference_annotations, my_annotations)\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 36,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"data\\\\\": {\\\\\\\\n      \\\\\"text/plain\\\\\": [\\\\\\\\n       \\\\\"23\\\\\"\\\\\\\\n      ]\\\\\\\\n     },\\\\\\\\n     \\\\\"execution_count\\\\\": 36,\\\\\\\\n     \\\\\"metadata\\\\\": {},\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"execute_result\\\\\"\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"val1\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 37,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"data\\\\\": {\\\\\\\\n      \\\\\"text/plain\\\\\": [\\\\\\\\n       \\\\\"37\\\\\"\\\\\\\\n      ]\\\\\\\\n     },\\\\\\\\n     \\\\\"execution_count\\\\\": 37,\\\\\\\\n     \\\\\"metadata\\\\\": {},\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"execute_result\\\\\"\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"val2\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 3:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"With the numbers now available, try to determine the Cohen\\\\\\\\\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"The rest of the formula should be as discussed in class.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Report the numbers you calculate.\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 4:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    A brief explanation of the Cohen\\\\\\\\\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 5:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Now you will compare the output of two extractors over a small dataset of news.\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 38,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"import spacy\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"import os\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 39,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# here we are just using two different spacy models.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# you will need to ensure that you have both models installed\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"model_1 = spacy.load(\\\\\\\\\\\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"model_2 = spacy.load(\\\\\\\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\\\\\\\")\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 40,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"from os import listdir\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"from os.path import isfile, join\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 41,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"data\\\\\": {\\\\\\\\n      \\\\\"text/plain\\\\\": [\\\\\\\\n       \\\\\"\\\\\\\\\\'C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\NLP_HW\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\HW3\\\\\\\\\\'\\\\\"\\\\\\\\n      ]\\\\\\\\n     },\\\\\\\\n     \\\\\"execution_count\\\\\": 41,\\\\\\\\n     \\\\\"metadata\\\\\": {},\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"execute_result\\\\\"\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"os.getcwd()\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 42,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"dir_base = os.getcwd()\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 43,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":379,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":386,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":293,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":296,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Irma\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":267,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":272,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Harvey\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":74,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":79,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Hardin\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":64,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":71,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":42,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":71,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Chief Deputy Jonathan Blackmon\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1541085438000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1541085438000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":453,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":460,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":315,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":325,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"the leaders\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":80,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":91,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"eter O’Neill\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":32,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":39,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":26,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":39,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Scott Morrison\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1541085568000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1541085568000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":416,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":420,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Clark\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":269,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":275,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Montana\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":245,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":259,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"the quarterback\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":40,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":44,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Clark\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":33,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":44,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Dwight Clark\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":4,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":10,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Montana\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":10,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Joe Montana\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1541085542000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1541085542000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":816,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":825,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":701,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":710,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":588,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":594,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":576,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":581,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":532,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":537,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":527,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":537,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Doug Walker\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":501,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":510,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":224,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":230,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":218,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":231,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Piper Merritt,\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":183,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":192,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":25,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":34,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1541085478000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1541085478000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":85,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":116,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"A group of students and teachers\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":44,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":60,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"George Washington\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1541085505000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1541085505000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\" \\\\\\\\\\\\\\\\\\\\\"cells\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# Homework #3\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Goal: In this homework you will briefly tag a few documents for person references. You will then compare your tags to a set of tags produced by myself and possibly other people. For the purposes of the submission you need only submit the comparison information with the set I\\\\\\\\\\'ve tagged.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Step 1:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Tag data. You\\\\\\\\\\'ll want to sign up at https://dataturks.com/ . There you will want to create an account and setup a new project for tagging.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Once you\\\\\\\\\\'ve created an account you\\\\\\\\\\'ll want to create a new dataset. (+ button on the left hand side.)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Select the Document Annotation option under Text annotations.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    Provide a dataset name (you can use whatever)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    for the list of entities just input Person\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    for the tagging instructions provide whatever you would like\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    Then hit submit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"You will then hit the \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Upload raw data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" button. Here, go into the homework data directory and upload the zip file which has all the documents inside of it.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"You can then tag each document. Simply highlight the piece of text that you think is a person. When you\\\\\\\\\\'ve identified all of them for a single document hit \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"move to done\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\". Use the guidelines contained in the next cell.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"When you finish tagging all 5 documents, go into the project you\\\\\\\\\\'ve tagged and hit the options button in the top right. You will then hit \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"download\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\". You will want to have the \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"complete items\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" and \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" options selected. Hit download and you will then have a json file for all of your documents.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"(If this is confusing, please send me an email. I can try to come up with screen shots if necessary.)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Annotation guidelines:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    These are from the ACE Guidelines for Person:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"3.1 Persons (PER) \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    Each distinct person or set of people mentioned in a document refers to an entity of type Person. For example, people may be specified by name (“John Smith”), occupation (“the butcher”), family relation (“dad”), pronoun (“he”), etc., or by some combination of these. Dead people and human remains are to be recorded as entities of type Person. So are fictional human characters appearing in movies, TV, books, plays, etc. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"There are a number of words that are ambiguous as to their referent. For example, nouns, which normally refer to animals or non-humans, can be used to describe people. If it is clear to the annotator that the noun refers to a person in a given context, it should be marked as a Person entity. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Examples: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"He is [a real turkey]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"[The political cat of the year]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"She’s known as [the brain of the family] \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Step 2:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Look through the below code.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"You will see that the compare annotations method needs to be implemented. It should report back the number of matches and non-matching annotations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Implement the appropriate code to calculate these numbers.\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# import json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"from pprint import pprint\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# method to read annotation file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"def annotation_processor(annotation_file):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    annotation_array = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # here we need to be careful and process each line of the annotation file separately\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    read_annotation = open(annotation_file)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    for line in read_annotation:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        data = json.loads(line)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        annotation_array.append(data)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # here we return an array of the individual annotations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    return annotation_array\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# calling the annotation processor function\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"annotation_processor(\\\\\\\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\\\\\\\')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# here we will create two objects to store the reference annotations and your own annotations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"reference_annotations = annotation_processor(\\\\\\\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\\\\\\\')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# here I am just putting the same file in... if I do this I would expect a perfect match\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"my_annotations = annotation_processor(\\\\\\\\\\'/s20_ds_nlp/homeworks/homework_3/annotated_data/annotated.json\\\\\\\\\\')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# you will primarily focus on implementing this compare_annotations method\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"def compare_annotations(reference_annotations, my_annotations):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    num_matches = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # you will need to implement this method\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # The annotations you will get in the parameters are arrays of objects like this:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # {\\\\\\\\\\'label\\\\\\\\\\': [\\\\\\\\\\'Person\\\\\\\\\\'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # \\\\\\\\\\'points\\\\\\\\\\': [{\\\\\\\\\\'start\\\\\\\\\\': 85,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    #  \\\\\\\\\\'end\\\\\\\\\\': 116,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    #  \\\\\\\\\\'text\\\\\\\\\\': \\\\\\\\\\'A group of students and teachers\\\\\\\\\\'}]}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # You will need to compare the annoatations between the reference and your own\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # You will look to see if you have annotations that match when the start and end values are the same,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # that is the character offset is correct\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    return num_matches, num_non_matches\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"def compare_annotation_files(reference_annotation_array, my_annotation_array):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    num_annotations_in_reference = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    num_annotations_in_mine = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # we want this method to calculate these two numbers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # num_matches should simply count all the cases where we \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    num_matches = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # num_non_matches should simply count those cases where an annotation only occurs in one file but not both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    num_non_matches = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # OPTIONAL if you want to be more precise you can look for annotations where this a partial overalp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    num_partial_match = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    for annotation in reference_annotation_array:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        for my_annotation in my_annotation_array:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"            # here we need to do some things to ensure that the documents we are comparing are identical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"            if (annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == my_annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"                temp_num_matches, temp_num_non_matches = compare_annotations(annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], my_annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        # implement the sum of the temp_num_matches to the num_matches\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    return num_matches, num_non_matches\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"print(compare_annotation_files(reference_annotations, my_annotations))\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Step 3:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"With the numbers now available, try to determine the Cohen\\\\\\\\\\'s Kappa for this dataset. (You can calculate this by hand if you prefer). Assume that the Probability of random agreement is 0.3.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Note, with this the proportionate agreement would be the number of matches divided by the number of matches + the number of non-matches.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"The rest of the formula should be as discussed in class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Report the numbers you calculate.\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Step 4:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"You will want to write a short report of 1 or 2 paragraphs. In it you should describe:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    What kind of differences there are between your annotations and the ones I have provided.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        Look through the different annotations and suggest where I might have been mistaken in identifying people\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    Explain if you think tagging persons are difficult. Do you think the guidelines should be improved?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    A brief explanation of the Cohen\\\\\\\\\\'s Kappa you calculated. Do you think it might be high or low? Does it report anything useful?\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Step 5:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Now you will compare the output of two extractors over a small dataset of news.\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"import spacy\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# here we are just using two different spacy models.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# you will need to ensure that you have both models installed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"model_1 = spacy.load(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"en_core_web_sm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"model_2 = spacy.load(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"from os import listdir\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"from os.path import isfile, join\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"dir_base = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3/news_data/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"####\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"####\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"def read_file(filename):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    input_file_text = open(filename , encoding=\\\\\\\\\\'utf-8\\\\\\\\\\').read()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    return input_file_text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"def read_directory_files(directory):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    file_texts = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    for f in files:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        file_text = read_file(join(directory, f))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        print(file_text)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"        file_texts.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":f, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_text })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    return file_texts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# here we will generate the list that contains all the files and their contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"text_corpus = read_directory_files(dir_base)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"print(text_corpus)\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# extract entities\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"def get_entities(document_text, model):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    analyzed_doc = model(document_text)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # here we are just limiting to a small set of entity types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"GPE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    return entities\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    print(reference_entities)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    print(test_entities)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # how many of the same entities are returned in the test entity set\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # test entity set and also if entities are not retrieved\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # are not in the reference entity set as well\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    correct_identified_entities = 0 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # count the number of items in the test set \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # that are also in the reference set\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    correct_unidentified_entities = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # count the number of items that are in the reference set \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # that are not in the test set\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    spurious_identified_entites = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # count the number of items in the test set that are not in \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # the reference set\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # item is in the reference entity set\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # correct_identified_entities number\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    ###\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # Your code goes here\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    ###\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"overall_correct_identified_entities = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"overall_correct_unidentified_entities = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"overall_spurious_identified_entites = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"for document in text_corpus:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # below you will see that entities_1 is from model_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # you can make a decision about which model output will be the reference output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    entities_1 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], model_1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    entities_2 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], model_2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    # increment the overall variables\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# now that you are outside the loop, determine the following values\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# what is the overall precision and recall?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"# does this change if you change the reference model?\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Step 6: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\\\\\\\\\'t using a normal evaluation set, feel free to speculate as you wish.\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"Extra Credit: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   ]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\\\\\\\": null,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\\\\\\\": [],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\": []\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  }\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\" ],\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\" \\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  \\\\\\\\\\\\\\\\\\\\\"kernelspec\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"display_name\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"Python 3\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"python3\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  \\\\\\\\\\\\\\\\\\\\\"language_info\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"codemirror_mode\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"ipython\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"    \\\\\\\\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\\\\\\\": 3\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"file_extension\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"text/x-python\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"nbconvert_exporter\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"pygments_lexer\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"ipython3\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"   \\\\\\\\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"3.7.2\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"  }\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\" },\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\" \\\\\\\\\\\\\\\\\\\\\"nbformat\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\" \\\\\\\\\\\\\\\\\\\\\"nbformat_minor\\\\\\\\\\\\\\\\\\\\\": 2\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"}\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stderr\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"IOPub data rate exceeded.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"The notebook server will temporarily stop sending output\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"to the client in order to avoid crashing it.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"To change this limit, set the config variable\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"`--NotebookApp.iopub_data_rate_limit`.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"Current values:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"NotebookApp.rate_limit_window=3.0 (secs)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":379,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":386,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":74,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":79,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Hardin\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":64,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":71,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":55,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":71,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Jonathan Blackmon\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1586954510000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1586954510000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"CORRECT\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":453,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":460,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":79,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":91,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Peter O’Neill\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":32,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":39,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":26,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":39,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Scott Morrison\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1586954448000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1586954448000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":10,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Joe Montana\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1586954477000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1586954477000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":816,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":825,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":701,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":710,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":588,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":594,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":576,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":581,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":532,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":537,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":501,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":510,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":224,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":230,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":218,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":229,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"Piper Merrit\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":183,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":192,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":25,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":34,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1586954335000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1586954335000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"{\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\":[\\\\\\\\\\\\\\\\\\\\\"Person\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\"points\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\":44,\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\":62,\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"George Washington’s\\\\\\\\\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\\\\\\\\\"extras\\\\\\\\\\\\\\\\\\\\\":null,\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\\\\\\\\\":1586954354000,\\\\\\\\\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\\\\\\\\\":1586954354000,\\\\\\\\\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\\\\\\\\\":0,\\\\\\\\\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"done\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\\\\\\\\\"}}\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stderr\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"IOPub data rate exceeded.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"The notebook server will temporarily stop sending output\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"to the client in order to avoid crashing it.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"To change this limit, set the config variable\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"`--NotebookApp.iopub_data_rate_limit`.\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"Current values:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"NotebookApp.rate_limit_window=3.0 (secs)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n     \\\\\"name\\\\\": \\\\\"stdout\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"stream\\\\\",\\\\\\\\n     \\\\\"text\\\\\": [\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n     ]\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"#dir_base = \\\\\\\\\\\\\\\\\\\\\"/GWU/NATURAL LANGUAGE PROCESSiNG/s20_ds_nlp-master/homeworks/homework_3/news_data\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"####\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"####\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def read_file(filename):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    input_file_text = open(filename , encoding=\\\\\\\\\\'utf-8\\\\\\\\\\').read()\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return input_file_text\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def read_directory_files(directory):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    file_texts = []\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    for f in files:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        file_text = read_file(join(directory, f))\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        print(file_text)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"        file_texts.append({\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\":f, \\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\": file_text })\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return file_texts\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# here we will generate the list that contains all the files and their contents\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"text_corpus = read_directory_files(dir_base)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"print(text_corpus)\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 44,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# extract entities\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"def get_entities(document_text, model):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    analyzed_doc = model(document_text)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # here we are just limiting to a small set of entity types\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\\\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\"GPE\\\\\\\\\\\\\\\\\\\\\"]]\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return entities\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"def compare_entities_from_document(reference_entities, test_entities):\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    print(reference_entities)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    print(test_entities)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # here we need to calculate how different the reference and test entity sets are\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # how many of the same entities are returned in the test entity set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # So we need to identify the correctly identified entities that are also in the \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # test entity set and also if entities are not retrieved\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # we also want to count the number of entities that are in the test entity set that\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # are not in the reference entity set as well\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # in this case we will only concern ourselves with exact matches of entities\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # thus, a match is the same portion of text and the same entity type\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # hint: this is easy if you try to use normal comparisons\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    correct_identified_entities = 0 \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # count the number of items in the test set \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # that are also in the reference set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    correct_unidentified_entities = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # count the number of items that are in the reference set \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # that are not in the test set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    spurious_identified_entites = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # count the number of items in the test set that are not in \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # the reference set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # one way you could do this is to iterate over the test entity list and see if each\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # item is in the reference entity set\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # so if an item in the test set is in the reference then you would increment the \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # correct_identified_entities number\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    ###\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # Your code goes here\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    ###\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": 45,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [\\\\\\\\n    {\\\\\\\\n     \\\\\"ename\\\\\": \\\\\"ValueError\\\\\",\\\\\\\\n     \\\\\"evalue\\\\\": \\\\\"[E088] Text of length 2211708 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you\\\\\\\\\\'re not using the parser or NER, it\\\\\\\\\\'s probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\\\\",\\\\\\\\n     \\\\\"output_type\\\\\": \\\\\"error\\\\\",\\\\\\\\n     \\\\\"traceback\\\\\": [\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\u001b[1;31m---------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[0m\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\u001b[1;31mValueError\\\\\\\\\\\\\\\\u001b[0m                                Traceback (most recent call last)\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\u001b[1;32m<ipython-input-45-5fe2e813ecf8>\\\\\\\\\\\\\\\\u001b[0m in \\\\\\\\\\\\\\\\u001b[0;36m<module>\\\\\\\\\\\\\\\\u001b[1;34m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m      6\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[1;31m# below you will see that entities_1 is from model_1\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m      7\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[1;31m# you can make a decision about which model output will be the reference output\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m----> 8\\\\\\\\\\\\\\\\u001b[1;33m     \\\\\\\\\\\\\\\\u001b[0mentities_1\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;33m=\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mget_entities\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m(\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mdocument\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m[\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;34m\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m]\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m,\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mmodel_1\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0;32m      9\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[0mentities_2\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;33m=\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mget_entities\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m(\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mdocument\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m[\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;34m\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m]\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m,\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mmodel_2\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     10\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[1;31m#correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\u001b[1;32m<ipython-input-44-627b81386c65>\\\\\\\\\\\\\\\\u001b[0m in \\\\\\\\\\\\\\\\u001b[0;36mget_entities\\\\\\\\\\\\\\\\u001b[1;34m(document_text, model)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m      1\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;31m# extract entities\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m      2\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;32mdef\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mget_entities\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m(\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mdocument_text\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m,\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mmodel\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m:\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m----> 3\\\\\\\\\\\\\\\\u001b[1;33m     \\\\\\\\\\\\\\\\u001b[0manalyzed_doc\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;33m=\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mmodel\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m(\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mdocument_text\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0;32m      4\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[1;31m# here we are just limiting to a small set of entity types\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m      5\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[0mentities\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;33m=\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;33m[\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mentity\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;32mfor\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mentity\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;32min\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0manalyzed_doc\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m.\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0ments\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;32mif\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mentity\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m.\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mlabel_\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;32min\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;33m[\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;34m\\\\\\\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m,\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;34m\\\\\\\\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m,\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;34m\\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m,\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;34m\\\\\\\\\\\\\\\\\\\\\"GPE\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m]\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m]\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\spacy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\language.py\\\\\\\\\\\\\\\\u001b[0m in \\\\\\\\\\\\\\\\u001b[0;36m__call__\\\\\\\\\\\\\\\\u001b[1;34m(self, text, disable, component_cfg)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    423\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[1;32mif\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mlen\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m(\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mtext\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m)\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;33m>\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mself\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m.\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mmax_length\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m:\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    424\\\\\\\\\\\\\\\\u001b[0m             raise ValueError(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 425\\\\\\\\\\\\\\\\u001b[1;33m                 \\\\\\\\\\\\\\\\u001b[0mErrors\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m.\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mE088\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m.\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mformat\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m(\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mlength\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m=\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mlen\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m(\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mtext\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m,\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mmax_length\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m=\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mself\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m.\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mmax_length\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0;32m    426\\\\\\\\\\\\\\\\u001b[0m             )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    427\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[0mdoc\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[1;33m=\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[0mself\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m.\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mmake_doc\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m(\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0mtext\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[1;33m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n      \\\\\"\\\\\\\\\\\\\\\\u001b[1;31mValueError\\\\\\\\\\\\\\\\u001b[0m: [E088] Text of length 2211708 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you\\\\\\\\\\'re not using the parser or NER, it\\\\\\\\\\'s probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\\\\"\\\\\\\\n     ]\\\\\\\\n    }\\\\\\\\n   ],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"overall_correct_identified_entities = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"overall_correct_unidentified_entities = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"overall_spurious_identified_entites = 0\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"for document in text_corpus:\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # below you will see that entities_1 is from model_1\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # you can make a decision about which model output will be the reference output\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    entities_1 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\"], model_1)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    entities_2 = get_entities(document[\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\"], model_2)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    #correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    # increment the overall variables\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\\\\\\\\\\\\n\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"# now that you are outside the loop, determine the following values\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"precision = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"recall = # determine which set of numbers above needed to calculate\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# what is the overall precision and recall?\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"# does this change if you change the reference model?\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Step 6: \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\\\\\\\\\'t using a normal evaluation set, feel free to speculate as you wish.\\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"markdown\\\\\",\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"source\\\\\": [\\\\\\\\n    \\\\\"Extra Credit: \\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\\\\\\\\\\\\\n\\\\\",\\\\\\\\n    \\\\\"    \\\\\"\\\\\\\\n   ]\\\\\\\\n  },\\\\\\\\n  {\\\\\\\\n   \\\\\"cell_type\\\\\": \\\\\"code\\\\\",\\\\\\\\n   \\\\\"execution_count\\\\\": null,\\\\\\\\n   \\\\\"metadata\\\\\": {},\\\\\\\\n   \\\\\"outputs\\\\\": [],\\\\\\\\n   \\\\\"source\\\\\": []\\\\\\\\n  }\\\\\\\\n ],\\\\\\\\n \\\\\"metadata\\\\\": {\\\\\\\\n  \\\\\"kernelspec\\\\\": {\\\\\\\\n   \\\\\"display_name\\\\\": \\\\\"Python 3\\\\\",\\\\\\\\n   \\\\\"language\\\\\": \\\\\"python\\\\\",\\\\\\\\n   \\\\\"name\\\\\": \\\\\"python3\\\\\"\\\\\\\\n  },\\\\\\\\n  \\\\\"language_info\\\\\": {\\\\\\\\n   \\\\\"codemirror_mode\\\\\": {\\\\\\\\n    \\\\\"name\\\\\": \\\\\"ipython\\\\\",\\\\\\\\n    \\\\\"version\\\\\": 3\\\\\\\\n   },\\\\\\\\n   \\\\\"file_extension\\\\\": \\\\\".py\\\\\",\\\\\\\\n   \\\\\"mimetype\\\\\": \\\\\"text/x-python\\\\\",\\\\\\\\n   \\\\\"name\\\\\": \\\\\"python\\\\\",\\\\\\\\n   \\\\\"nbconvert_exporter\\\\\": \\\\\"python\\\\\",\\\\\\\\n   \\\\\"pygments_lexer\\\\\": \\\\\"ipython3\\\\\",\\\\\\\\n   \\\\\"version\\\\\": \\\\\"3.7.2\\\\\"\\\\\\\\n  }\\\\\\\\n },\\\\\\\\n \\\\\"nbformat\\\\\": 4,\\\\\\\\n \\\\\"nbformat_minor\\\\\": 2\\\\\\\\n}\\\\\\\\n\\'}, {\\'file\\': \\'Person_entites.json\\', \\'content\\': \\'{\\\\\"content\\\\\": \\\\\"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":379,\\\\\"end\\\\\":386,\\\\\"text\\\\\":\\\\\"Blackmon\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":74,\\\\\"end\\\\\":79,\\\\\"text\\\\\":\\\\\"Hardin\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":64,\\\\\"end\\\\\":71,\\\\\"text\\\\\":\\\\\"Blackmon\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":55,\\\\\"end\\\\\":71,\\\\\"text\\\\\":\\\\\"Jonathan Blackmon\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954510000,\\\\\"last_updated_at\\\\\":1586954510000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"CORRECT\\\\\"}}\\\\\\\\n{\\\\\"content\\\\\": \\\\\"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":453,\\\\\"end\\\\\":460,\\\\\"text\\\\\":\\\\\"Morrison\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":79,\\\\\"end\\\\\":91,\\\\\"text\\\\\":\\\\\"Peter O’Neill\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":32,\\\\\"end\\\\\":39,\\\\\"text\\\\\":\\\\\"Morrison\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":26,\\\\\"end\\\\\":39,\\\\\"text\\\\\":\\\\\"Scott Morrison\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954448000,\\\\\"last_updated_at\\\\\":1586954448000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n{\\\\\"content\\\\\": \\\\\"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":0,\\\\\"end\\\\\":10,\\\\\"text\\\\\":\\\\\"Joe Montana\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954477000,\\\\\"last_updated_at\\\\\":1586954477000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n{\\\\\"content\\\\\": \\\\\"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":816,\\\\\"end\\\\\":825,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":701,\\\\\"end\\\\\":710,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":588,\\\\\"end\\\\\":594,\\\\\"text\\\\\":\\\\\"Merritt\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":576,\\\\\"end\\\\\":581,\\\\\"text\\\\\":\\\\\"Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":532,\\\\\"end\\\\\":537,\\\\\"text\\\\\":\\\\\"Walker\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":501,\\\\\"end\\\\\":510,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":224,\\\\\"end\\\\\":230,\\\\\"text\\\\\":\\\\\"Merritt\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":218,\\\\\"end\\\\\":229,\\\\\"text\\\\\":\\\\\"Piper Merrit\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":183,\\\\\"end\\\\\":192,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]},{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":25,\\\\\"end\\\\\":34,\\\\\"text\\\\\":\\\\\"John Deere\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954335000,\\\\\"last_updated_at\\\\\":1586954335000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n{\\\\\"content\\\\\": \\\\\"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\\\\\\\\\\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\\\\\\\\\\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\\\\\",\\\\\"annotation\\\\\":[{\\\\\"label\\\\\":[\\\\\"Person\\\\\"],\\\\\"points\\\\\":[{\\\\\"start\\\\\":44,\\\\\"end\\\\\":62,\\\\\"text\\\\\":\\\\\"George Washington’s\\\\\"}]}],\\\\\"extras\\\\\":null,\\\\\"metadata\\\\\":{\\\\\"first_done_at\\\\\":1586954354000,\\\\\"last_updated_at\\\\\":1586954354000,\\\\\"sec_taken\\\\\":0,\\\\\"last_updated_by\\\\\":\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\",\\\\\"status\\\\\":\\\\\"done\\\\\",\\\\\"evaluation\\\\\":\\\\\"NONE\\\\\"}}\\\\\\\\n\\'}]\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"#dir_base = \\\\\"/GWU/NATURAL LANGUAGE PROCESSiNG/s20_ds_nlp-master/homeworks/homework_3/news_data\\\\\"\\\\n\",\\n    \"\\\\n\",\\n    \"\\\\n\",\\n    \"####\\\\n\",\\n    \"# Notice: We are reusing code from class notes... remember these kind of building blocks\\\\n\",\\n    \"####\\\\n\",\\n    \"\\\\n\",\\n    \"def read_file(filename):\\\\n\",\\n    \"    input_file_text = open(filename , encoding=\\'utf-8\\').read()\\\\n\",\\n    \"    return input_file_text\\\\n\",\\n    \"\\\\n\",\\n    \"    \\\\n\",\\n    \"def read_directory_files(directory):\\\\n\",\\n    \"    file_texts = []\\\\n\",\\n    \"    files = [f for f in listdir(directory) if isfile(join(directory, f))]\\\\n\",\\n    \"    for f in files:\\\\n\",\\n    \"        file_text = read_file(join(directory, f))\\\\n\",\\n    \"        print(file_text)\\\\n\",\\n    \"        file_texts.append({\\\\\"file\\\\\":f, \\\\\"content\\\\\": file_text })\\\\n\",\\n    \"    return file_texts\\\\n\",\\n    \"    \\\\n\",\\n    \"# here we will generate the list that contains all the files and their contents\\\\n\",\\n    \"text_corpus = read_directory_files(dir_base)\\\\n\",\\n    \"print(text_corpus)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 21,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# extract entities\\\\n\",\\n    \"def get_entities(document_text, model):\\\\n\",\\n    \"    analyzed_doc = model(document_text)\\\\n\",\\n    \"    # here we are just limiting to a small set of entity types\\\\n\",\\n    \"    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\\\\\"PER\\\\\", \\\\\"ORG\\\\\", \\\\\"LOC\\\\\", \\\\\"GPE\\\\\"]]\\\\n\",\\n    \"    return entities\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 65,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"for document in text_corpus[:]:\\\\n\",\\n    \"    entities_1 = get_entities(document[\\\\\"content\\\\\"], model_1)\\\\n\",\\n    \"    entities_2 = get_entities(document[\\\\\"content\\\\\"], model_2)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 66,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"28\"\\n      ]\\n     },\\n     \"execution_count\": 66,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"len(entities_1)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 67,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"23\"\\n      ]\\n     },\\n     \"execution_count\": 67,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"len(entities_2)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 69,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"1\"\\n      ]\\n     },\\n     \"execution_count\": 69,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"match\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 70,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"22\"\\n      ]\\n     },\\n     \"execution_count\": 70,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"unmatch\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 71,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"0\"\\n      ]\\n     },\\n     \"execution_count\": 71,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"spmatch\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 105,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"def compare_entities_from_document(reference_entities, test_entities):\\\\n\",\\n    \"    print(reference_entities)\\\\n\",\\n    \"    print(test_entities)\\\\n\",\\n    \"    # here we need to calculate how different the reference and test entity sets are\\\\n\",\\n    \"    # Since we treat the reference entity set as the ground truth we are trying to find \\\\n\",\\n    \"    # how many of the same entities are returned in the test entity set\\\\n\",\\n    \"    \\\\n\",\\n    \"    # So we need to identify the correctly identified entities that are also in the \\\\n\",\\n    \"    # test entity set and also if entities are not retrieved\\\\n\",\\n    \"    # we also want to count the number of entities that are in the test entity set that\\\\n\",\\n    \"    # are not in the reference entity set as well\\\\n\",\\n    \"    \\\\n\",\\n    \"    # in this case we will only concern ourselves with exact matches of entities\\\\n\",\\n    \"    # thus, a match is the same portion of text and the same entity type\\\\n\",\\n    \"    # hint: this is easy if you try to use normal comparisons\\\\n\",\\n    \"    \\\\n\",\\n    \"    correct_identified_entities = 0 \\\\n\",\\n    \"    # count the number of items in the test set \\\\n\",\\n    \"    # that are also in the reference set\\\\n\",\\n    \"    \\\\n\",\\n    \"    correct_unidentified_entities = 0\\\\n\",\\n    \"    # count the number of items that are in the reference set \\\\n\",\\n    \"    # that are not in the test set\\\\n\",\\n    \"    \\\\n\",\\n    \"    spurious_identified_entites = 0\\\\n\",\\n    \"    # count the number of items in the test set that are not in \\\\n\",\\n    \"    # the reference set\\\\n\",\\n    \"    \\\\n\",\\n    \"    \\\\n\",\\n    \"    # one way you could do this is to iterate over the test entity list and see if each\\\\n\",\\n    \"    # item is in the reference entity set\\\\n\",\\n    \"    # so if an item in the test set is in the reference then you would increment the \\\\n\",\\n    \"    # correct_identified_entities number\\\\n\",\\n    \"    \\\\n\",\\n    \"    ###\\\\n\",\\n    \"    # Your code goes here\\\\n\",\\n    \"    ###\\\\n\",\\n    \"    sp = [value for value in test_entities if value not in reference_entities] \\\\n\",\\n    \"    match = [value for value in reference_entities if value  in test_entities]\\\\n\",\\n    \"    unmatch = [value for value in reference_entities if value  not in test_entities]\\\\n\",\\n    \"    correct_identified_entities=len(match)\\\\n\",\\n    \"    correct_unidentified_entities=len(unmatch)\\\\n\",\\n    \"    spurious_identified_entites=len(sp)\\\\n\",\\n    \"    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\\\\n\",\\n    \"    \\\\n\",\\n    \"\\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 106,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"[Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon]\\\\n\",\\n      \"[Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus, statement.\\\\\\\\n\\\\\\\\n“I, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s]\\\\n\",\\n      \"[Text annotations.\\\\\\\\n, \\\\\\\\\\\\\"download\\\\\\\\, num_matches, non-matches.\\\\\\\\n, class.\\\\\\\\n, analyzed_doc.ents, entities_1, model_1)\\\\\\\\n, entities_2, kernelspec]\\\\n\",\\n      \"[tagged.\\\\\\\\n, \\\\\\\\\\\\\"download\\\\\\\\, \\\\\\\\\\\\\"json\\\\\\\\, json, the ACE Guidelines, code.\\\\\\\\n, pprint, read_annotation:\\\\\\\\n\\\\\", num_non_matches, this:\\\\\\\\n\\\\\", own\\\\\\\\n, num_non_matches\\\\\\\\n, num_non_matches, num_non_matches, num_non_matches, os.path, dir_base, files:\\\\\\\\n, \\\\\\\\\\\\\"GPE\\\\\\\\\\\\\"]]\\\\\\\\n\\\\\", correct_unidentified_entities, entities_1, model_1)\\\\\\\\n, correct_unidentified_entities, cell_type, cell_type, ipython]\\\\n\",\\n      \"[Text annotations.\\\\\\\\n, \\\\\\\\\\\\\"download\\\\\\\\, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, zip(smallm.items(),smalln.items, zip(valuem, zip(vm.items(),vn.items()):\\\\\\\\n\\\\\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\\\\\n, v11,v22, m:\\\\\\\\n, v.items():\\\\\\\\n\\\\\", zip(m, zip(smallm.items(),smalln.items, zip(valuem, zip(vm.items(),vn.items()):\\\\\\\\n\\\\\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\\\\\n, v11,v22, zip(vv1,vv2):\\\\\\\\n, num_matches, zip(m, zip(smallm.items(),smalln.items, zip(valuem, zip(vm.items(),vn.items()):\\\\\\\\n\\\\\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\\\\\n, v11,v22, zip(vv1,vv2):\\\\\\\\n, num_matches, compare_annotations(mm, non-matches.\\\\\\\\n, class.\\\\\\\\n, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, FFA.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":816,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":825,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":701,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":710,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":588,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":594,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":576,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":581,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":532,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":537,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Walker\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":527,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":537,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Doug Walker\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":501,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":510,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":224,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":230,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Merritt\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":218,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":231,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Piper Merritt,\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":183,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":192,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":25,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":34,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"John Deere\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1541085478000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1541085478000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n\\\\\", \\\\\\\\\\\\\"A, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, done\\\\\\\\\\\\\\\\\\\\\\\\, annotations\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n, num_matches, num_matches, news.\\\\\\\\\\\\\"\\\\\\\\n, spacy.load(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\"\\\\\\\\n, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3, encoding=\\'utf-8\\').read()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n, types\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n, analyzed_doc.ents, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\\\\, entities_1, entities_2, IOPub, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, speech.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":453,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":460,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":79,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":91,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Peter O’Neill\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":32,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":39,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Morrison\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":26,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":39,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Scott Morrison\\\\\\\\\\\\\"}]}],\\\\\\\\\\\\\"extras\\\\\\\\\\\\\":null,\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\":{\\\\\\\\\\\\\"first_done_at\\\\\\\\\\\\\":1586954448000,\\\\\\\\\\\\\"last_updated_at\\\\\\\\\\\\\":1586954448000,\\\\\\\\\\\\\"sec_taken\\\\\\\\\\\\\":0,\\\\\\\\\\\\\"last_updated_by\\\\\\\\\\\\\":\\\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\\\",\\\\\\\\\\\\\"status\\\\\\\\\\\\\":\\\\\\\\\\\\\"done\\\\\\\\\\\\\",\\\\\\\\\\\\\"evaluation\\\\\\\\\\\\\":\\\\\\\\\\\\\"NONE\\\\\\\\\\\\\"}}\\\\\\\\n, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, \\\\\\\\\\\\\"A, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, IOPub, dir_base, analyzed_doc.ents, NER, NER, entities_1, model_1\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[1;33m\\\\\\\\u001b[0m\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32, \\\\\\\\u001b[0;36mget_entities\\\\\\\\u001b[1;34m(document_text, \\\\\\\\u001b[0;36m__call__\\\\\\\\u001b[1;34m(self,, NER, NER, entities_1, model_1)\\\\\\\\n, entities_2, kernelspec]\\\\n\",\\n      \"[tagged.\\\\\\\\n, \\\\\\\\\\\\\"download\\\\\\\\, \\\\\\\\\\\\\"json\\\\\\\\, json, the ACE Guidelines, code.\\\\\\\\n, Polk County Sheriff’s, Rome, zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, Mount Vernon’s, encoding=\\'utf8\\')\\\\\\\\n, num_non_matches, own\\\\\\\\n, smallm, smalln, zip(m, n):\\\\\\\\n\\\\\", keym, valuem, keyn, valuen, keyn==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":\\\\\\\\n, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\\\\\n, vk1,vv1, vk2,vv2, num_non_matches, m:\\\\\\\\n, small.items():\\\\\\\\n\\\\\", vk, vv, v.items():\\\\\\\\n\\\\\", vvl, vv:\\\\\\\\n, vvl, vv:\\\\\\\\n, vvlk, vvlv, vvl.items():\\\\\\\\n, n):\\\\\\\\n\\\\\", num_matches, num_non_matches, this:\\\\\\\\n\\\\\", own\\\\\\\\n, smallm, smalln, zip(m, n):\\\\\\\\n\\\\\", keym, valuem, keyn, valuen, keyn==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":\\\\\\\\n, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\\\\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches, n):\\\\\\\\n\\\\\", num_matches, num_non_matches, this:\\\\\\\\n\\\\\", own\\\\\\\\n, smallm, smalln, zip(m, n):\\\\\\\\n\\\\\", keym, valuem, keyn, valuen, keyn==\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":\\\\\\\\n, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\\\\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches\\\\\\\\n, print(compare_annotation_files(m, n), cell_type, os.path, Polk County Sheriff’s, Rome, zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, well.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":379,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":386,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":293,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":296,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Irma\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":267,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":272,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Harvey\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":74,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":79,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Hardin\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":64,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":71,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Blackmon\\\\\\\\\\\\\"}]},{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":42,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":71,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"Chief, Papua New Guinea, Sydney, Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe, the Pacific for the Pacific’s, Morrison, Montana, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, Mount Vernon’s, period.\\\\\\\\\\\\\",\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"label\\\\\\\\\\\\\":[\\\\\\\\\\\\\"Person\\\\\\\\\\\\\"],\\\\\\\\\\\\\"points\\\\\\\\\\\\\":[{\\\\\\\\\\\\\"start\\\\\\\\\\\\\":85,\\\\\\\\\\\\\"end\\\\\\\\\\\\\":116,\\\\\\\\\\\\\"text\\\\\\\\\\\\\":\\\\\\\\\\\\\"A, submit\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\", done\\\\\\\\\\\\\\\\\\\\\\\\, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\, json, the ACE Guidelines, \\\\\\\\\\\\\"She, num_matches, num_non_matches, method\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n, num_matches, num_non_matches, num_non_matches, isfile, join\\\\\\\\\\\\\"\\\\\\\\n, blocks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\", input_file_text, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\, types\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\", entity.label_, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\\\\\\\\\\, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\\\\, entities\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\", type\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\", correct_unidentified_entities, each\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n\\\\\", correct_unidentified_entities, entities_1, correct_unidentified_entities, variables\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\",\\\\\\\\n, IOPub, Polk County Sheriff’s, Rome, zone.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus Island.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, Mount Vernon’s, IOPub, files:\\\\\\\\n, model):\\\\\\\\n\\\\\", \\\\\\\\\\\\\"GPE\\\\\\\\\\\\\"]]\\\\\\\\n\\\\\", correct_unidentified_entities, entities_1, correct_unidentified_entities, \\\\\\\\u001b[0;36mget_entities\\\\\\\\u001b[1;34m(document_text, model)\\\\\\\\u001b[0m\\\\\\\\n\\\\\\\\u001b[0;32m, \\\\\\\\u001b[0;36m__call__\\\\\\\\u001b[1;34m(self, 426\\\\\\\\u001b[0m             , entities_1, model_1)\\\\\\\\n, correct_unidentified_entities, cell_type, cell_type, ipython]\\\\n\",\\n      \"[Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon]\\\\n\",\\n      \"[Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus, statement.\\\\\\\\n\\\\\\\\n“I, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s]\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"for document in text_corpus:\\\\n\",\\n    \"    # below you will see that entities_1 is from model_1\\\\n\",\\n    \"    # you can make a decision about which model output will be the reference output\\\\n\",\\n    \"    entities_1 = get_entities(document[\\\\\"content\\\\\"], model_1)\\\\n\",\\n    \"    entities_2 = get_entities(document[\\\\\"content\\\\\"], model_2)\\\\n\",\\n    \"    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\\\\n\",\\n    \"    \\\\n\",\\n    \"    \\\\n\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": []\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 109,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"name\": \"stdout\",\\n     \"output_type\": \"stream\",\\n     \"text\": [\\n      \"14\\\\n\",\\n      \"0.5\\\\n\",\\n      \"0.5\\\\n\"\\n     ]\\n    }\\n   ],\\n   \"source\": [\\n    \"# now that you are outside the loop, determine the following values\\\\n\",\\n    \"#fn=(len(entities_1)+len(entities_2))-(correct_identified_entities+correct_unidentified_entities+spurious_identified_entites)\\\\n\",\\n    \"precision = correct_identified_entities/(correct_identified_entities+spurious_identified_entites)\\\\n\",\\n    \"# determine which set of numbers above needed to calculate\\\\n\",\\n    \"recall = correct_identified_entities/(correct_identified_entities+correct_unidentified_entities)\\\\n\",\\n    \"# determine which set of numbers above needed to calculate\\\\n\",\\n    \"print(fn)\\\\n\",\\n    \"print(precision)\\\\n\",\\n    \"print(recall)\\\\n\",\\n    \"# what is the overall precision and recall?\\\\n\",\\n    \"# does this change if you change the reference model?\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Step 6: \\\\n\",\\n    \"Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren\\'t using a normal evaluation set, feel free to speculate as you wish.\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"Extra Credit: \\\\n\",\\n    \"\\\\n\",\\n    \"- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\\\\n\",\\n    \"- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\\\\n\",\\n    \"    \"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": []\\n  }\\n ],\\n \"metadata\": {\\n  \"kernelspec\": {\\n   \"display_name\": \"Python 3\",\\n   \"language\": \"python\",\\n   \"name\": \"python3\"\\n  },\\n  \"language_info\": {\\n   \"codemirror_mode\": {\\n    \"name\": \"ipython\",\\n    \"version\": 3\\n   },\\n   \"file_extension\": \".py\",\\n   \"mimetype\": \"text/x-python\",\\n   \"name\": \"python\",\\n   \"nbconvert_exporter\": \"python\",\\n   \"pygments_lexer\": \"ipython3\",\\n   \"version\": \"3.7.2\"\\n  }\\n },\\n \"nbformat\": 4,\\n \"nbformat_minor\": 2\\n}\\n'}, {'file': 'Person_entites.json', 'content': '{\"content\": \"According to Polk County Sheriff’s Office Chief Deputy Jonathan Blackmon, Hardin is a Rome native who worked with RomeCares and Floyd Sheriff’s officials to get the supplies to a disaster relief zone.\\\\n\\\\n“We originally took in the supplies for the victims of Hurricane Harvey in Texas, but when Irma hit closer to home we felt it would be more beneficial to send them to Florida,” Blackmon said.\\\\n\\\\nThe team that went to Florida with the supplies helped with relief efforts in the Moore Haven area as well.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":379,\"end\":386,\"text\":\"Blackmon\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":74,\"end\":79,\"text\":\"Hardin\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":64,\"end\":71,\"text\":\"Blackmon\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":55,\"end\":71,\"text\":\"Jonathan Blackmon\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954510000,\"last_updated_at\":1586954510000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"CORRECT\"}}\\n{\"content\": \"Australian Prime Minister Scott Morrison and his Papua New Guinea counterpart, Peter O’Neill, met in Sydney to sign the joint redevelopment agreement for the Lombrum Naval Base on Manus Island.\\\\n\\\\nThe deal will enhance interoperability between the near-neighbors’ militaries and lead to more Australian naval visits, the leaders said in a statement.\\\\n\\\\n“I want to strengthen our engagement with the Pacific for the Pacific’s sake because this is our home,” Morrison said in a foreign policy speech.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":453,\"end\":460,\"text\":\"Morrison\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":79,\"end\":91,\"text\":\"Peter O’Neill\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":32,\"end\":39,\"text\":\"Morrison\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":26,\"end\":39,\"text\":\"Scott Morrison\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954448000,\"last_updated_at\":1586954448000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n{\"content\": \"Joe Montana, forever linked with Dwight Clark, knows exactly how his old friend would have handled the unveiling of “The Catch” statue on Sunday morning.\\\\n\\\\n“He’d be whispering in my ear: ‘You know they didn’t call it ‘The Throw’ for a reason,’ ” the quarterback joked.\\\\n\\\\nMontana and more than 70 other former 49ers attended the unveiling ceremony at Gate A outside Levi’s Stadium. The twin statues feature an airborne Clark leaping high into the air for a fingertip catch, just as he did for “The Catch” against the Dallas Cowboys in the NFC Championship game on Jan. 10, 1982.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":0,\"end\":10,\"text\":\"Joe Montana\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954477000,\"last_updated_at\":1586954477000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n{\"content\": \"To celebrate 75 years of John Deere partnering and supporting the National FFA organization, National FFA commissioned the Delphi FFA Chapter of Delphi, Ind., to completely restore a John Deere Model B tractor.\\\\n\\\\n“When Piper Merritt, the 2017-2018 National FFA central region vice president visited our chapter during 2018 National FFA Week and saw four to five tractors we were restoring at the time in our shop, she mentioned that the National FFA Organization was looking for a chapter to restore a John Deere tractor,” said Doug Walker, adviser of the Delphi FFA Chapter.\\\\n\\\\nWalker said Merritt called within days saying that the National FFA would like the Delphi Chapter to be the one to restore a John Deere tractor that would be presented at the National FFA Convention to honor the 75-year partnership between John Deere and FFA.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":816,\"end\":825,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":701,\"end\":710,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":588,\"end\":594,\"text\":\"Merritt\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":576,\"end\":581,\"text\":\"Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":532,\"end\":537,\"text\":\"Walker\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":501,\"end\":510,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":224,\"end\":230,\"text\":\"Merritt\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":218,\"end\":229,\"text\":\"Piper Merrit\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":183,\"end\":192,\"text\":\"John Deere\"}]},{\"label\":[\"Person\"],\"points\":[{\"start\":25,\"end\":34,\"text\":\"John Deere\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954335000,\"last_updated_at\":1586954335000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n{\"content\": \"A 6,000-year-old axe has been discovered at George Washington’s Mount Vernon estate.\\\\nA group of students and teachers participating in an archaeology field trip discover the stone axe head at Mount Vernon’s African American cemetery on Oct. 12.\\\\nAccording to a release, the axe – which is seven inches long and three inches wide – dates back to the fourth millennia BCE and would have been an important part of the Native American toolkit during that period.\",\"annotation\":[{\"label\":[\"Person\"],\"points\":[{\"start\":44,\"end\":62,\"text\":\"George Washington’s\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1586954354000,\"last_updated_at\":1586954354000,\"sec_taken\":0,\"last_updated_by\":\"GAUua4TByDWq4pqf203jFtL8DoL2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\\n'}]\n"
     ]
    }
   ],
   "source": [
    "#dir_base = \"/GWU/NATURAL LANGUAGE PROCESSiNG/s20_ds_nlp-master/homeworks/homework_3/news_data\"\n",
    "\n",
    "\n",
    "####\n",
    "# Notice: We are reusing code from class notes... remember these kind of building blocks\n",
    "####\n",
    "\n",
    "def read_file(filename):\n",
    "    input_file_text = open(filename , encoding='utf-8').read()\n",
    "    return input_file_text\n",
    "\n",
    "    \n",
    "def read_directory_files(directory):\n",
    "    file_texts = []\n",
    "    files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    for f in files:\n",
    "        file_text = read_file(join(directory, f))\n",
    "        print(file_text)\n",
    "        file_texts.append({\"file\":f, \"content\": file_text })\n",
    "    return file_texts\n",
    "    \n",
    "# here we will generate the list that contains all the files and their contents\n",
    "text_corpus = read_directory_files(dir_base)\n",
    "print(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract entities\n",
    "def get_entities(document_text, model):\n",
    "    analyzed_doc = model(document_text)\n",
    "    # here we are just limiting to a small set of entity types\n",
    "    entities = [entity for entity in analyzed_doc.ents if entity.label_ in [\"PER\", \"ORG\", \"LOC\", \"GPE\"]]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in text_corpus[:]:\n",
    "    entities_1 = get_entities(document[\"content\"], model_1)\n",
    "    entities_2 = get_entities(document[\"content\"], model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_entities_from_document(reference_entities, test_entities):\n",
    "    print(reference_entities)\n",
    "    print(test_entities)\n",
    "    # here we need to calculate how different the reference and test entity sets are\n",
    "    # Since we treat the reference entity set as the ground truth we are trying to find \n",
    "    # how many of the same entities are returned in the test entity set\n",
    "    \n",
    "    # So we need to identify the correctly identified entities that are also in the \n",
    "    # test entity set and also if entities are not retrieved\n",
    "    # we also want to count the number of entities that are in the test entity set that\n",
    "    # are not in the reference entity set as well\n",
    "    \n",
    "    # in this case we will only concern ourselves with exact matches of entities\n",
    "    # thus, a match is the same portion of text and the same entity type\n",
    "    # hint: this is easy if you try to use normal comparisons\n",
    "    \n",
    "    correct_identified_entities = 0 \n",
    "    # count the number of items in the test set \n",
    "    # that are also in the reference set\n",
    "    \n",
    "    correct_unidentified_entities = 0\n",
    "    # count the number of items that are in the reference set \n",
    "    # that are not in the test set\n",
    "    \n",
    "    spurious_identified_entites = 0\n",
    "    # count the number of items in the test set that are not in \n",
    "    # the reference set\n",
    "    \n",
    "    \n",
    "    # one way you could do this is to iterate over the test entity list and see if each\n",
    "    # item is in the reference entity set\n",
    "    # so if an item in the test set is in the reference then you would increment the \n",
    "    # correct_identified_entities number\n",
    "    \n",
    "    ###\n",
    "    # Your code goes here\n",
    "    ###\n",
    "    sp = [value for value in test_entities if value not in reference_entities] \n",
    "    match = [value for value in reference_entities if value  in test_entities]\n",
    "    unmatch = [value for value in reference_entities if value  not in test_entities]\n",
    "    correct_identified_entities=len(match)\n",
    "    correct_unidentified_entities=len(unmatch)\n",
    "    spurious_identified_entites=len(sp)\n",
    "    return correct_identified_entities, correct_unidentified_entities, spurious_identified_entites\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\nA, Mount Vernon]\n",
      "[Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus, statement.\\n\\n“I, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\nA, Mount Vernon’s]\n",
      "[Text annotations.\\n, \\\"download\\, num_matches, non-matches.\\n, class.\\n, analyzed_doc.ents, entities_1, model_1)\\n, entities_2, kernelspec]\n",
      "[tagged.\\n, \\\"download\\, \\\"json\\, json, the ACE Guidelines, code.\\n, pprint, read_annotation:\\n\", num_non_matches, this:\\n\", own\\n, num_non_matches\\n, num_non_matches, num_non_matches, num_non_matches, os.path, dir_base, files:\\n, \\\"GPE\\\"]]\\n\", correct_unidentified_entities, entities_1, model_1)\\n, correct_unidentified_entities, cell_type, cell_type, ipython]\n",
      "[Text annotations.\\n, \\\"download\\, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\nA, zip(m, zip(smallm.items(),smalln.items, zip(valuem, zip(vm.items(),vn.items()):\\n\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\n, v11,v22, zip(vv1,vv2):\\n, num_matches, compare_annotations(mm, non-matches.\\n, class.\\n, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, FFA.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":816,\\\"end\\\":825,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":701,\\\"end\\\":710,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":588,\\\"end\\\":594,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":576,\\\"end\\\":581,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":532,\\\"end\\\":537,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":527,\\\"end\\\":537,\\\"text\\\":\\\"Doug Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":501,\\\"end\\\":510,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":224,\\\"end\\\":230,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":218,\\\"end\\\":231,\\\"text\\\":\\\"Piper Merritt,\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":183,\\\"end\\\":192,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":25,\\\"end\\\":34,\\\"text\\\":\\\"John Deere\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085478000,\\\"last_updated_at\\\":1541085478000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n\", \\\"A, Mount Vernon estate.\\\\nA, done\\\\\\, annotations\\\\n\\\",\\n, num_matches, num_matches, news.\\\"\\n, spacy.load(\\\\\\\"en_core_web_md\\\\\\\")\\\"\\n, \\\\\\\"/s20_ds_nlp/homeworks/homework_3, encoding='utf-8').read()\\\\n\\\",\\n, types\\\\n\\\",\\n, analyzed_doc.ents, \\\\\\\"LOC\\\\\\, entities_1, entities_2, done\\\\\\, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon, annotations\\\\n\\\",\\n, zip(m, n):\\\\n\\\",\\n, zip(smallm.items(),smalln.items, vm, vn, zip(valuem, zip(vm.items(),vn.items()):\\\\n\\\",\\n\", vk2,vv2, v11,v22, num_matches, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag, \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag, \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag, \\\"keys start\\\\n\\\",\\n, \\\"tag, \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"value Doug, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag, \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, \\\"tag, \\\"keys start\\\\n\\\",\\n, \\\"tag, \\\"keys start\\\\n\\\",\\n, \\\"tag Person\\\\n\\\",\\n\", \\\"keys start\\\\n\\\",\\n, v.items():\\\\n\\\",\\n, vv:\\\\n\\\",\\n\", vv:\\\\n\\\",\\n\", n):\\\\n\\\",\\n, num_matches, zip(m, n):\\\\n\\\",\\n, zip(smallm.items(),smalln.items, vm, vn, zip(valuem, zip(vm.items(),vn.items()):\\\\n\\\",\\n\", vk2,vv2, v11,v22, num_matches, num_matches, n):\\\\n\\\",\\n, num_matches, zip(m, n):\\\\n\\\",\\n, zip(smallm.items(),smalln.items, vm, vn, zip(valuem, zip(vm.items(),vn.items()):\\\\n\\\",\\n\", vk2,vv2, v11,v22, num_matches, num_matches, compare_annotations(mm, nn)\\\\n\\\",\\n, news.\\\"\\n, spacy.load(\\\\\\\"en_core_web_md\\\\\\\")\\\"\\n, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon, period.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":85,\\\\\\\"end\\\\\\\":116,\\\\\\\"text\\\\\\\":\\\\\\\"A group of students, \\\\\\\"def annotation_processor(annotation_file):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, homework_3/annotated_data/annotated.json')\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\", num_matches, num_matches, reference_annotation_array:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, compare_annotations(annotation[\\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\, temp_num_matches, news.\\\\\\\"\\\\n\\\",\\n, \\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3, analyzed_doc.ents, \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\, test_entities):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, entities_1, entities_2, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, speech.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":453,\\\\\\\"end\\\\\\\":460,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":79,\\\\\\\"end\\\\\\\":91,\\\\\\\"text\\\\\\\":\\\\\\\"Peter O’Neill\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":32,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":26,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Scott Morrison\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954448000,\\\\\\\"last_updated_at\\\\\\\":1586954448000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n\", Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon, \\\"NotebookApp.iopub_data_rate_limit=1000000.0, encoding='utf-8').read()\\\\n\\\",\\n, types\\\\n\\\",\\n, analyzed_doc.ents, \\\\\\\"LOC\\\\\\, NER, NER, entities_1, entities\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32m      , NER, NER, entities_1, entities_2, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, speech.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":453,\\\"end\\\":460,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":79,\\\"end\\\":91,\\\"text\\\":\\\"Peter O’Neill\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":32,\\\"end\\\":39,\\\"text\\\":\\\"Morrison\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":26,\\\"end\\\":39,\\\"text\\\":\\\"Scott Morrison\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1586954448000,\\\"last_updated_at\\\":1586954448000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\n, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the National FFA, John Deere, the National FFA Convention, \\\"A, Mount Vernon estate.\\\\nA, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, the National FFA, John Deere, the National FFA Convention, FFA.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":816,\\\"end\\\":825,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":701,\\\"end\\\":710,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":588,\\\"end\\\":594,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":576,\\\"end\\\":581,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":532,\\\"end\\\":537,\\\"text\\\":\\\"Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":527,\\\"end\\\":537,\\\"text\\\":\\\"Doug Walker\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":501,\\\"end\\\":510,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":224,\\\"end\\\":230,\\\"text\\\":\\\"Merritt\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":218,\\\"end\\\":231,\\\"text\\\":\\\"Piper Merritt,\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":183,\\\"end\\\":192,\\\"text\\\":\\\"John Deere\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":25,\\\"end\\\":34,\\\"text\\\":\\\"John Deere\\\"}]}],\\\"extras\\\":null,\\\"metadata\\\":{\\\"first_done_at\\\":1541085478000,\\\"last_updated_at\\\":1541085478000,\\\"sec_taken\\\":0,\\\"last_updated_by\\\":\\\"nJUvh8eg6cTQb2imeaFWqJDvwDt1\\\",\\\"status\\\":\\\"done\\\",\\\"evaluation\\\":\\\"NONE\\\"}}\\\\n{\\\"content\\, \\\"A, Mount Vernon estate.\\\\\\\\nA, Mount Vernon, you\\\\'ll, null,\\\\n, read_annotation:\\\\\\\\n\\\",\\\\n, null,\\\\n, null,\\\\n, num_matches, num_matches, num_non_matches\\\\\\\\n\\\",\\\\n, compare_annotation_files(reference_annotation_array, numbers\\\\\\\\n\\\",\\\\n, num_matches, identical\\\\\\\\n\\\",\\\\n, compare_annotations(annotation[\\\\\\\\\\\"annotation\\\\\\\\\\, num_matches, null,\\\\n, people\\\\\\\\n\\\",\\\\n, Kappa, null,\\\\n, null,\\\\n, null,\\\\n, join\\\"\\\\n, null,\\\\n, read_file(filename):\\\\\\\\n\\\",\\\\n, read_directory_files(dir_base)\\\\\\\\n\\\",\\\\n, null,\\\\n, get_entities(document_text, analyzed_doc.ents, \\\\\\\\\\\"ORG\\\\\\\\\\\", \\\\\\\\\\\"LOC\\\\\\\\\\, null,\\\\n, number\\\\\\\\n\\\",\\\\n, null,\\\\n, text_corpus:\\\\\\\\n\\\",\\\\n, entities_1, entities_2, null,\\\\n, calculate\\\\\\\\n\\\",\\\\n, calculate\\\\\\\\n\\\",\\\\n, null,\\\\n, you\\\\'ll, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, None,\\\\\\\\n\\\",\\\\n, Papua New Guinea, Sydney, Pacific, Pacific, None,\\\\\\\\n\\\",\\\\n, Montana, Gate A, Levi, None,\\\\\\\\n\\\",\\\\n, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker, the National FFA, John Deere, the National FFA Convention, \\\\'start\\\\, None,\\\\\\\\n\\\",\\\\n, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, None,\\\\\\\\n\\\",\\\\n, read_annotation:\\\\\\\\n\\\",\\\\n, zip(m, zip(smallm.items(),smalln.items, vm, vn, zip(valuem, vk1,vv1, vk2,vv2, vv1==vv2:\\\\\\\\n\\\",\\\\n, num_matches, \\\"keys, \\\"keys, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      , \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"tag, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"tag, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"tag, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"keys, \\\"keys, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"keys, \\\"tag, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"keys, \\\"keys, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, \\\"tag, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      , \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys, \\\"keys text\\\\\\\\n\\\",\\\\n      \\\"value, value:\\\\\\\\n\\\",\\\\n, v.items():\\\\\\\\n\\\",\\\\n, num_matches, zip(m, zip(smallm.items(),smalln.items, vm, vn, zip(valuem, vk1,vv1, vk2,vv2, v11,v22, vv1==vv2:\\\\\\\\n\\\",\\\\n, num_matches, num_matches, n))\\\\\\\\n\\\",\\\\n, num_matches, zip(m, zip(smallm.items(),smalln.items, vm, vn, zip(valuem, vk1,vv1, vk2,vv2, v11,v22, vv1==vv2:\\\\\\\\n\\\",\\\\n, num_matches, num_matches, num_non_matches\\\\\\\\n\\\",\\\\n, compare_annotations(mm, people\\\\\\\\n\\\",\\\\n, Kappa, join\\\"\\\\n, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, well.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":379,\\\\\\\\\\\"end\\\\\\\\\\\":386,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":293,\\\\\\\\\\\"end\\\\\\\\\\\":296,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Irma\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":267,\\\\\\\\\\\"end\\\\\\\\\\\":272,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Harvey\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":74,\\\\\\\\\\\"end\\\\\\\\\\\":79,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Hardin\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":64,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":42,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Chief, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, period.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":85,\\\\\\\\\\\"end\\\\\\\\\\\":116,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"A group of, method\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, num_matches, num_matches, \\\\\\\\\\\\\\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3/, model):\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, analyzed_doc.ents, \\\\\\\\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\\\\\\, entities_1, entities_2, \\\"NotebookApp.iopub_data_rate_limit=1000000.0, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, \\\"NotebookApp.iopub_data_rate_limit=1000000.0, blocks\\\\\\\\n\\\",\\\\n, read_file(filename):\\\\\\\\n\\\",\\\\n, read_directory_files(dir_base)\\\\\\\\n\\\",\\\\n, get_entities(document_text, analyzed_doc.ents, \\\\\\\\\\\"ORG\\\\\\\\\\\", \\\\\\\\\\\"LOC\\\\\\\\\\, null,\\\\n, number\\\\\\\\n\\\",\\\\n, NER, NER, \\\\\\\\u001b[0;36m, entities_1, \\\\\\\\u001b[0;36mget_entities\\\\\\\\u001b[1;34m(document_text, NER, NER, text_corpus:\\\\\\\\n\\\",\\\\n, entities_1, entities_2, null,\\\\n, calculate\\\\\\\\n\\\",\\\\n, calculate\\\\\\\\n\\\",\\\\n, null,\\\\n, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, the National FFA, John Deere, the National FFA Convention, \\\"A, Mount Vernon estate.\\\\\\\\nA, Mount Vernon, dir_base, analyzed_doc.ents, entities_2, get_entities(document[\\\"content\\, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, Levi, National FFA, National FFA, Ind., the National FFA Organization, Delphi, the National FFA, the National FFA Convention, Mount Vernon]\\n\", Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, Morrison, NFC Championship, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the National FFA Convention, num_matches, non-matches.\\\\n, class.\\\\n, analyzed_doc.ents, entities_1, model_1)\\\\n, entities_2, ACE Guidelines, code.\\\\n, pprint, own\\\\n, num_non_matches\\\\n, num_non_matches, num_non_matches, dir_base, files:\\\\n, entities_1, cell_type, cell_type, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, Levi, National FFA, National FFA, Ind., the National FFA Organization, the National FFA, the National FFA Convention, Mount Vernon, zip(smallm.items(),smalln.items, zip(valuem, vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, m:\\\\n, zip(smallm.items(),smalln.items, zip(valuem, vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, zip(vv1,vv2):\\\\n, num_matches, zip(smallm.items(),smalln.items, zip(valuem, vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, zip(vv1,vv2):\\\\n, num_matches, compare_annotations(mm, non-matches.\\\\n, class.\\\\n, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Levi, National FFA, National FFA, Ind., the National FFA Organization, the National FFA, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, done\\\\\\\\\\\\, annotations\\\\\\\\n\\\\\\\",\\\\n, num_matches, num_matches, news.\\\\\\\"\\\\n, spacy.load(\\\\\\\\\\\\\\\"en_core_web_md\\\\\\\\\\\\\\\")\\\\\\\"\\\\n, \\\\\\\\\\\\\\\"/s20_ds_nlp/homeworks/homework_3, types\\\\\\\\n\\\\\\\",\\\\n, analyzed_doc.ents, \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\, entities_1, entities_2, IOPub, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, speech.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":453,\\\\\\\"end\\\\\\\":460,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":79,\\\\\\\"end\\\\\\\":91,\\\\\\\"text\\\\\\\":\\\\\\\"Peter O’Neill\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":32,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":26,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Scott Morrison\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954448000,\\\\\\\"last_updated_at\\\\\\\":1586954448000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n, Montana, Levi, National FFA, National FFA, Ind., the National FFA Organization, the National FFA, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, IOPub, dir_base, analyzed_doc.ents, NER, NER, entities_1, NER, NER, entities_1, model_1)\\\\n, entities_2, ACE Guidelines, code.\\\\n, Polk County Sheriff, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, Morrison, NFC Championship, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon, valuem, keyn, valuen, vm, zip(valuem, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, m:\\\\n, vv, v.items():\\\\n\\, vvl, vv:\\\\n, vv:\\\\n, vvl.items():\\\\n, num_matches, valuem, keyn, valuen, vm, zip(valuem, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_matches, valuem, keyn, valuen, vm, zip(valuem, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches\\\\n, os.path, Polk County Sheriff, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, well.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":379,\\\\\\\"end\\\\\\\":386,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":293,\\\\\\\"end\\\\\\\":296,\\\\\\\"text\\\\\\\":\\\\\\\"Irma\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":267,\\\\\\\"end\\\\\\\":272,\\\\\\\"text\\\\\\\":\\\\\\\"Harvey\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":74,\\\\\\\"end\\\\\\\":79,\\\\\\\"text\\\\\\\":\\\\\\\"Hardin\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":64,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":42,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Chief, Papua New Guinea, Sydney, Pacific, Pacific, Morrison, Montana, NFC Championship, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon, period.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":85,\\\\\\\"end\\\\\\\":116,\\\\\\\"text\\\\\\\":\\\\\\\"A, submit\\\\\\\\n\\\\\\\",\\\\n\\\", done\\\\\\\\\\\\, json, num_matches, num_non_matches, method\\\\\\\\n\\\\\\\",\\\\n, num_matches, \\\\\\\\\\\\\\\"PER\\\\\\\\\\\\, \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\, entities_1, variables\\\\\\\\n\\\\\\\",\\\\n, IOPub, Polk County Sheriff, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, Morrison, NFC Championship, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon, IOPub, files:\\\\n, model):\\\\n\\, entities_1, entities_1, model_1)\\\\n, cell_type, cell_type, Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, Levi, National FFA, National FFA, Ind., the National FFA Organization, Delphi, the National FFA, the National FFA Convention, Mount Vernon]\\n\", Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Papua New Guinea, Sydney, Pacific, Pacific, Morrison, NFC Championship, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the National FFA Convention, entities_1, model_1)\\n, entities_2, kernelspec]\n",
      "[tagged.\\n, \\\"download\\, \\\"json\\, json, the ACE Guidelines, code.\\n, Polk County Sheriff’s, Rome, zone.\\\\n\\\\n“We, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus Island.\\\\n\\\\nThe, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon’s, encoding='utf8')\\n, n):\\n\", num_matches, num_non_matches, this:\\n\", own\\n, smallm, smalln, zip(m, n):\\n\", keym, valuem, keyn, valuen, keyn==\\\"annotation\\\":\\n, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches\\n, print(compare_annotation_files(m, n), cell_type, os.path, Polk County Sheriff’s, Rome, zone.\\\\n\\\\n“We, Texas, Florida, Florida, Moore Haven, well.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":379,\\\"end\\\":386,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":293,\\\"end\\\":296,\\\"text\\\":\\\"Irma\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":267,\\\"end\\\":272,\\\"text\\\":\\\"Harvey\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":74,\\\"end\\\":79,\\\"text\\\":\\\"Hardin\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":64,\\\"end\\\":71,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":42,\\\"end\\\":71,\\\"text\\\":\\\"Chief, Papua New Guinea, Sydney, Manus Island.\\\\n\\\\nThe, the Pacific for the Pacific’s, Morrison, Montana, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon’s, period.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":85,\\\"end\\\":116,\\\"text\\\":\\\"A, submit\\\\n\\\",\\n\", done\\\\\\, \\\\\\\"json\\\\\\, json, the ACE Guidelines, \\\"She, num_matches, num_non_matches, method\\\\n\\\",\\n, num_matches, num_non_matches, num_non_matches, isfile, join\\\"\\n, blocks\\\\n\\\",\\n\", input_file_text, \\\\\\\"content\\\\\\, types\\\\n\\\",\\n\", entity.label_, \\\\\\\"PER\\\\\\, \\\\\\\"LOC\\\\\\, entities\\\\n\\\",\\n\", type\\\\n\\\",\\n\", correct_unidentified_entities, each\\\\n\\\",\\n\", correct_unidentified_entities, entities_1, correct_unidentified_entities, variables\\\\n\\\",\\n, submit\\\\n\\\",\\n\", done\\\\\\, \\\\\\\"json\\\\\\, json, the ACE Guidelines, \\\"She, Polk County Sheriff’s, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, the Pacific for the Pacific’s, Morrison, NFC Championship, 1586954477000,\\\\n\\\",\\n, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s, 1586954354000,\\\\n\\\",\\n, 1586954354000,\\\\n\\\",\\n, \\\"annotation_processor('Person_entites.json')\\\\n\\\"\\n, smalln, n):\\\\n\\\",\\n, keym, valuem, keyn, valuen, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n\\\",\\n\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n\\\",\\n\", num_non_matches, vk, vv, v.items():\\\\n\\\",\\n, vv:\\\\n\\\",\\n\", vvlk, vvlv, vvl.items():\\\\n\\\",\\n, n):\\\\n\\\",\\n, num_matches, num_non_matches, method\\\\n\\\",\\n, smallm, smalln, n):\\\\n\\\",\\n, keym, valuem, keyn, valuen, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n\\\",\\n\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n\\\",\\n\", num_non_matches, num_matches, n):\\\\n\\\",\\n, num_matches, num_non_matches, method\\\\n\\\",\\n, smallm, smalln, n):\\\\n\\\",\\n, keym, valuem, keyn, valuen, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n\\\",\\n\", vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n\\\",\\n\", num_non_matches, \\\"success\\\\n\\\"\\n, \\\"val1,val2, isfile, join\\\"\\n, Polk County Sheriff’s, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, the Pacific for the Pacific’s, Morrison, Montana, NFC Championship, \\\\\\\"To, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\, json, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, read_annotation:\\\\\\\\n\\\\\\\",\\\\n\\\",\\n\", \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, num_matches, \\\\\\, num_non_matches, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, same,\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, my_annotation_array):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, num_matches, \\\\\\, num_non_matches, \\\\\\, num_non_matches, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, temp_num_matches, \\\\\\, \\\\\\, num_matches, num_non_matches\\\\\\\"\\\\n\\\",\\n\", \\\\\\\"print(compare_annotation_files(reference_annotations, calculate.\\\\\\\"\\\\n\\\",\\n, \\\\\\, \\\\\\, improved?\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, \\\\\\, news.\\\\\\\"\\\\n\\\",\\n, \\\\\\, \\\\\\, \\\\\\\"from os.path, isfile, join\\\\\\\"\\\\n\\\",\\n\", \\\\\\, \\\\\\, input_file_text, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\, \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\, \\\\\\, test_entities):\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, \\\\\\, \\\\\\, \\\\\\, are\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, \\\\\\, \\\\\\, set\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, correct_unidentified_entities, \\\\\\, \\\\\\, set\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, \\\\\\, \\\\\\, \\\\\\, \\\\\\\\n\\\\\\\",\\\\n\\\",\\n\", \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, correct_unidentified_entities, \\\\\\, \\\\\\, entities_1, \\\\\\, \\\\\\, \\\\\\, \\\\\\, correct_unidentified_entities, \\\\\\, \\\\\\, \\\\\\, \\\\\\, \\\\\\, recall?\\\\\\\\n\\\\\\\",\\\\n\\\",\\n, \\\\\\, wish.\\\\\\\"\\\\n\\\",\\n, \\\\\\, Polk County Sheriff’s, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, the Pacific for the Pacific’s, Morrison, speech.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":453,\\\\\\\"end\\\\\\\":460,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":79,\\\\\\\"end\\\\\\\":91,\\\\\\\"text\\\\\\\":\\\\\\\"Peter O’Neill\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":32,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":26,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Scott Morrison\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954448000,\\\\\\\"last_updated_at\\\\\\\":1586954448000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n, Montana, NFC Championship, Montana\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954477000,\\\\\\\"last_updated_at\\\\\\\":1586954477000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n\\\",\\n, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s, \\\\\\\"content\\\\\\, types\\\\n\\\",\\n\", entity.label_, \\\\\\\"PER\\\\\\, \\\\\\\"LOC\\\\\\, entities\\\\n\\\",\\n\", type\\\\n\\\",\\n\", correct_unidentified_entities, each\\\\n\\\",\\n\", correct_unidentified_entities, \\\"\\\\u001b[1;32m, entities_1, correct_unidentified_entities, \\\"\\\\u001b[1;32m, \\\\u001b[0;36mget_entities\\\\u001b[1;34m(document_text, \\\\u001b[0;36m__call__\\\\u001b[1;34m(self, entities_1, correct_unidentified_entities, variables\\\\n\\\",\\n, Polk County Sheriff’s, Rome, zone.\\\\n\\\\n“We, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus Island.\\\\n\\\\nThe, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon’s, Polk County Sheriff’s, Rome, Texas, Florida, Florida, Moore Haven, well.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":379,\\\"end\\\":386,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":293,\\\"end\\\":296,\\\"text\\\":\\\"Irma\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":267,\\\"end\\\":272,\\\"text\\\":\\\"Harvey\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":74,\\\"end\\\":79,\\\"text\\\":\\\"Hardin\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":64,\\\"end\\\":71,\\\"text\\\":\\\"Blackmon\\\"}]},{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":42,\\\"end\\\":71,\\\"text\\\":\\\"Chief, Papua New Guinea, Sydney, the Pacific for the Pacific’s, Morrison, \\\"Joe Montana, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s, period.\\\",\\\"annotation\\\":[{\\\"label\\\":[\\\"Person\\\"],\\\"points\\\":[{\\\"start\\\":85,\\\"end\\\":116,\\\"text\\\":\\\"A, \\\\\\\\\\\"json\\\\\\\\\\, json, the ACE Guidelines, Person:\\\\\\\\n\\\",\\\\n, Person, \\\"code\\\",\\\\n, num_matches, num_non_matches, \\\\'A, num_matches, num_non_matches, num_non_matches, class.\\\\\\\\n\\\",\\\\n, Kappa, \\\"Now, \\\"code\\\",\\\\n, isfile, \\\"code\\\",\\\\n, input_file_text, \\\\\\\\\\\"content\\\\\\\\\\, \\\"code\\\",\\\\n, \\\\\\\\\\\"PER\\\\\\\\\\, \\\\\\\\\\\"LOC\\\\\\\\\\, correct_unidentified_entities, correct_unidentified_entities, \\\"code\\\",\\\\n, entities_1, correct_unidentified_entities, calculate\\\\\\\\n\\\",\\\\n, calculate\\\\\\\\n\\\",\\\\n, aren\\\\'t, \\\\\\\\\\\"json\\\\\\\\\\, json, the ACE Guidelines, Person:\\\\\\\\n\\\",\\\\n, Person, Polk County Sheriff’s, Rome, Texas, Florida, Florida, Moore Haven, None,\\\\\\\\n\\\",\\\\n, Papua New Guinea, Sydney, statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I, the Pacific for the Pacific’s, Morrison, None,\\\\\\\\n\\\",\\\\n, Montana, NFC Championship, None,\\\\\\\\n\\\",\\\\n, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker, John Deere, the National FFA Convention, None,\\\\\\\\n\\\",\\\\n, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, Mount Vernon’s, period.\\\\',\\\\\\\\n\\\",\\\\n, None,\\\\\\\\n\\\",\\\\n, pprint\\\\\\\\n\\\",\\\\n    \\\"import, \\\\'A, smalln, zip(m, keym, valuem, keyn, valuen, keym==\\\\\\\\\\\"annotation\\\\\\\\\\, vm, zip(valuem, vmk, vmk==\\\\\\\\\\\"points\\\\\\\\\\, v1,v2, vk1,vv1, vk2,vv2, num_non_matches, text\\\\\\\\n\\\",\\\\n      , teachers\\\\\\\\n\\\",\\\\n, Person\\\\\\\\n\\\",\\\\n, vvlk, vvlv, vvl.items():\\\\\\\\n\\\",\\\\n, num_matches, num_non_matches, \\\\'A, smallm, smalln, zip(m, keym, valuem, keyn, valuen, vn, zip(valuem, vmk, vmk==\\\\\\\\\\\"points\\\\\\\\\\, v1,v2, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches, \\\\'A, smallm, smalln, zip(m, keym, valuem, keyn, valuen, vn, zip(valuem, vmk, vmk==\\\\\\\\\\\"points\\\\\\\\\\, v1,v2, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches\\\\\\\\n\\\",\\\\n, nn):\\\\\\\\n\\\",\\\\n, class.\\\\\\\\n\\\",\\\\n, Kappa, \\\"Now, isfile, Polk County Sheriff’s, Rome, Texas, Florida, Florida, Moore Haven, well.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":379,\\\\\\\\\\\"end\\\\\\\\\\\":386,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":293,\\\\\\\\\\\"end\\\\\\\\\\\":296,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Irma\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":267,\\\\\\\\\\\"end\\\\\\\\\\\":272,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Harvey\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":74,\\\\\\\\\\\"end\\\\\\\\\\\":79,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Hardin\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":64,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":42,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Chief, Papua New Guinea, Sydney, statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I, the Pacific for the Pacific’s, Morrison, Montana, NFC Championship, \\\"{\\\\\\\\\\\"content\\\\\\\\\\, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker, John Deere, the National FFA Convention, \\\\\\\\\\\"A, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, Mount Vernon’s, period.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":85,\\\\\\\\\\\"end\\\\\\\\\\\":116,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"A, \\\\\\\\\\, You\\\\'ll, \\\\\\\\\\, \\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\, json, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\\"There, \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, read_annotation:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, num_matches, \\\\\\\\\\, num_non_matches, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\'A, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, num_matches, \\\\\\\\\\, num_non_matches, \\\\\\\\\\, num_non_matches, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, annotation[\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, temp_num_matches, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\\"print(compare_annotation_files(reference_annotations, Kappa, 0.3.\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\\"Note, \\\\\\\\\\\"Report, \\\\\\\\\\, \\\\\\\\\\, Kappa, \\\\\\\\\\, \\\\\\\\\\, os.path, \\\\\\\\\\, \\\\\\\\\\\"####\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, input_file_text, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\\"print(text_corpus)\\\\\\\\\\\"\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\\\\\\\\\\\\\\\\\\"PER\\\\\\\\\\\\\\\\\\\\\\\\\\, \\\\\\\\\\\\\\\\\\\\\\\\\\\"ORG\\\\\\\\\\\\\\\\\\\\\\\\\\, \\\\\\\\\\\\\\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\\\\\\\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, correct_unidentified_entities, \\\\\\\\\\, \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, correct_unidentified_entities, \\\\\\\\\\, text_corpus:\\\\\\\\\\\\\\\\n\\\\\\\\\\\",\\\\\\\\n\\\",\\\\n, \\\\\\\\\\, entities_1, \\\\\\\\\\, \\\\\\\\\\, correct_unidentified_entities, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, \\\\\\\\\\, aren\\\\'t, \\\\\\\\\\, Polk County Sheriff’s, Rome, Texas, Florida, Florida, Moore Haven, well.\\\\\\\\\\\",\\\\\\\\\\\"annotation\\\\\\\\\\\":[{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":379,\\\\\\\\\\\"end\\\\\\\\\\\":386,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":74,\\\\\\\\\\\"end\\\\\\\\\\\":79,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Hardin\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":64,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Blackmon\\\\\\\\\\\"}]},{\\\\\\\\\\\"label\\\\\\\\\\\":[\\\\\\\\\\\"Person\\\\\\\\\\\"],\\\\\\\\\\\"points\\\\\\\\\\\":[{\\\\\\\\\\\"start\\\\\\\\\\\":55,\\\\\\\\\\\"end\\\\\\\\\\\":71,\\\\\\\\\\\"text\\\\\\\\\\\":\\\\\\\\\\\"Jonathan Blackmon\\\\\\\\\\\"}]}],\\\\\\\\\\\"extras\\\\\\\\\\\":null,\\\\\\\\\\\"metadata\\\\\\\\\\\":{\\\\\\\\\\\"first_done_at\\\\\\\\\\\":1586954510000,\\\\\\\\\\\"last_updated_at\\\\\\\\\\\":1586954510000,\\\\\\\\\\\"sec_taken\\\\\\\\\\\":0,\\\\\\\\\\\"last_updated_by\\\\\\\\\\\":\\\\\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\\\\\",\\\\\\\\\\\"status\\\\\\\\\\\":\\\\\\\\\\\"done\\\\\\\\\\\",\\\\\\\\\\\"evaluation\\\\\\\\\\\":\\\\\\\\\\\"CORRECT\\\\\\\\\\\"}}\\\\\\\\n\\\",\\\\n, Papua New Guinea, Sydney, statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n“I, the Pacific for the Pacific’s, Morrison, Montana, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the Delphi FFA Chapter.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWalker, John Deere, the National FFA Convention, \\\\\\\\\\\"A, Mount Vernon estate.\\\\\\\\\\\\\\\\nA, Mount Vernon’s, blocks\\\\\\\\n\\\",\\\\n, input_file_text, \\\\\\\\\\\"content\\\\\\\\\\, \\\"code\\\",\\\\n, \\\\\\\\\\\"PER\\\\\\\\\\, \\\\\\\\\\\"LOC\\\\\\\\\\, correct_unidentified_entities, correct_unidentified_entities, \\\"code\\\",\\\\n, entities_1, correct_unidentified_entities, \\\\\\\\u001b[0;36mget_entities\\\\\\\\u001b[1;34m(document_text, entities_1, correct_unidentified_entities, calculate\\\\\\\\n\\\",\\\\n, calculate\\\\\\\\n\\\",\\\\n, aren\\\\'t, Polk County Sheriff’s, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, the Pacific for the Pacific’s, Morrison, \\\"Joe Montana, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, the Delphi FFA Chapter.\\\\\\\\n\\\\\\\\nWalker, John Deere, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, Mount Vernon’s, files:\\n, model):\\n\", \\\"GPE\\\"]]\\n\", entities_1, model_1)\\n, model_2, test_entities]\\n\", correct_unidentified_entities, Polk County Sheriff, Rome, RomeCares, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, National FFA, Ind., the National FFA Organization, Delphi, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon]\\n\", Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, statement.\\\\n\\\\n“I, Pacific, Pacific, Morrison, NFC Championship, Delphi, Ind., the National FFA Organization, the National FFA Convention, Mount Vernon estate.\\\\nA, num_matches, non-matches.\\\\n, class.\\\\n, analyzed_doc.ents, entities_1, kernelspec]\\n, json, ACE Guidelines, pprint, num_non_matches, own\\\\n, num_non_matches, num_non_matches, num_non_matches, os.path, dir_base, correct_unidentified_entities, entities_1, correct_unidentified_entities, cell_type, cell_type, ipython]\\n, Polk County Sheriff, Rome, RomeCares, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, National FFA, Ind., the National FFA Organization, the National FFA Convention, Mount Vernon, vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, m:\\\\n, zip(valuem, vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, zip(vv1,vv2):\\\\n, num_matches, zip(valuem, vk1,vv1, vk2,vv2, zip(v1.items(),v2.items()):\\\\n, v11,v22, zip(vv1,vv2):\\\\n, num_matches, compare_annotations(mm, non-matches.\\\\n, class.\\\\n, Polk County Sheriff, Rome, RomeCares, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Montana, Gate A, National FFA, Ind., the National FFA Organization, the National FFA Convention, Mount Vernon estate.\\\\\\\\nA, done\\\\\\\\\\\\, annotations\\\\\\\\n\\\\\\\",\\\\n, num_matches, num_matches, news.\\\\\\\"\\\\n, types\\\\\\\\n\\\\\\\",\\\\n, analyzed_doc.ents, \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\, entities_1, entities_2, IOPub, Polk County Sheriff, Rome, RomeCares, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, speech.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":453,\\\\\\\"end\\\\\\\":460,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":79,\\\\\\\"end\\\\\\\":91,\\\\\\\"text\\\\\\\":\\\\\\\"Peter O’Neill\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":32,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Morrison\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":26,\\\\\\\"end\\\\\\\":39,\\\\\\\"text\\\\\\\":\\\\\\\"Scott Morrison\\\\\\\"}]}],\\\\\\\"extras\\\\\\\":null,\\\\\\\"metadata\\\\\\\":{\\\\\\\"first_done_at\\\\\\\":1586954448000,\\\\\\\"last_updated_at\\\\\\\":1586954448000,\\\\\\\"sec_taken\\\\\\\":0,\\\\\\\"last_updated_by\\\\\\\":\\\\\\\"GAUua4TByDWq4pqf203jFtL8DoL2\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"done\\\\\\\",\\\\\\\"evaluation\\\\\\\":\\\\\\\"NONE\\\\\\\"}}\\\\n, Montana, Gate A, National FFA, Ind., the National FFA Organization, the National FFA Convention, Mount Vernon, IOPub, dir_base, analyzed_doc.ents, NER, NER, entities_1, model_1\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[1;33m\\\\u001b[0m\\\\u001b[0m\\\\n\\\\u001b[0;32, \\\\u001b[0;36mget_entities\\\\u001b[1;34m(document_text, \\\\u001b[0;36m__call__\\\\u001b[1;34m(self, NER, NER, entities_1, entities_2, kernelspec]\\n, json, ACE Guidelines, Polk County Sheriff’s, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Morrison, NFC Championship, Delphi, Ind., the National FFA Organization, the National FFA Convention, Mount Vernon, Mount Vernon’s, num_non_matches, own\\\\n, smallm, smalln, keym, valuem, keyn, valuen, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, m:\\\\n, vk, vv, v.items():\\\\n\\, vvl, vv:\\\\n, vvl, vv:\\\\n, vvlk, vvlv, num_matches, num_non_matches, own\\\\n, smallm, smalln, keym, valuem, keyn, valuen, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches, num_matches, num_non_matches, own\\\\n, smallm, smalln, keym, valuem, keyn, valuen, vm, zip(valuem, vmk, zip(vm.items(),vn.items()):\\\\n, vk1,vv1, vk2,vv2, num_non_matches, num_matches, num_non_matches\\\\n, print(compare_annotation_files(m, cell_type, os.path, Polk County Sheriff’s, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, well.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":379,\\\\\\\"end\\\\\\\":386,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":293,\\\\\\\"end\\\\\\\":296,\\\\\\\"text\\\\\\\":\\\\\\\"Irma\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":267,\\\\\\\"end\\\\\\\":272,\\\\\\\"text\\\\\\\":\\\\\\\"Harvey\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":74,\\\\\\\"end\\\\\\\":79,\\\\\\\"text\\\\\\\":\\\\\\\"Hardin\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":64,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Blackmon\\\\\\\"}]},{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":42,\\\\\\\"end\\\\\\\":71,\\\\\\\"text\\\\\\\":\\\\\\\"Chief, Papua New Guinea, Sydney, Pacific, Pacific, Morrison, Montana, NFC Championship, Delphi, Ind., the National FFA Organization, the National FFA Convention, Mount Vernon, Mount Vernon’s, period.\\\\\\\",\\\\\\\"annotation\\\\\\\":[{\\\\\\\"label\\\\\\\":[\\\\\\\"Person\\\\\\\"],\\\\\\\"points\\\\\\\":[{\\\\\\\"start\\\\\\\":85,\\\\\\\"end\\\\\\\":116,\\\\\\\"text\\\\\\\":\\\\\\\"A, submit\\\\\\\\n\\\\\\\",\\\\n\\\", done\\\\\\\\\\\\, json, ACE Guidelines, num_matches, num_non_matches, method\\\\\\\\n\\\\\\\",\\\\n, num_matches, num_non_matches, num_non_matches, isfile, join\\\\\\\"\\\\n, input_file_text, \\\\\\\\\\\\\\\"content\\\\\\\\\\\\, \\\\\\\\\\\\\\\"PER\\\\\\\\\\\\, \\\\\\\\\\\\\\\"LOC\\\\\\\\\\\\, correct_unidentified_entities, correct_unidentified_entities, entities_1, correct_unidentified_entities, variables\\\\\\\\n\\\\\\\",\\\\n, IOPub, Polk County Sheriff’s, Rome, zone.\\\\\\\\n\\\\\\\\n“We, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Morrison, NFC Championship, Delphi, Ind., the National FFA Organization, the National FFA Convention, Mount Vernon, Mount Vernon’s, IOPub, correct_unidentified_entities, entities_1, correct_unidentified_entities, \\\\u001b[0;36mget_entities\\\\u001b[1;34m(document_text, \\\\u001b[0;36m__call__\\\\u001b[1;34m(self, entities_1, correct_unidentified_entities, cell_type, cell_type, ipython]\\n, Polk County Sheriff, Rome, RomeCares, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, National FFA, Ind., the National FFA Organization, Delphi, the National FFA Convention, Mount Vernon estate.\\\\nA, Mount Vernon]\\n\", Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, statement.\\\\n\\\\n“I, Pacific, Pacific, Morrison, NFC Championship, Delphi, Ind., the National FFA Organization, the National FFA Convention, Mount Vernon estate.\\\\nA, entities_1, model_1)\\n, correct_unidentified_entities, cell_type, cell_type, cell_type, ipython]\n",
      "[Polk County Sheriff, Rome, RomeCares, Floyd Sheriff, Hurricane Harvey, Texas, Irma, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Pacific, Pacific, Gate A, Levi, John Deere, National FFA, National FFA, Ind., the National FFA Organization, John Deere, Delphi, the National FFA, John Deere, the National FFA Convention, Mount Vernon estate.\\nA, Mount Vernon]\n",
      "[Polk County Sheriff’s Office, Rome, Texas, Florida, Florida, Moore Haven, Papua New Guinea, Sydney, Manus, statement.\\n\\n“I, the Pacific for the Pacific’s, Morrison, NFC Championship, John Deere, National FFA, Delphi, Ind., National FFA, the National FFA Organization, John Deere, the National FFA Convention, Mount Vernon estate.\\nA, Mount Vernon’s]\n"
     ]
    }
   ],
   "source": [
    "for document in text_corpus:\n",
    "    # below you will see that entities_1 is from model_1\n",
    "    # you can make a decision about which model output will be the reference output\n",
    "    entities_1 = get_entities(document[\"content\"], model_1)\n",
    "    entities_2 = get_entities(document[\"content\"], model_2)\n",
    "    correct_identified_entities, correct_unidentified_entities, spurious_identified_entites = compare_entities_from_document(entities_1, entities_2)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(correct_identified_entities)\n",
    "print(correct_unidentified_entities)\n",
    "print(spurious_identified_entites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6086956521739131\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# now that you are outside the loop, determine the following values\n",
    "#fn=(len(entities_1)+len(entities_2))-(correct_identified_entities+correct_unidentified_entities+spurious_identified_entites)\n",
    "precision = correct_identified_entities/(correct_identified_entities+spurious_identified_entites)\n",
    "# determine which set of numbers above needed to calculate\n",
    "recall = correct_identified_entities/(correct_identified_entities+correct_unidentified_entities)\n",
    "# determine which set of numbers above needed to calculate\n",
    "#print(fn)\n",
    "print(precision)\n",
    "print(recall)\n",
    "# what is the overall precision and recall?\n",
    "# does this change if you change the reference model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: \n",
    "Now you might want to speculate on which model appears to work better. Write a 1 paragraph brief on which model you think works better. Since we aren't using a normal evaluation set, feel free to speculate as you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination:\n",
    "The correctly identified entities and correct unidentified entities are equal. This would show that both the models give the same kind of output or can both correctly tag the data. But looking the spurious identified entites, it is pretty high. Meaning that the second model can tag more correctly data than the first model. In my opinion the second model seems to better than the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Credit: \n",
    "\n",
    "- You can add a function that will help to identify which documents appear to be the most different in terms of their extracted entities\n",
    "- You can add a function that will tell which entity types exhibit the greatest difference in extraction between models\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
